{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "        ***** Image Classification with TensorFlow for Cat/Dog Use case********\n",
    "\n",
    "In this notebook, \n",
    "A. Used local data of Cat/Dog image to build Image classification model using TensorFlow library (CNN)\n",
    "B. For referencing Image data, there are different ways of providing a reference of Image data such as \n",
    "    a. via 'flow_from_directory' api  - This is used when you have two different folder for Train and Validation images\n",
    "    b. via 'flow_from_dataframe' api - This is used when u have single folder and u load the images into dataframe and then split\n",
    "        into Train and Validation image\n",
    "\n",
    "C. In this notebook implementation, \n",
    "    a. 'flow_from_directory' api is used to load the data from local directory and used it in model fitting\n",
    "    \n",
    "D. Save the model and model weight into file and used these files for further prediction on Test Images\n",
    "   \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part-1 - Initialising the CNN and compiling the model\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.preprocessing.image.ImageDataGenerator object at 0x00000250E75C1FD0>\n",
      "Found 210 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Part 2 - Create train and test ImageDataGenerator via 'flow_from_directory' \n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "print(train_datagen)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('Downloads/trainsubset', target_size = (64, 64), \n",
    "                                                 batch_size = 32, class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 132 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('Downloads/testsubset', target_size = (64, 64), \n",
    "                                            batch_size = 32, class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "8000/8000 [==============================] - 1351s 169ms/step - loss: 0.0197 - acc: 0.9919 - val_loss: 6.2451 - val_acc: 0.4848\n",
      "Epoch 2/25\n",
      "8000/8000 [==============================] - 1348s 169ms/step - loss: 7.7223e-06 - acc: 1.0000 - val_loss: 8.4396 - val_acc: 0.4621\n",
      "Epoch 3/25\n",
      "8000/8000 [==============================] - 1348s 168ms/step - loss: 6.1360e-08 - acc: 1.0000 - val_loss: 10.3973 - val_acc: 0.4773\n",
      "Epoch 4/25\n",
      "8000/8000 [==============================] - 1343s 168ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 8.9769 - val_acc: 0.5076\n",
      "Epoch 5/25\n",
      "8000/8000 [==============================] - 1338s 167ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 9.5480 - val_acc: 0.5303\n",
      "Epoch 6/25\n",
      "8000/8000 [==============================] - 1339s 167ms/step - loss: 4.0490e-07 - acc: 1.0000 - val_loss: 11.2074 - val_acc: 0.5455\n",
      "Epoch 7/25\n",
      "8000/8000 [==============================] - 1335s 167ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 11.4909 - val_acc: 0.4394\n",
      "Epoch 8/25\n",
      "8000/8000 [==============================] - 1340s 168ms/step - loss: 1.3928e-06 - acc: 1.0000 - val_loss: 12.3288 - val_acc: 0.4545\n",
      "Epoch 9/25\n",
      "8000/8000 [==============================] - 1339s 167ms/step - loss: 1.2838e-08 - acc: 1.0000 - val_loss: 13.3563 - val_acc: 0.4621\n",
      "Epoch 10/25\n",
      "8000/8000 [==============================] - 1341s 168ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 13.9934 - val_acc: 0.5076\n",
      "Epoch 11/25\n",
      "8000/8000 [==============================] - 1341s 168ms/step - loss: 9.2280e-08 - acc: 1.0000 - val_loss: 15.1602 - val_acc: 0.5303\n",
      "Epoch 12/25\n",
      "8000/8000 [==============================] - 1343s 168ms/step - loss: 3.4585e-09 - acc: 1.0000 - val_loss: 16.7152 - val_acc: 0.5076\n",
      "Epoch 13/25\n",
      "8000/8000 [==============================] - 1344s 168ms/step - loss: 2.7645e-10 - acc: 1.0000 - val_loss: 18.0918 - val_acc: 0.5076\n",
      "Epoch 14/25\n",
      "8000/8000 [==============================] - 1347s 168ms/step - loss: 0.0011 - acc: 0.9998 - val_loss: 15.6879 - val_acc: 0.4924\n",
      "Epoch 15/25\n",
      "8000/8000 [==============================] - 1346s 168ms/step - loss: 5.5212e-08 - acc: 1.0000 - val_loss: 16.4831 - val_acc: 0.4848\n",
      "Epoch 16/25\n",
      "8000/8000 [==============================] - 1352s 169ms/step - loss: 2.2157e-09 - acc: 1.0000 - val_loss: 17.4287 - val_acc: 0.4848\n",
      "Epoch 17/25\n",
      "8000/8000 [==============================] - 1349s 169ms/step - loss: 1.5877e-10 - acc: 1.0000 - val_loss: 18.5454 - val_acc: 0.4773\n",
      "Epoch 18/25\n",
      "8000/8000 [==============================] - 1349s 169ms/step - loss: 0.0011 - acc: 0.9998 - val_loss: 19.0939 - val_acc: 0.4773\n",
      "Epoch 19/25\n",
      "8000/8000 [==============================] - 1345s 168ms/step - loss: 0.0013 - acc: 0.9998 - val_loss: 19.9949 - val_acc: 0.5076\n",
      "Epoch 20/25\n",
      "8000/8000 [==============================] - 1348s 169ms/step - loss: 8.8472e-04 - acc: 0.9999 - val_loss: 26.3902 - val_acc: 0.4848\n",
      "Epoch 21/25\n",
      "8000/8000 [==============================] - 1348s 169ms/step - loss: 3.4206e-07 - acc: 1.0000 - val_loss: 27.8457 - val_acc: 0.4773\n",
      "Epoch 22/25\n",
      "8000/8000 [==============================] - 1348s 168ms/step - loss: 6.2184e-09 - acc: 1.0000 - val_loss: 26.9053 - val_acc: 0.5000\n",
      "Epoch 23/25\n",
      "8000/8000 [==============================] - 1349s 169ms/step - loss: 9.1186e-04 - acc: 0.9999 - val_loss: 30.1056 - val_acc: 0.4545\n",
      "Epoch 24/25\n",
      "8000/8000 [==============================] - 1350s 169ms/step - loss: 0.0014 - acc: 0.9998 - val_loss: 27.6078 - val_acc: 0.4697\n",
      "Epoch 25/25\n",
      "8000/8000 [==============================] - 1347s 168ms/step - loss: 1.0653e-08 - acc: 1.0000 - val_loss: 27.7188 - val_acc: 0.4773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x250eb66dfd0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 3 - Fitting the CNN to the images. Train the Model on Training images. For validation, used Test Images\n",
    "\n",
    "classifier.fit_generator(training_set, steps_per_epoch = 8000, epochs = 25,\n",
    "                         validation_data = test_set, validation_steps = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test image1: [[[ 40.  84. 111.]\n",
      "  [ 40.  86. 112.]\n",
      "  [ 42.  91. 121.]\n",
      "  ...\n",
      "  [ 93.  23.  13.]\n",
      "  [ 32.  18.   5.]\n",
      "  [ 26.  11.  14.]]\n",
      "\n",
      " [[ 53.  75.  88.]\n",
      "  [ 41.  88. 116.]\n",
      "  [ 45.  90. 113.]\n",
      "  ...\n",
      "  [ 68.  15.  11.]\n",
      "  [ 18.  15.   6.]\n",
      "  [ 23.  13.  14.]]\n",
      "\n",
      " [[ 11.   0.   0.]\n",
      "  [ 50.  90. 116.]\n",
      "  [ 43.  91. 113.]\n",
      "  ...\n",
      "  [ 58.  17.  13.]\n",
      "  [ 13.  15.   2.]\n",
      "  [ 21.   9.  11.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 61.  26.  33.]\n",
      "  [ 54.  19.  26.]\n",
      "  [ 59.  24.  31.]\n",
      "  ...\n",
      "  [137.  73.  38.]\n",
      "  [133.  68.  36.]\n",
      "  [136.  71.  43.]]\n",
      "\n",
      " [[ 50.  17.  24.]\n",
      "  [ 61.  26.  33.]\n",
      "  [ 60.  23.  31.]\n",
      "  ...\n",
      "  [137.  68.  35.]\n",
      "  [126.  60.  26.]\n",
      "  [123.  60.  27.]]\n",
      "\n",
      " [[ 62.  31.  37.]\n",
      "  [ 74.  32.  42.]\n",
      "  [ 72.  24.  36.]\n",
      "  ...\n",
      "  [147.  77.  51.]\n",
      "  [134.  67.  38.]\n",
      "  [136.  74.  37.]]]\n",
      "test image2: [[[[ 40.  84. 111.]\n",
      "   [ 40.  86. 112.]\n",
      "   [ 42.  91. 121.]\n",
      "   ...\n",
      "   [ 93.  23.  13.]\n",
      "   [ 32.  18.   5.]\n",
      "   [ 26.  11.  14.]]\n",
      "\n",
      "  [[ 53.  75.  88.]\n",
      "   [ 41.  88. 116.]\n",
      "   [ 45.  90. 113.]\n",
      "   ...\n",
      "   [ 68.  15.  11.]\n",
      "   [ 18.  15.   6.]\n",
      "   [ 23.  13.  14.]]\n",
      "\n",
      "  [[ 11.   0.   0.]\n",
      "   [ 50.  90. 116.]\n",
      "   [ 43.  91. 113.]\n",
      "   ...\n",
      "   [ 58.  17.  13.]\n",
      "   [ 13.  15.   2.]\n",
      "   [ 21.   9.  11.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 61.  26.  33.]\n",
      "   [ 54.  19.  26.]\n",
      "   [ 59.  24.  31.]\n",
      "   ...\n",
      "   [137.  73.  38.]\n",
      "   [133.  68.  36.]\n",
      "   [136.  71.  43.]]\n",
      "\n",
      "  [[ 50.  17.  24.]\n",
      "   [ 61.  26.  33.]\n",
      "   [ 60.  23.  31.]\n",
      "   ...\n",
      "   [137.  68.  35.]\n",
      "   [126.  60.  26.]\n",
      "   [123.  60.  27.]]\n",
      "\n",
      "  [[ 62.  31.  37.]\n",
      "   [ 74.  32.  42.]\n",
      "   [ 72.  24.  36.]\n",
      "   ...\n",
      "   [147.  77.  51.]\n",
      "   [134.  67.  38.]\n",
      "   [136.  74.  37.]]]]\n",
      "It is a : cat\n"
     ]
    }
   ],
   "source": [
    "# Part 4 - Making new predictions for single image which is loaded from local folder\n",
    "\n",
    "test_image = image.load_img('Downloads/11221.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "print(\"test image1:\", test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "print(\"test image2:\", test_image)\n",
    "\n",
    "\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "    \n",
    "print(\"It is a :\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved classifier model to disk\n"
     ]
    }
   ],
   "source": [
    "# Part 5- save model file and model weights \n",
    "classifier.save(\"classifier.model1\")\n",
    "classifier.save_weights(\"classifier.model2\")\n",
    "print(\"Saved classifier model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 6-  serialize model to JSON\n",
    "classifier_json = classifier.to_json()\n",
    "\n",
    "with open(\"classifier.json\", \"w\") as json_file:\n",
    "    json_file.write(classifier_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a : cat\n"
     ]
    }
   ],
   "source": [
    "# Part 7- Load the model file and used it for prediction on test image.\n",
    "classnames = [\"cat\", \"dog\"]\n",
    "model = load_model('classifier.model1')\n",
    "\n",
    "test_image = image.load_img('Downloads/10212.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(\"It is a :\", prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
