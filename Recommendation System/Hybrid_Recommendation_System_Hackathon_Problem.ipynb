{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    ****************** HYBRID RECOMMENDATION SYSTEM  **********************\n",
    "    \n",
    "This notebook provides implementation of Hybrid Recommendation System for the problem stated in below link. Please refer below \n",
    "link to understand the problem statement in better manner.\n",
    "\n",
    "https://datahack.analyticsvidhya.com/contest/practice-problem-recommendation-engine/\n",
    "\n",
    "In this notebook -\n",
    "A. Data is transformed using Feature engineering concepts.\n",
    "B. Several algorithms in combination has been put up to build the model to predict the 'Attempted_range' for given user and problem id\n",
    "    a. cosine_similarity\n",
    "    b. SVD\n",
    "    c. Baseline\n",
    "    d. NMF\n",
    "    e. KNNBaseline item-item similarity\n",
    "    f. KNNBaseline user-user similarity\n",
    "    \n",
    "C. I was able to get the second best accuracy (F1-score) i.e. '0.5103025641' with using KNNBaseline user-user similarity and Cosine\n",
    "    similarity algorithm in combination. refer below link for leaderboard.\n",
    "\n",
    "https://datahack.analyticsvidhya.com/contest/practice-problem-recommendation-engine/lb\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from statistics import mean\n",
    "import math\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix\n",
    "from numpy import array\n",
    "\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import NormalPredictor\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNWithZScore\n",
    "from surprise import KNNBaseline\n",
    "from surprise import SVD\n",
    "from surprise import BaselineOnly\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "from surprise.accuracy import rmse\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part-1  Load the Problem and Users data into dataframe\n",
    "\n",
    "problems = pd.read_csv('analytics_vidhya_recommendataion_engine_data/problem_data.csv', sep=',', error_bad_lines=False, encoding=\"latin-1\")\n",
    "users = pd.read_csv('analytics_vidhya_recommendataion_engine_data/user_data.csv', sep=',', error_bad_lines=False, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem_id</th>\n",
       "      <th>level_type</th>\n",
       "      <th>points</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prob_3649</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prob_6191</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prob_2020</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prob_313</td>\n",
       "      <td>A</td>\n",
       "      <td>500.0</td>\n",
       "      <td>greedy,implementation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prob_101</td>\n",
       "      <td>A</td>\n",
       "      <td>500.0</td>\n",
       "      <td>constructive algorithms,greedy,math</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  problem_id level_type  points                                 tags\n",
       "0  prob_3649          H     NaN                                  NaN\n",
       "1  prob_6191          A     NaN                                  NaN\n",
       "2  prob_2020          F     NaN                                  NaN\n",
       "3   prob_313          A   500.0                greedy,implementation\n",
       "4   prob_101          A   500.0  constructive algorithms,greedy,math"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problems.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>submission_count</th>\n",
       "      <th>problem_solved</th>\n",
       "      <th>contribution</th>\n",
       "      <th>country</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>last_online_time_seconds</th>\n",
       "      <th>max_rating</th>\n",
       "      <th>rating</th>\n",
       "      <th>rank</th>\n",
       "      <th>registration_time_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_3311</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1504111645</td>\n",
       "      <td>348.337</td>\n",
       "      <td>330.849</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>1466686436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_3028</td>\n",
       "      <td>63</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>India</td>\n",
       "      <td>17</td>\n",
       "      <td>1498998165</td>\n",
       "      <td>405.677</td>\n",
       "      <td>339.450</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>1441893325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_2268</td>\n",
       "      <td>226</td>\n",
       "      <td>203</td>\n",
       "      <td>-8</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>24</td>\n",
       "      <td>1505566052</td>\n",
       "      <td>307.339</td>\n",
       "      <td>284.404</td>\n",
       "      <td>beginner</td>\n",
       "      <td>1454267603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_480</td>\n",
       "      <td>611</td>\n",
       "      <td>490</td>\n",
       "      <td>1</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>94</td>\n",
       "      <td>1505257499</td>\n",
       "      <td>525.803</td>\n",
       "      <td>471.330</td>\n",
       "      <td>advanced</td>\n",
       "      <td>1350720417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_650</td>\n",
       "      <td>504</td>\n",
       "      <td>479</td>\n",
       "      <td>12</td>\n",
       "      <td>Russia</td>\n",
       "      <td>4</td>\n",
       "      <td>1496613433</td>\n",
       "      <td>548.739</td>\n",
       "      <td>486.525</td>\n",
       "      <td>advanced</td>\n",
       "      <td>1395560498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  submission_count  problem_solved  contribution  country  \\\n",
       "0  user_3311                47              40             0      NaN   \n",
       "1  user_3028                63              52             0    India   \n",
       "2  user_2268               226             203            -8    Egypt   \n",
       "3   user_480               611             490             1  Ukraine   \n",
       "4   user_650               504             479            12   Russia   \n",
       "\n",
       "   follower_count  last_online_time_seconds  max_rating   rating  \\\n",
       "0               4                1504111645     348.337  330.849   \n",
       "1              17                1498998165     405.677  339.450   \n",
       "2              24                1505566052     307.339  284.404   \n",
       "3              94                1505257499     525.803  471.330   \n",
       "4               4                1496613433     548.739  486.525   \n",
       "\n",
       "           rank  registration_time_seconds  \n",
       "0  intermediate                 1466686436  \n",
       "1  intermediate                 1441893325  \n",
       "2      beginner                 1454267603  \n",
       "3      advanced                 1350720417  \n",
       "4      advanced                 1395560498  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    " ***********    Part-2A  - Feature Engineering ********************  \n",
    "\n",
    "Problems dataframe contains 'tags' column which contains list of values ... to convert into continious value for model training.\n",
    "\n",
    "A. Get the unique tags from 'Tags' column \n",
    "B. Create a new column for each unqiue tag value\n",
    "C. Fill these column with either 0 or 1 based on that tag presence on that row\n",
    "\n",
    "'''\n",
    "\n",
    "problems['tags'] = problems['tags'].fillna('')\n",
    "\n",
    "unique_tags = []\n",
    "df_tags = problems['tags']\n",
    "\n",
    "for tag in problems['tags']:\n",
    "    tag = str(tag)\n",
    "    if tag is not '':\n",
    "        tag_splits = tag.split(',')\n",
    "        for s in tag_splits:\n",
    "            if s not in unique_tags:\n",
    "                unique_tags.append(s)\n",
    "\n",
    "def chk_row_index_list(row, tag):\n",
    "    if tag in row['tags']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "    \n",
    "for tag in unique_tags:\n",
    "    problems[tag] = problems.apply(\n",
    "                lambda x: chk_row_index_list(x, tag), axis=1)\n",
    "    \n",
    "\n",
    "# problems = problems.dropna(subset=['level_type'])\n",
    "problems['level_type'] = problems['level_type'].fillna('A')\n",
    "problems.points = problems.groupby('level_type')['points'].apply(lambda x: x.fillna(x.mean()))\n",
    "problems.points = problems.points.fillna(0.0)\n",
    "problems.drop(['tags'], axis=1, inplace=True)\n",
    "\n",
    "users.drop(['last_online_time_seconds', 'registration_time_seconds', 'country'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " ***********    Part-2B  - Feature Engineering ********************\n",
    " A. Use lable encoder for converting 'Rank' and 'Level_Type' categorical columnn values into continious\n",
    " \n",
    "'''\n",
    "\n",
    "rank_values = array(users['rank'])\n",
    "le_rank = preprocessing.LabelEncoder()\n",
    "users['rank'] = le_rank.fit_transform(users['rank'])\n",
    "rank_classes = le_rank.classes_\n",
    "\n",
    "le_level_type = preprocessing.LabelEncoder()\n",
    "problems['level_type'] = le_level_type.fit_transform(problems['level_type'])\n",
    "level_classes = le_level_type.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>submission_count</th>\n",
       "      <th>problem_solved</th>\n",
       "      <th>contribution</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>max_rating</th>\n",
       "      <th>rating</th>\n",
       "      <th>rank</th>\n",
       "      <th>problem_id</th>\n",
       "      <th>level_type</th>\n",
       "      <th>...</th>\n",
       "      <th>*special</th>\n",
       "      <th>geometry</th>\n",
       "      <th>graph matchings</th>\n",
       "      <th>string suffix structures</th>\n",
       "      <th>fft</th>\n",
       "      <th>matrices</th>\n",
       "      <th>schedules</th>\n",
       "      <th>2-sat</th>\n",
       "      <th>chinese remainder theorem</th>\n",
       "      <th>attempts_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_3311</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>348.337</td>\n",
       "      <td>330.849</td>\n",
       "      <td>3</td>\n",
       "      <td>prob_75</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_3311</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>348.337</td>\n",
       "      <td>330.849</td>\n",
       "      <td>3</td>\n",
       "      <td>prob_3508</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_3311</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>348.337</td>\n",
       "      <td>330.849</td>\n",
       "      <td>3</td>\n",
       "      <td>prob_6362</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_3311</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>348.337</td>\n",
       "      <td>330.849</td>\n",
       "      <td>3</td>\n",
       "      <td>prob_1308</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_3311</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>348.337</td>\n",
       "      <td>330.849</td>\n",
       "      <td>3</td>\n",
       "      <td>prob_1481</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  submission_count  problem_solved  contribution  follower_count  \\\n",
       "0  user_3311                47              40             0               4   \n",
       "1  user_3311                47              40             0               4   \n",
       "2  user_3311                47              40             0               4   \n",
       "3  user_3311                47              40             0               4   \n",
       "4  user_3311                47              40             0               4   \n",
       "\n",
       "   max_rating   rating  rank problem_id  level_type  ...  *special  geometry  \\\n",
       "0     348.337  330.849     3    prob_75           0  ...         0         0   \n",
       "1     348.337  330.849     3  prob_3508           0  ...         0         0   \n",
       "2     348.337  330.849     3  prob_6362           3  ...         0         0   \n",
       "3     348.337  330.849     3  prob_1308           2  ...         0         0   \n",
       "4     348.337  330.849     3  prob_1481           1  ...         0         0   \n",
       "\n",
       "   graph matchings  string suffix structures  fft  matrices  schedules  2-sat  \\\n",
       "0                0                         0    0         0          0      0   \n",
       "1                0                         0    0         0          0      0   \n",
       "2                0                         0    0         0          0      0   \n",
       "3                0                         0    0         0          0      0   \n",
       "4                0                         0    0         0          0      0   \n",
       "\n",
       "   chinese remainder theorem  attempts_range  \n",
       "0                          0               1  \n",
       "1                          0               1  \n",
       "2                          0               2  \n",
       "3                          0               1  \n",
       "4                          0               1  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_submissions = pd.read_csv('analytics_vidhya_recommendataion_engine_data/train_submissions.csv', sep=',', error_bad_lines=False, encoding=\"latin-1\")\n",
    "tempdf = pd.merge(problems, train_submissions, on='problem_id', how='inner')\n",
    "final_df = pd.merge(users, tempdf, on='user_id', how='inner')\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after data transformation-\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>submission_count</th>\n",
       "      <th>problem_solved</th>\n",
       "      <th>contribution</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>max_rating</th>\n",
       "      <th>rating</th>\n",
       "      <th>rank</th>\n",
       "      <th>problem_id</th>\n",
       "      <th>level_type</th>\n",
       "      <th>...</th>\n",
       "      <th>*special</th>\n",
       "      <th>geometry</th>\n",
       "      <th>graph matchings</th>\n",
       "      <th>string suffix structures</th>\n",
       "      <th>fft</th>\n",
       "      <th>matrices</th>\n",
       "      <th>schedules</th>\n",
       "      <th>2-sat</th>\n",
       "      <th>chinese remainder theorem</th>\n",
       "      <th>attempts_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2570</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>348.337</td>\n",
       "      <td>330.849</td>\n",
       "      <td>3</td>\n",
       "      <td>6267</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2570</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>348.337</td>\n",
       "      <td>330.849</td>\n",
       "      <td>3</td>\n",
       "      <td>2788</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2570</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>348.337</td>\n",
       "      <td>330.849</td>\n",
       "      <td>3</td>\n",
       "      <td>5959</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2570</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>348.337</td>\n",
       "      <td>330.849</td>\n",
       "      <td>3</td>\n",
       "      <td>344</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2570</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>348.337</td>\n",
       "      <td>330.849</td>\n",
       "      <td>3</td>\n",
       "      <td>536</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  submission_count  problem_solved  contribution  follower_count  \\\n",
       "0     2570                47              40             0               4   \n",
       "1     2570                47              40             0               4   \n",
       "2     2570                47              40             0               4   \n",
       "3     2570                47              40             0               4   \n",
       "4     2570                47              40             0               4   \n",
       "\n",
       "   max_rating   rating  rank  problem_id  level_type  ...  *special  geometry  \\\n",
       "0     348.337  330.849     3        6267           0  ...         0         0   \n",
       "1     348.337  330.849     3        2788           0  ...         0         0   \n",
       "2     348.337  330.849     3        5959           3  ...         0         0   \n",
       "3     348.337  330.849     3         344           2  ...         0         0   \n",
       "4     348.337  330.849     3         536           1  ...         0         0   \n",
       "\n",
       "   graph matchings  string suffix structures  fft  matrices  schedules  2-sat  \\\n",
       "0                0                         0    0         0          0      0   \n",
       "1                0                         0    0         0          0      0   \n",
       "2                0                         0    0         0          0      0   \n",
       "3                0                         0    0         0          0      0   \n",
       "4                0                         0    0         0          0      0   \n",
       "\n",
       "   chinese remainder theorem  attempts_range  \n",
       "0                          0               1  \n",
       "1                          0               1  \n",
       "2                          0               2  \n",
       "3                          0               1  \n",
       "4                          0               1  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    " ***********    Part-2C  - Feature Engineering ********************\n",
    " A. Use lable encoder for converting 'user_id' and 'problem_id' categorical columnn values into continious values\n",
    " \n",
    "'''\n",
    "\n",
    "le_user_id = preprocessing.LabelEncoder()\n",
    "users['user_id'] = le_user_id.fit_transform(users['user_id'])\n",
    "final_df['user_id'] = le_user_id.transform(final_df['user_id'])\n",
    "train_submissions['user_id'] = le_user_id.transform(train_submissions['user_id'])\n",
    "user_classes = le_user_id.classes_\n",
    "\n",
    "le_problem_id = preprocessing.LabelEncoder()\n",
    "problems['problem_id'] = le_problem_id.fit_transform(problems['problem_id'])\n",
    "final_df['problem_id'] = le_problem_id.transform(final_df['problem_id'])\n",
    "train_submissions['problem_id'] = le_problem_id.transform(train_submissions['problem_id'])\n",
    "problem_classes = le_problem_id.classes_\n",
    "\n",
    "print('after data transformation-')\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.77813551, 0.91730815, ..., 0.973738  , 0.79231861,\n",
       "        0.78707369],\n",
       "       [0.77813551, 1.        , 0.46369623, ..., 0.90069909, 0.99973759,\n",
       "        0.22500447],\n",
       "       [0.91730815, 0.46369623, 1.        , ..., 0.80256495, 0.48386933,\n",
       "        0.96760873],\n",
       "       ...,\n",
       "       [0.973738  , 0.90069909, 0.80256495, ..., 1.        , 0.9104142 ,\n",
       "        0.62596437],\n",
       "       [0.79231861, 0.99973759, 0.48386933, ..., 0.9104142 , 1.        ,\n",
       "        0.2472643 ],\n",
       "       [0.78707369, 0.22500447, 0.96760873, ..., 0.62596437, 0.2472643 ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 3- Get the cosine similarity matrix for Problem and User dataframe\n",
    "problem_cosine_similarity = cosine_similarity(problems)\n",
    "user_cosine_similarity = cosine_similarity(users)\n",
    "\n",
    "problem_cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part-4 - Get the list of user_id and problem_id and corresponding indices\n",
    "users = users.reset_index()\n",
    "user_ids = users['user_id']\n",
    "user_indices = pd.Series(users.index, index=users['user_id'])\n",
    "\n",
    "problems = problems.reset_index()\n",
    "problem_ids = problems['problem_id']\n",
    "problem_indices = pd.Series(problems.index, index=problems['problem_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0, 9))\n",
    "data = Dataset.load_from_df(train_submissions[['user_id', 'problem_id', 'attempts_range']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8900\n",
      "0.8899748016154547\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Part 5A - train the model using SVD algoirthm \n",
    "'''\n",
    "\n",
    "svdalgo = SVD(n_factors=160, n_epochs=100, lr_all=0.005, reg_all=0.1, random_state=0)\n",
    "svdalgo.fit(trainset)\n",
    "svdpredictions = svdalgo.test(testset[:200])\n",
    "\n",
    "print(accuracy.rmse(svdpredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0311\n",
      "1.0311492681002459\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Part 5B - train the model using CoClustering algoirthm \n",
    "'''\n",
    "\n",
    "CoClusteringalgo = CoClustering(n_epochs=100, random_state=42)\n",
    "CoClusteringalgo.fit(trainset)\n",
    "CoClusteringalgopredictions = CoClusteringalgo.test(testset[:200])\n",
    "\n",
    "print(accuracy.rmse(CoClusteringalgopredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Part 5C - train the model using NMF algoirthm \n",
    "'''\n",
    "\n",
    "nmfalgo = NMF(n_factors=160, n_epochs=100, random_state=0)\n",
    "nmfalgo.fit(trainset)\n",
    "nmfpredictions = nmfalgo.test(testset[:200])\n",
    "\n",
    "print(accuracy.rmse(nmfpredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0146\n",
      "1.0146300424898553\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Part 5D - train the model using KNNBaseline Item-item similarity algoirthm \n",
    "'''\n",
    "\n",
    "sim_options = {'name': 'pearson_baseline', 'user_based': False}\n",
    "itemAlgo = KNNBaseline(sim_options=sim_options)\n",
    "itemAlgo.fit(trainset)\n",
    "itempredictions = itemAlgo.test(testset[:200])\n",
    "print(accuracy.rmse(itempredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8877\n",
      "0.8877278792589097\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Part 5E - train the model using KNNBaseline User-User similarity algoirthm \n",
    "'''\n",
    "\n",
    "sim_options = {'name': 'pearson_baseline', 'user_based': True}\n",
    "userAlgo = KNNBaseline(sim_options=sim_options)\n",
    "userAlgo.fit(trainset)\n",
    "itempredictions = userAlgo.test(testset[:200])\n",
    "print(accuracy.rmse(itempredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "RMSE: 0.9501\n",
      "0.9500616452613694\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Part 5F - train the model using BaselineOnly algoirthm \n",
    "'''\n",
    "\n",
    "bsl_options = {'method': 'als',\n",
    "               'n_epochs': 5,\n",
    "               'reg_u': 12,\n",
    "               'reg_i': 5\n",
    "               }\n",
    "baseline_algo = BaselineOnly(bsl_options=bsl_options)\n",
    "baseline_algo.fit(trainset)\n",
    "itempredictions = baseline_algo.test(testset[:200])\n",
    "print(accuracy.rmse(itempredictions))\n",
    "# cross_validate(baseline_algo, data, measures=['RMSE'], cv=3, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Attempted_range value:  1\n",
      "for 2148  and  6257 and  1  attemted_range calcualted with value:  1  :  1\n",
      "for 1937  and  2451 and  2  attemted_range calcualted with value:  2  :  1\n",
      "for 2451  and  751 and  2  attemted_range calcualted with value:  2  :  3\n",
      "for 3356  and  1292 and  1  attemted_range calcualted with value:  1  :  2\n",
      "for 3441  and  4675 and  1  attemted_range calcualted with value:  1  :  1\n",
      "for 1909  and  6299 and  4  attemted_range calcualted with value:  4  :  5\n",
      "for 611  and  1954 and  1  attemted_range calcualted with value:  1  :  1\n",
      "for 2253  and  4015 and  2  attemted_range calcualted with value:  2  :  2\n",
      "for 105  and  2755 and  4  attemted_range calcualted with value:  4  :  1\n",
      "for 2937  and  1581 and  2  attemted_range calcualted with value:  2  :  1\n",
      "for 1467  and  2610 and  2  attemted_range calcualted with value:  2  :  1\n",
      "for 1829  and  1614 and  4  attemted_range calcualted with value:  4  :  1\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Part 6A - Model Prediction using cosine similarity\n",
    "\n",
    "Following are steps to predict 'attempted_ranges' for given user id and problem id -\n",
    "\n",
    "A. Get the similar User IDs and Problems IDs for given user id and problem id respectively.\n",
    "\n",
    "B. If final_df contains given user id and problem id then return its correponding 'attempted_ranges' column value\n",
    "\n",
    "C. If not, then get the 'attempted_ranges' column value for each combination of user id and similar problem ids from final_df\n",
    "    and compute mean of all 'attempted_ranges'  values\n",
    "    \n",
    "D. If final_df doesn't contain user id and simialar problem ids combination, then get the 'attempted_ranges' column value for each \n",
    "    combination of problem id and similar user ids from final_df and compute mean of all 'attempted_ranges'  values\n",
    "\n",
    "E. if final_df doesn't contain problem id and simialar user id combination then get the 'attempted_ranges' column value for each \n",
    "    combination of similar problem ids and similar user ids from final_df and compute mean of all 'attempted_ranges'  values\n",
    "\n",
    "C. If not, then return default 'attempted_range' value \n",
    "    \n",
    "'''\n",
    "\n",
    "def get_recommendations(user_id, problem_id):\n",
    "    user_idx = user_indices[user_id]\n",
    "    problem_idx = problem_indices[problem_id]\n",
    "    \n",
    "    user_sim_scores = list(enumerate(user_cosine_similarity[user_idx]))\n",
    "    user_sim_scores = sorted(user_sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    user_sim_scores = user_sim_scores[1:30]\n",
    "    \n",
    "    problem_sim_scores = list(enumerate(problem_cosine_similarity[problem_idx]))\n",
    "    problem_sim_scores = sorted(problem_sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    problem_sim_scores = problem_sim_scores[1:30]\n",
    "    \n",
    "    user_top_indices = [i[0] for i in user_sim_scores]\n",
    "    \n",
    "    similar_user_ids = user_ids.iloc[user_top_indices]\n",
    "    \n",
    "    total_attempted_range = []\n",
    "    for userid in similar_user_ids:\n",
    "        attempted_ranges = final_df[(final_df['user_id'] == userid) & (final_df['problem_id'] == problem_id)]['attempts_range'].values\n",
    "        if len(attempted_ranges) > 0:\n",
    "            total_attempted_range.append(attempted_ranges[0])\n",
    "    \n",
    "    compute_avg_attempted_range = 0.0\n",
    "    if len(total_attempted_range) > 0:\n",
    "        compute_avg_attempted_range = mean(total_attempted_range)\n",
    "        # print('for', user_id, ' and ', problem_id, ' attemted_range calcualted via user similarity with value: ', compute_avg_attempted_range)\n",
    "    else:\n",
    "        problem_top_indices = [i[0] for i in problem_sim_scores]\n",
    "        similar_problem_ids = problem_ids.iloc[problem_top_indices]\n",
    "        \n",
    "        for problemid in similar_problem_ids:\n",
    "            attempted_ranges = final_df[(final_df['user_id'] == user_id) & (final_df['problem_id'] == problemid)]['attempts_range'].values\n",
    "            if len(attempted_ranges) > 0:\n",
    "                total_attempted_range.append(attempted_ranges[0])\n",
    "        \n",
    "        if len(total_attempted_range) > 0:\n",
    "            compute_avg_attempted_range = mean(total_attempted_range)\n",
    "            # print('for', user_id, ' and ', problem_id, ' attemted_range calcualted via problem similarity with value: ', compute_avg_attempted_range)\n",
    "        else:\n",
    "            for userid in similar_user_ids:\n",
    "                for problemid in similar_problem_ids:\n",
    "                    attempted_ranges = final_df[(final_df['user_id'] == userid) & (final_df['problem_id'] == problemid)]['attempts_range'].values\n",
    "                    if len(attempted_ranges) > 0:\n",
    "                        total_attempted_range.append(attempted_ranges[0])\n",
    "            \n",
    "            if len(total_attempted_range) > 0:\n",
    "                compute_avg_attempted_range = mean(total_attempted_range)\n",
    "                # print('for', user_id, ' and ', problem_id, ' attemted_range calcualted via user-problem similarity with value: ', compute_avg_attempted_range)\n",
    "            else:\n",
    "                print('there is no matching user and problem')\n",
    "    \n",
    "    # compute_avg_attempted_range = mean(compute_avg_attempted_range)\n",
    "    if (float(compute_avg_attempted_range) % 1) >= 0.5:\n",
    "        compute_avg_attempted_range = math.ceil(compute_avg_attempted_range)\n",
    "    else:\n",
    "        compute_avg_attempted_range = math.floor(compute_avg_attempted_range)\n",
    "    return compute_avg_attempted_range\n",
    "\n",
    "\n",
    "# Test for single record where user_id is 2570 and problem_id is 6267\n",
    "print('Predicted Attempted_range value: ', get_recommendations(2570, 6267))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(train_submissions,\n",
    "                                   test_size=0.20,\n",
    "                                   random_state=42)\n",
    "predicted_rating = []\n",
    "\n",
    "#lets predict for first 10 test records\n",
    "test1_df = test_df[:10]\n",
    "for index, row in test1_df.iterrows():\n",
    "    atempt_range = get_recommendations(row['user_id'], row['problem_id'])\n",
    "    print('for', row['user_id'], ' and ', row['problem_id'], 'and ', row['attempts_range'], ' attemted_range calcualted with value: ', row['attempts_range'] , ' : ' , atempt_range)\n",
    "    predicted_rating.append(atempt_range)\n",
    "\n",
    "test1_df['predicted_rating'] = predicted_rating\n",
    "test1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Part-6B - use cosine similarity and baseline Algorithm to predict the 'attempted_range' value for given user id and problem id\n",
    "'''\n",
    "\n",
    "def get_recommendations_baseline(user_id, problem_id):\n",
    "    user_idx = user_indices[user_id]\n",
    "    problem_idx = problem_indices[problem_id]\n",
    "    \n",
    "    user_sim_scores = list(enumerate(user_cosine_similarity[user_idx]))\n",
    "    user_sim_scores = sorted(user_sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    user_sim_scores = user_sim_scores[1:30]\n",
    "    \n",
    "    problem_sim_scores = list(enumerate(problem_cosine_similarity[problem_idx]))\n",
    "    problem_sim_scores = sorted(problem_sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    problem_sim_scores = problem_sim_scores[1:30]\n",
    "    \n",
    "    user_top_indices = [i[0] for i in user_sim_scores]\n",
    "    similar_user_ids = user_ids.iloc[user_top_indices]\n",
    "    \n",
    "    problem_top_indices = [i[0] for i in problem_sim_scores]\n",
    "    similar_problem_ids = problem_ids.iloc[problem_top_indices]\n",
    "    \n",
    "    total_attempted_range = []\n",
    "    '''\n",
    "    for problemid in similar_problem_ids:\n",
    "        total_attempted_range.append(baseline_algo.predict(user_id, problemid).est)\n",
    "    '''\n",
    "    \n",
    "    for userid in similar_user_ids:\n",
    "        total_attempted_range.append(baseline_algo.predict(userid, problem_id).est)\n",
    "    \n",
    "    compute_avg_attempted_range = mean(total_attempted_range)\n",
    "    if (float(compute_avg_attempted_range) % 1) >= 0.5:\n",
    "        compute_avg_attempted_range = math.ceil(compute_avg_attempted_range)\n",
    "    else:\n",
    "        compute_avg_attempted_range = math.floor(compute_avg_attempted_range)\n",
    "    \n",
    "    return compute_avg_attempted_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Part-6C - use cosine similarity and coclustering Algorithm to predict the 'attempted_range' value for given user id and problem id\n",
    "'''\n",
    "\n",
    "def get_recommendations_coclustering(user_id, problem_id):\n",
    "    user_idx = user_indices[user_id]\n",
    "    problem_idx = problem_indices[problem_id]\n",
    "    \n",
    "    user_sim_scores = list(enumerate(user_cosine_similarity[user_idx]))\n",
    "    user_sim_scores = sorted(user_sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    user_sim_scores = user_sim_scores[1:30]\n",
    "    \n",
    "    problem_sim_scores = list(enumerate(problem_cosine_similarity[problem_idx]))\n",
    "    problem_sim_scores = sorted(problem_sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    problem_sim_scores = problem_sim_scores[1:30]\n",
    "    \n",
    "    user_top_indices = [i[0] for i in user_sim_scores]\n",
    "    similar_user_ids = user_ids.iloc[user_top_indices]\n",
    "    \n",
    "    problem_top_indices = [i[0] for i in problem_sim_scores]\n",
    "    similar_problem_ids = problem_ids.iloc[problem_top_indices]\n",
    "    \n",
    "    total_attempted_range = []\n",
    "    '''\n",
    "    for problemid in similar_problem_ids:\n",
    "        total_attempted_range.append(baseline_algo.predict(user_id, problemid).est)\n",
    "    '''\n",
    "    \n",
    "    for userid in similar_user_ids:\n",
    "        total_attempted_range.append(CoClusteringalgo.predict(userid, problem_id).est)\n",
    "    \n",
    "    compute_avg_attempted_range = mean(total_attempted_range)\n",
    "    if (float(compute_avg_attempted_range) % 1) >= 0.5:\n",
    "        compute_avg_attempted_range = math.ceil(compute_avg_attempted_range)\n",
    "    else:\n",
    "        compute_avg_attempted_range = math.floor(compute_avg_attempted_range)\n",
    "    \n",
    "    return compute_avg_attempted_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Part-6D - use cosine similarity and knnbaseline_item Algorithm to predict the 'attempted_range' value for given user id and problem id\n",
    "'''\n",
    "\n",
    "def get_recommendations_knnbaseline_item(user_id, problem_id):\n",
    "    user_idx = user_indices[user_id]\n",
    "    problem_idx = problem_indices[problem_id]\n",
    "    \n",
    "    user_sim_scores = list(enumerate(user_cosine_similarity[user_idx]))\n",
    "    user_sim_scores = sorted(user_sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    user_sim_scores = user_sim_scores[1:30]\n",
    "    \n",
    "    problem_sim_scores = list(enumerate(problem_cosine_similarity[problem_idx]))\n",
    "    problem_sim_scores = sorted(problem_sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    problem_sim_scores = problem_sim_scores[1:30]\n",
    "    \n",
    "    user_top_indices = [i[0] for i in user_sim_scores]\n",
    "    similar_user_ids = user_ids.iloc[user_top_indices]\n",
    "    \n",
    "    problem_top_indices = [i[0] for i in problem_sim_scores]\n",
    "    similar_problem_ids = problem_ids.iloc[problem_top_indices]\n",
    "    \n",
    "    total_attempted_range = []\n",
    "    \n",
    "    '''\n",
    "    for problemid in similar_problem_ids:\n",
    "        total_attempted_range.append(itemAlgo.predict(user_id, problemid).est)\n",
    "    '''\n",
    "    \n",
    "    for userid in similar_user_ids:\n",
    "        total_attempted_range.append(itemAlgo.predict(userid, problem_id).est)\n",
    "        \n",
    "    compute_avg_attempted_range = mean(total_attempted_range)\n",
    "    if (float(compute_avg_attempted_range) % 1) >= 0.5:\n",
    "        compute_avg_attempted_range = math.ceil(compute_avg_attempted_range)\n",
    "    else:\n",
    "        compute_avg_attempted_range = math.floor(compute_avg_attempted_range)\n",
    "    \n",
    "    return compute_avg_attempted_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Part-6E - use cosine similarity and knnbaseline_user Algorithm to predict the 'attempted_range' value for given user id and problem id\n",
    "'''\n",
    "\n",
    "def get_recommendations_knnbaseline_user(user_id, problem_id):\n",
    "    user_idx = user_indices[user_id]\n",
    "    problem_idx = problem_indices[problem_id]\n",
    "    \n",
    "    user_sim_scores = list(enumerate(user_cosine_similarity[user_idx]))\n",
    "    user_sim_scores = sorted(user_sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    user_sim_scores = user_sim_scores[1:30]\n",
    "    \n",
    "    problem_sim_scores = list(enumerate(problem_cosine_similarity[problem_idx]))\n",
    "    problem_sim_scores = sorted(problem_sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    problem_sim_scores = problem_sim_scores[1:30]\n",
    "    \n",
    "    user_top_indices = [i[0] for i in user_sim_scores]\n",
    "    similar_user_ids = user_ids.iloc[user_top_indices]\n",
    "    \n",
    "    problem_top_indices = [i[0] for i in problem_sim_scores]\n",
    "    similar_problem_ids = problem_ids.iloc[problem_top_indices]\n",
    "    \n",
    "    total_attempted_range = []\n",
    "    '''\n",
    "    for problemid in similar_problem_ids:\n",
    "        total_attempted_range.append(userAlgo.predict(user_id, problemid).est)\n",
    "    '''\n",
    "    \n",
    "    for userid in similar_user_ids:\n",
    "        total_attempted_range.append(userAlgo.predict(userid, problem_id).est)\n",
    "        \n",
    "    compute_avg_attempted_range = mean(total_attempted_range)\n",
    "    if (float(compute_avg_attempted_range) % 1) >= 0.75:\n",
    "        compute_avg_attempted_range = math.ceil(compute_avg_attempted_range)\n",
    "    else:\n",
    "        compute_avg_attempted_range = math.floor(compute_avg_attempted_range)\n",
    "    \n",
    "    return compute_avg_attempted_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Part-6F - use cosine similarity and SVD Algorithm to predict the 'attempted_range' value for given user id and problem id\n",
    "'''\n",
    "\n",
    "def get_recommendations_svd(user_id, problem_id):\n",
    "    user_idx = user_indices[user_id]\n",
    "    problem_idx = problem_indices[problem_id]\n",
    "    \n",
    "    user_sim_scores = list(enumerate(user_cosine_similarity[user_idx]))\n",
    "    user_sim_scores = sorted(user_sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    user_sim_scores = user_sim_scores[1:30]\n",
    "    \n",
    "    problem_sim_scores = list(enumerate(problem_cosine_similarity[problem_idx]))\n",
    "    problem_sim_scores = sorted(problem_sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    problem_sim_scores = problem_sim_scores[1:30]\n",
    "    \n",
    "    user_top_indices = [i[0] for i in user_sim_scores]\n",
    "    similar_user_ids = user_ids.iloc[user_top_indices]\n",
    "    \n",
    "    problem_top_indices = [i[0] for i in problem_sim_scores]\n",
    "    similar_problem_ids = problem_ids.iloc[problem_top_indices]\n",
    "    \n",
    "    total_attempted_range = []\n",
    "    '''\n",
    "    for problemid in similar_problem_ids:\n",
    "        total_attempted_range.append(svdalgo.predict(user_id, problemid).est)\n",
    "    '''\n",
    "    \n",
    "    for userid in similar_user_ids:\n",
    "        total_attempted_range.append(svdalgo.predict(userid, problem_id).est)\n",
    "        \n",
    "    compute_avg_attempted_range = mean(total_attempted_range)\n",
    "    if (float(compute_avg_attempted_range) % 1) >= 0.5:\n",
    "        compute_avg_attempted_range = math.ceil(compute_avg_attempted_range)\n",
    "    else:\n",
    "        compute_avg_attempted_range = math.floor(compute_avg_attempted_range)\n",
    "    \n",
    "    return compute_avg_attempted_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Part-6G - use cosine similarity and NMF Algorithm to predict the 'attempted_range' value for given user id and problem id\n",
    "'''\n",
    "\n",
    "def get_recommendations_nmf(user_id, problem_id):\n",
    "    user_idx = user_indices[user_id]\n",
    "    problem_idx = problem_indices[problem_id]\n",
    "    \n",
    "    user_sim_scores = list(enumerate(user_cosine_similarity[user_idx]))\n",
    "    user_sim_scores = sorted(user_sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    user_sim_scores = user_sim_scores[1:30]\n",
    "    \n",
    "    problem_sim_scores = list(enumerate(problem_cosine_similarity[problem_idx]))\n",
    "    problem_sim_scores = sorted(problem_sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    problem_sim_scores = problem_sim_scores[1:30]\n",
    "    \n",
    "    user_top_indices = [i[0] for i in user_sim_scores]\n",
    "    similar_user_ids = user_ids.iloc[user_top_indices]\n",
    "    \n",
    "    problem_top_indices = [i[0] for i in problem_sim_scores]\n",
    "    similar_problem_ids = problem_ids.iloc[problem_top_indices]\n",
    "    \n",
    "    total_attempted_range = []\n",
    "    '''\n",
    "    for problemid in similar_problem_ids:\n",
    "        total_attempted_range.append(nmfalgo.predict(user_id, problemid).est)\n",
    "    '''\n",
    "    \n",
    "    for userid in similar_user_ids:\n",
    "        total_attempted_range.append(nmfalgo.predict(userid, problem_id).est)\n",
    "        \n",
    "    compute_avg_attempted_range = mean(total_attempted_range)\n",
    "    if (float(compute_avg_attempted_range) % 1) >= 0.66:\n",
    "        compute_avg_attempted_range = math.ceil(compute_avg_attempted_range)\n",
    "    else:\n",
    "        compute_avg_attempted_range = math.floor(compute_avg_attempted_range)\n",
    "    \n",
    "    return compute_avg_attempted_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 7A-  Predict 'attemped_range' for test data via calling SVD algorithm function\n",
    "\n",
    "train_df, test_df = train_test_split(train_submissions,\n",
    "                                   test_size=0.20,\n",
    "                                   random_state=42)\n",
    "\n",
    "predicted_rating = []\n",
    "test1_df = test_df\n",
    "for index, row in test1_df.iterrows():\n",
    "    atempt_range = get_recommendations_svd(row['user_id'], row['problem_id'])\n",
    "    predicted_rating.append(atempt_range)\n",
    "\n",
    "test1_df['predicted_rating'] = predicted_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 7B-  Predict 'attemped_range' for test data via calling NMF algorithm function\n",
    "\n",
    "\n",
    "train_df, test_df = train_test_split(train_submissions,\n",
    "                                   test_size=0.20,\n",
    "                                   random_state=42)\n",
    "\n",
    "predicted_rating = []\n",
    "test1_df = test_df\n",
    "for index, row in test1_df.iterrows():\n",
    "    atempt_range = get_recommendations_nmf(row['user_id'], row['problem_id'])\n",
    "    print('for', row['user_id'], ' and ', row['problem_id'], 'and ', row['attempts_range'], ' attemted_range calcualted with value: ', row['attempts_range'] , ' : ' , atempt_range)\n",
    "    predicted_rating.append(atempt_range)\n",
    "\n",
    "test1_df['predicted_rating'] = predicted_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_avg_attempted_range in ciel:  2\n",
      "for 573  and  6203 and  1  attemted_range calcualted with value:  1  :  2\n",
      "compute_avg_attempted_range in ciel:  2\n",
      "for 2044  and  5173 and  2  attemted_range calcualted with value:  2  :  2\n",
      "compute_avg_attempted_range in floor:  1\n",
      "for 1327  and  4878 and  1  attemted_range calcualted with value:  1  :  1\n",
      "compute_avg_attempted_range in ciel:  2\n",
      "for 3159  and  3849 and  1  attemted_range calcualted with value:  1  :  2\n",
      "compute_avg_attempted_range in ciel:  2\n",
      "for 1329  and  5317 and  2  attemted_range calcualted with value:  2  :  2\n",
      "compute_avg_attempted_range in floor:  2\n",
      "for 216  and  4335 and  1  attemted_range calcualted with value:  1  :  2\n",
      "for 2772  and  4514 and  3  attemted_range calcualted with value:  3  :  2\n",
      "for 2757  and  5095 and  1  attemted_range calcualted with value:  1  :  2\n",
      "for 555  and  965 and  1  attemted_range calcualted with value:  1  :  2\n",
      "for 1272  and  4989 and  1  attemted_range calcualted with value:  1  :  1\n",
      "for 1739  and  2579 and  1  attemted_range calcualted with value:  1  :  2\n",
      "for 1776  and  2006 and  2  attemted_range calcualted with value:  2  :  2\n",
      "for 2551  and  6358 and  2  attemted_range calcualted with value:  2  :  2\n",
      "for 3313  and  1594 and  1  attemted_range calcualted with value:  1  :  2\n",
      "for 676  and  667 and  2  attemted_range calcualted with value:  2  :  2\n",
      "for 2769  and  1171 and  1  attemted_range calcualted with value:  1  :  2\n",
      "for 1051  and  6069 and  2  attemted_range calcualted with value:  2  :  2\n",
      "for 2355  and  6275 and  3  attemted_range calcualted with value:  3  :  2\n",
      "for 2883  and  3920 and  1  attemted_range calcualted with value:  1  :  2\n",
      "for 647  and  4525 and  1  attemted_range calcualted with value:  1  :  2\n",
      "for 153  and  6227 and  1  attemted_range calcualted with value:  1  :  2\n",
      "for 3166  and  5681 and  2  attemted_range calcualted with value:  2  :  1\n",
      "for 2092  and  5086 and  2  attemted_range calcualted with value:  2  :  2\n",
      "for 400  and  5823 and  1  attemted_range calcualted with value:  1  :  2\n",
      "for 2890  and  3649 and  1  attemted_range calcualted with value:  1  :  3\n",
      "for 2239  and  1806 and  1  attemted_range calcualted with value:  1  :  2\n",
      "for 2909  and  2451 and  1  attemted_range calcualted with value:  1  :  2\n",
      "for 1570  and  1303 and  1  attemted_range calcualted with value:  1  :  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\618757\\Anaconda3\\envs\\mypika\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Part 7C-  Predict 'attemped_range' for test data via calling knnbaseline_item algorithm function\n",
    "\n",
    "\n",
    "train_df, test_df = train_test_split(train_submissions,\n",
    "                                   test_size=0.20,\n",
    "                                   random_state=42)\n",
    "\n",
    "predicted_rating = []\n",
    "test1_df = test_df\n",
    "for index, row in test1_df.iterrows():\n",
    "    atempt_range = get_recommendations_knnbaseline_item(row['user_id'], row['problem_id'])\n",
    "    print('for', row['user_id'], ' and ', row['problem_id'], 'and ', row['attempts_range'], ' attemted_range calcualted with value: ', row['attempts_range'] , ' : ' , atempt_range)\n",
    "    predicted_rating.append(atempt_range)\n",
    "\n",
    "test1_df['predicted_rating'] = predicted_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.34804726488296467\n",
      "precision_score:  0.8289046374634128\n",
      "recall_score:  0.34804726488296467\n",
      "f1_score::  0.4361536838382517\n"
     ]
    }
   ],
   "source": [
    "#Part 8- Use F1 Score to calculate the model accuracy\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "accuracy_score = metrics.accuracy_score(test1_df['predicted_rating'], test1_df['attempts_range'])\n",
    "precision_score = metrics.precision_score(test1_df['predicted_rating'], test1_df['attempts_range'], average='weighted')\n",
    "recall_score = metrics.recall_score(test1_df['predicted_rating'], test1_df['attempts_range'], average='weighted')\n",
    "f1_score = metrics.f1_score(test1_df['predicted_rating'], test1_df['attempts_range'], average='weighted')\n",
    "\n",
    "print('accuracy_score: ', accuracy_score)\n",
    "print('precision_score: ', precision_score)\n",
    "print('recall_score: ', recall_score)\n",
    "print('f1_score:: ', f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part-9 -  Load the test data against which model is going to be vvalidated\n",
    "\n",
    "test = pd.read_csv('analytics_vidhya_recommendataion_engine_data/test_submissions_NeDLEvX.csv', sep=',', error_bad_lines=False, encoding=\"latin-1\")\n",
    "sample_submission = pd.read_csv('analytics_vidhya_recommendataion_engine_data/sample_submissions_wbscxqU.csv', sep=',', error_bad_lines=False, encoding=\"latin-1\")\n",
    "\n",
    "test['problem_id'] = le_problem_id.transform(test['problem_id'])\n",
    "test['user_id'] = le_user_id.transform(test['user_id'])\n",
    "\n",
    "sample_submission['ID'] = test['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part-10 -  Use knnbaseline_user algorithm for prediction and export the result into CSV file\n",
    "predicted_attempt_range = []\n",
    "for index, row in test.iterrows():\n",
    "    attempt_range = get_recommendations_knnbaseline_user(row['user_id'], row['problem_id'])\n",
    "    predicted_attempt_range.append(attempt_range)\n",
    "\n",
    "sample_submission['attempts_range'] = predicted_attempt_range\n",
    "export_csv = sample_submission.to_csv (r'test_predictions_knnbaseline_user_75_1.csv', sep=',', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypika",
   "language": "python",
   "name": "mypika"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
