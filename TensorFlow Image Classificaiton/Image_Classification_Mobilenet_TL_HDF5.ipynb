{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Image_Classification_Mobilenet_TL_HDF5.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"UDIeqEy83ONx","colab_type":"code","colab":{}},"source":["import matplotlib\n","!pip install imutils\n","!pip install opencv-python\n","!pip install q keras==2.3.0\n","!pip install tensorflow_hub"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H4TB9iOU65cL","colab_type":"code","outputId":"606691cd-54df-4ce2-b0ac-09a998df7712","executionInfo":{"status":"ok","timestamp":1585849411222,"user_tz":300,"elapsed":366,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import keras\n","keras.__version__"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.3.0'"]},"metadata":{"tags":[]},"execution_count":73}]},{"cell_type":"code","metadata":{"id":"Grmxcjd23eap","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.optimizers import SGD\n","from keras.utils import np_utils\n","from imutils import paths\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import argparse\n","import cv2\n","import os\n","import h5py\n","import matplotlib\n","import pickle\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from random import shuffle\n","import glob\n","import numpy as np\n","import h5py\n","import cv2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oGlBlEnI3iYP","colab_type":"code","outputId":"589798e1-c370-4b3d-aa57-40d44bfe0eb7","executionInfo":{"status":"ok","timestamp":1585849416912,"user_tz":300,"elapsed":722,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nXkPIfS53wrh","colab_type":"code","outputId":"9604cbf0-647a-4413-a004-af7b87eef556","executionInfo":{"status":"ok","timestamp":1585854773362,"user_tz":300,"elapsed":517,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["hdf5_path = '/content/drive/My Drive/VideoTestCases/VideoTestCases224V5.hdf5'\n","dataset = h5py.File(hdf5_path, \"r\")\n","print(dataset[\"train_labels\"].shape)\n","train_labels=np.array(dataset[\"train_labels\"])\n","unique_lables_set = set(train_labels) \n","\n","train_labels = train_labels.reshape((len(train_labels),-1))\n","train_batch_labels=train_labels\n","\n","unique_labels_list = (list(unique_lables_set))\n","\n","print(len(unique_labels_list))\n","print(unique_labels_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(3615,)\n","3\n","[0, 1, 2]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0_vfBHZZ-doA","colab_type":"code","outputId":"20bf3e5c-5196-4953-af69-4f79d6d77a21","executionInfo":{"status":"ok","timestamp":1585854776470,"user_tz":300,"elapsed":547,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(dataset[\"train_labels\"].shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(3615,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sqh7fMBo4GLS","colab_type":"code","outputId":"9e24a1b2-ae08-4106-9894-07a9e47475ba","executionInfo":{"status":"ok","timestamp":1585854780191,"user_tz":300,"elapsed":1796,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["train_img=np.array(dataset[\"train_img\"])\n","#train_img = train_img.reshape((len(train_img),-1))\n","print(len(train_img))\n","train_img[0].shape"],"execution_count":0,"outputs":[{"output_type":"stream","text":["3615\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(224, 224, 3)"]},"metadata":{"tags":[]},"execution_count":111}]},{"cell_type":"code","metadata":{"id":"7oS-KBQ94PHb","colab_type":"code","outputId":"4c9b2e00-3d03-4b94-ecfc-89022afe0d08","executionInfo":{"status":"ok","timestamp":1585854790207,"user_tz":300,"elapsed":7946,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["train_batch_imgs=[]\n","for i in range(len(train_batch_labels)):\n","   img=(dataset['train_img'])[i]\n","   img=img/255.\n","   train_batch_imgs.append(img)    \n","train_batch_imgs=np.array(train_batch_imgs)\n","train_batch_imgs[0].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(224, 224, 3)"]},"metadata":{"tags":[]},"execution_count":112}]},{"cell_type":"code","metadata":{"id":"-cP6y1K-4dH8","colab_type":"code","colab":{}},"source":["INIT_LR = 1e-1\n","BS = 15\n","EPOCHS = 50\n","\n","data = train_batch_imgs\n","labels = train_batch_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nsxdPlpRbFag","colab_type":"code","outputId":"4d0e41fd-b907-49a9-f49b-22a2ce025b78","executionInfo":{"status":"ok","timestamp":1585854813084,"user_tz":300,"elapsed":477,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["le = LabelEncoder()\n","labels = le.fit_transform(labels)\n","labels = np_utils.to_categorical(labels, 3)\n","with open('/content/drive/My Drive/3kImages/label_encoder_file_0402.pkl', 'wb') as fid:\n","    pickle.dump(le, fid)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"VDQYn12U4ryy","colab_type":"code","outputId":"78c878e7-cd74-438b-d349-b3f73e64fed8","executionInfo":{"status":"ok","timestamp":1585854820682,"user_tz":300,"elapsed":5436,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)\n","trainX[0].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(224, 224, 3)"]},"metadata":{"tags":[]},"execution_count":115}]},{"cell_type":"code","metadata":{"id":"1UBDJiCo4v43","colab_type":"code","outputId":"eb4a0620-2069-476e-ae9b-ca07b8eda771","executionInfo":{"status":"ok","timestamp":1585854822860,"user_tz":300,"elapsed":696,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(\"[INFO] performing 'on the fly' data augmentation\")\n","aug = ImageDataGenerator(\n","    rotation_range=20, zoom_range=0.15, width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.15,\n","    horizontal_flip=True,\n","    fill_mode=\"nearest\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[INFO] performing 'on the fly' data augmentation\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Dnlonj3SZlcT","colab_type":"code","outputId":"81497167-1f87-4930-f8eb-d612c7865987","executionInfo":{"status":"ok","timestamp":1585854828494,"user_tz":300,"elapsed":3043,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":277}},"source":["print(\"[INFO] compiling model...\")\n","model = tf.keras.Sequential([ hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\",\n","                              output_shape=[1280], trainable=False), tf.keras.layers.Dropout(0.4),\n","                              tf.keras.layers.Dense(len(unique_labels_list), activation='softmax')])\n","model.build([None, 224, 224, 3])\n","model.summary()\n","\n","model.compile(\n","      optimizer=tf.keras.optimizers.Adam(),\n","      loss='categorical_crossentropy',\n","      metrics=['acc'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[INFO] compiling model...\n","Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","keras_layer_7 (KerasLayer)   multiple                  2257984   \n","_________________________________________________________________\n","dropout_7 (Dropout)          multiple                  0         \n","_________________________________________________________________\n","dense_6 (Dense)              multiple                  3843      \n","=================================================================\n","Total params: 2,261,827\n","Trainable params: 3,843\n","Non-trainable params: 2,257,984\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YXp3BWXD43ct","colab_type":"code","outputId":"86a3d0d8-5900-4a3a-bcf8-2950cf9d60e6","executionInfo":{"status":"error","timestamp":1585856204897,"user_tz":300,"elapsed":1374166,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["print(\"[INFO] training network for {} epochs...\".format(EPOCHS))\n","H = model.fit_generator(\n","    aug.flow(trainX, trainY, batch_size=BS),\n","    validation_data=(testX, testY),\n","    steps_per_epoch=len(trainX) // BS,\n","    epochs=EPOCHS)\n","\n","print(H)\n","\n","model.save(\"/content/drive/My Drive/3kImages/models/ImageQualityV11.h5\")\n","model.save_weights(\"/content/drive/My Drive/3kImages/models/ImageQualityV11Weights.h5\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[INFO] training network for 50 epochs...\n","Epoch 1/50\n","180/180 [==============================] - 38s 209ms/step - loss: 1.3547 - acc: 0.4026 - val_loss: 1.1262 - val_acc: 0.4679\n","Epoch 2/50\n","180/180 [==============================] - 36s 202ms/step - loss: 1.2889 - acc: 0.4169 - val_loss: 1.2151 - val_acc: 0.3319\n","Epoch 3/50\n","180/180 [==============================] - 36s 202ms/step - loss: 1.2201 - acc: 0.4169 - val_loss: 1.1129 - val_acc: 0.3883\n","Epoch 4/50\n","180/180 [==============================] - 36s 200ms/step - loss: 1.1818 - acc: 0.4243 - val_loss: 1.0658 - val_acc: 0.4701\n","Epoch 5/50\n","180/180 [==============================] - 36s 198ms/step - loss: 1.1393 - acc: 0.4336 - val_loss: 1.1178 - val_acc: 0.3750\n","Epoch 6/50\n","180/180 [==============================] - 37s 207ms/step - loss: 1.1427 - acc: 0.4329 - val_loss: 1.1104 - val_acc: 0.3507\n","Epoch 7/50\n","180/180 [==============================] - 36s 199ms/step - loss: 1.1399 - acc: 0.4321 - val_loss: 1.0619 - val_acc: 0.4425\n","Epoch 8/50\n","180/180 [==============================] - 37s 203ms/step - loss: 1.1389 - acc: 0.4310 - val_loss: 1.1285 - val_acc: 0.5188\n","Epoch 9/50\n","180/180 [==============================] - 37s 205ms/step - loss: 1.1314 - acc: 0.4295 - val_loss: 1.2632 - val_acc: 0.5155\n","Epoch 10/50\n","180/180 [==============================] - 36s 199ms/step - loss: 1.1242 - acc: 0.4358 - val_loss: 1.1244 - val_acc: 0.3783\n","Epoch 11/50\n","180/180 [==============================] - 37s 204ms/step - loss: 1.1094 - acc: 0.4451 - val_loss: 1.0813 - val_acc: 0.4569\n","Epoch 12/50\n","180/180 [==============================] - 37s 205ms/step - loss: 1.1085 - acc: 0.4455 - val_loss: 1.0878 - val_acc: 0.4049\n","Epoch 13/50\n","180/180 [==============================] - 35s 197ms/step - loss: 1.1170 - acc: 0.4288 - val_loss: 1.0792 - val_acc: 0.4535\n","Epoch 14/50\n","180/180 [==============================] - 35s 193ms/step - loss: 1.1183 - acc: 0.4477 - val_loss: 1.0825 - val_acc: 0.4369\n","Epoch 15/50\n","180/180 [==============================] - 35s 197ms/step - loss: 1.1149 - acc: 0.4321 - val_loss: 1.0760 - val_acc: 0.4535\n","Epoch 16/50\n","180/180 [==============================] - 38s 209ms/step - loss: 1.1184 - acc: 0.4340 - val_loss: 1.0635 - val_acc: 0.4513\n","Epoch 17/50\n","180/180 [==============================] - 36s 202ms/step - loss: 1.1211 - acc: 0.4384 - val_loss: 1.0948 - val_acc: 0.3883\n","Epoch 18/50\n","180/180 [==============================] - 36s 202ms/step - loss: 1.0962 - acc: 0.4421 - val_loss: 1.0852 - val_acc: 0.4967\n","Epoch 19/50\n","180/180 [==============================] - 36s 199ms/step - loss: 1.1027 - acc: 0.4343 - val_loss: 1.0503 - val_acc: 0.4613\n","Epoch 20/50\n","180/180 [==============================] - 36s 199ms/step - loss: 1.0931 - acc: 0.4596 - val_loss: 1.0846 - val_acc: 0.4524\n","Epoch 21/50\n","180/180 [==============================] - 36s 201ms/step - loss: 1.1001 - acc: 0.4414 - val_loss: 1.0920 - val_acc: 0.4049\n","Epoch 22/50\n","180/180 [==============================] - 36s 199ms/step - loss: 1.1190 - acc: 0.4407 - val_loss: 1.1289 - val_acc: 0.3606\n","Epoch 23/50\n","180/180 [==============================] - 36s 202ms/step - loss: 1.1210 - acc: 0.4314 - val_loss: 1.0957 - val_acc: 0.4956\n","Epoch 24/50\n","180/180 [==============================] - 36s 198ms/step - loss: 1.0922 - acc: 0.4536 - val_loss: 1.0631 - val_acc: 0.4989\n","Epoch 25/50\n","180/180 [==============================] - 36s 198ms/step - loss: 1.1119 - acc: 0.4470 - val_loss: 1.0851 - val_acc: 0.4369\n","Epoch 26/50\n","180/180 [==============================] - 36s 199ms/step - loss: 1.1004 - acc: 0.4484 - val_loss: 1.0882 - val_acc: 0.4215\n","Epoch 27/50\n","180/180 [==============================] - 36s 203ms/step - loss: 1.1337 - acc: 0.4284 - val_loss: 1.0970 - val_acc: 0.5166\n","Epoch 28/50\n","180/180 [==============================] - 36s 203ms/step - loss: 1.1066 - acc: 0.4470 - val_loss: 1.0973 - val_acc: 0.4790\n","Epoch 29/50\n","180/180 [==============================] - 37s 203ms/step - loss: 1.0986 - acc: 0.4488 - val_loss: 1.0856 - val_acc: 0.3872\n","Epoch 30/50\n","180/180 [==============================] - 36s 198ms/step - loss: 1.0926 - acc: 0.4455 - val_loss: 1.0482 - val_acc: 0.4558\n","Epoch 31/50\n","180/180 [==============================] - 37s 204ms/step - loss: 1.1305 - acc: 0.4280 - val_loss: 1.0561 - val_acc: 0.4425\n","Epoch 32/50\n","180/180 [==============================] - 35s 197ms/step - loss: 1.1057 - acc: 0.4451 - val_loss: 1.0985 - val_acc: 0.3971\n","Epoch 33/50\n","180/180 [==============================] - 36s 197ms/step - loss: 1.1292 - acc: 0.4225 - val_loss: 1.0816 - val_acc: 0.4259\n","Epoch 34/50\n","180/180 [==============================] - 37s 203ms/step - loss: 1.1020 - acc: 0.4466 - val_loss: 1.0787 - val_acc: 0.4768\n","Epoch 35/50\n","180/180 [==============================] - 37s 203ms/step - loss: 1.1285 - acc: 0.4236 - val_loss: 1.0906 - val_acc: 0.3993\n","Epoch 36/50\n","180/180 [==============================] - 37s 204ms/step - loss: 1.1184 - acc: 0.4440 - val_loss: 1.0909 - val_acc: 0.4447\n","Epoch 37/50\n","180/180 [==============================] - 37s 206ms/step - loss: 1.1063 - acc: 0.4343 - val_loss: 1.0528 - val_acc: 0.4900\n","Epoch 38/50\n","139/180 [======================>.......] - ETA: 7s - loss: 1.1184 - acc: 0.4296"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-118-bd1e024023aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     epochs=EPOCHS)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1416\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m   @deprecation.deprecated(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    784\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"f1j3u5MeajEd","colab_type":"code","colab":{}},"source":["from keras import models\n","#new_model = models.load_model('/content/drive/My Drive/3kImages/models/ImageQualityX1.h5')\n","new_model = tf.keras.models.load_model('/content/drive/My Drive/3kImages/models/ImageQualityX1.h5',custom_objects={'KerasLayer':hub.KerasLayer})\n","new_model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5m57U0Ef80PJ","colab_type":"code","colab":{}},"source":["test_image = image.load_img('/content/drive/My Drive/VideoTestCases/test/Normal/TAJframe3427.jpg', target_size = (224, 224))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis = 0)\n","test_image = test_image/255\n","\n","print(test_image.shape)\n","\n","result = new_model.predict(test_image)\n","print(result)\n","#predict_proba = new_model.predict_proba(test_image)\n","prediction_result = np.argmax(result[0])\n","print(prediction_result)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f83X6VcGayl-","colab_type":"code","colab":{}},"source":["from keras.models import load_model\n","from keras.preprocessing import image\n","import numpy as np\n","import os\n","\n","# image folder\n","folder_path = '/content/drive/My Drive/3kImages/miniTest/MacroBlocking'\n","# path to model\n","model_path = '/path/to/saved/model.h5'\n","# dimensions of images\n","img_width, img_height = 224, 224\n","\n","\n","# load all images into a list\n","images = []\n","for img in os.listdir(folder_path):\n","    img = os.path.join(folder_path, img)\n","    img = image.load_img(img, target_size=(img_width, img_height))\n","    img = image.img_to_array(img)\n","    img = np.expand_dims(img, axis=0)\n","    images.append(img)\n","    #print(img)\n","\n","# stack up images list to pass for prediction\n","images = np.vstack(images)\n","classes = new_model.predict_classes(images, batch_size=10)\n","print(classes)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wYCuGVVRaq-W","colab_type":"code","colab":{}},"source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","data_root='/content/drive/My Drive/VideoTestCases/test'\n","\n","IMAGE_SHAPE = (224, 224)\n","TRAINING_DATA_DIR = str(data_root)\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","test_set = test_datagen.flow_from_directory(directory=TRAINING_DATA_DIR, target_size = (224, 224),\n","                                            batch_size = 876, shuffle=False)\n","\n","sample_training_images, _ = next(test_set)\n","print(test_set.labels[800:815])\n","\n","plt.figure(figsize=(12, 12))\n","\n","def plotImages(images_arr):\n","    fig, axes = plt.subplots(1, 20, figsize=(20,20))\n","    axes = axes.flatten()\n","    for img, ax in zip( images_arr, axes):\n","        ax.imshow(img)\n","        ax.axis('off')\n","    plt.tight_layout()\n","    plt.show()\n","# plotImages(sample_training_images[800:815])\n","\n","for i in range(40):\n","  plt.figure(figsize=(12, 12))\n","  #plt.imshow(sample_training_images[i+800])\n","  #plt.show()\n","\n","total_validate = 44\n","batch_size = 32\n","\n","\n","#predict = new_model.predict(test_set, steps=np.ceil(total_validate/32))\n","\n","print('before running prediction')\n","predict = new_model.predict(sample_training_images)\n","print('after running prediction')\n","predict=np.round(predict,decimals=5)\n","result = map(lambda v : np.argmax(v), predict)\n","prediction_result = np.array(list(result))\n","print(prediction_result[800:815])\n","#print(predict)\n","\n","#test_labels = np.array(np.zeros(44))\n","#print(test_labels.shape)\n","#my_data = (test_set, test_labels)\n","#test_loss, test_acc = new_model.evaluate(my_data)\n","#print(test_acc)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IgQ7S3heaswL","colab_type":"code","colab":{}},"source":["import sklearn.metrics as metrics\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","\n","classification_report = metrics.classification_report(test_set.labels, prediction_result, target_names = test_set.class_indices.keys())\n","print(\"Classification report: \\n\", classification_report)\n","confusion_matrix = metrics.confusion_matrix(test_set.labels, prediction_result)\n","print(\"Confusion matrix: \\n\",confusion_matrix)\n","\n","print(\"Accuracy Score: \", accuracy_score(test_set.labels, prediction_result))\n","print(\"F1 Score: \", f1_score(test_set.labels, prediction_result, average='macro'))\n","print(\"F1 Score: \", f1_score(test_set.labels, prediction_result, average='micro'))\n","print(\"F1 Score: \", f1_score(test_set.labels, prediction_result, average='weighted'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mNa-Pwn-axdc","colab_type":"code","colab":{}},"source":["import cv2\n","from keras.preprocessing import image\n","vidcap = cv2.VideoCapture('/content/drive/My Drive/3kImages/faces_noblur.mp4')\n","print(cv2.__version__)\n","\n","success,img = vidcap.read()\n","count = 0\n","newsize = (224, 224) \n","images = []\n","while success:\n","  img = cv2.resize(img, newsize, interpolation = cv2.INTER_AREA)\n","  img = image.img_to_array(img)\n","  img = np.expand_dims(img, axis = 0)\n","\n","  prediction_probability = new_model.predict(img)\n","  prediction_result = np.argmax(prediction_probability[0])\n","  images.append(prediction_result)\n","  # cv2.imwrite(\"frame%d.jpg\" % count, image)     # save frame as JPEG file\n","\n","  success,img = vidcap.read()\n","  count += 1\n","\n","print('final result')\n","print(images)\n","vidcap.release()\n","cv2.destroyAllWindows()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"caXdPOwb2awU","colab_type":"code","colab":{}},"source":["from keras.layers.normalization import BatchNormalization\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import AveragePooling2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.convolutional import ZeroPadding2D\n","from keras.layers.core import Activation\n","from keras.layers.core import Dense\n","from keras.layers import Flatten\n","from keras.layers import Input\n","from keras.models import Model\n","from keras.layers import add\n","from keras.regularizers import l2\n","from keras import backend as K\n","\n","class ResNet:\n","    @staticmethod\n","    def residual_module(data, K, stride, chanDim, red=False,\n","        reg=0.0001, bnEps=2e-5, bnMom=0.9):\n","        # the shortcut branch of the ResNet module should be\n","        # initialize as the input (identity) data\n","        shortcut = data\n","\n","        # the first block of the ResNet module are the 1x1 CONVs\n","        bn1 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n","            momentum=bnMom)(data)\n","        act1 = Activation(\"relu\")(bn1)\n","        conv1 = Conv2D(int(K * 0.25), (1, 1), use_bias=False,\n","            kernel_regularizer=l2(reg))(act1)\n","\n","        # the second block of the ResNet module are the 3x3 CONVs\n","        bn2 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n","            momentum=bnMom)(conv1)\n","        act2 = Activation(\"relu\")(bn2)\n","        conv2 = Conv2D(int(K * 0.25), (3, 3), strides=stride,\n","            padding=\"same\", use_bias=False,\n","            kernel_regularizer=l2(reg))(act2)\n","\n","        # the third block of the ResNet module is another set of 1x1\n","        # CONVs\n","        bn3 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n","            momentum=bnMom)(conv2)\n","        act3 = Activation(\"relu\")(bn3)\n","        conv3 = Conv2D(K, (1, 1), use_bias=False,\n","            kernel_regularizer=l2(reg))(act3)\n","\n","        # if we are to reduce the spatial size, apply a CONV layer to\n","        # the shortcut\n","        if red:\n","            shortcut = Conv2D(K, (1, 1), strides=stride,\n","                use_bias=False, kernel_regularizer=l2(reg))(act1)\n","\n","        # add together the shortcut and the final CONV\n","        x = add([conv3, shortcut])\n","\n","        # return the addition as the output of the ResNet module\n","        return x\n","\n","    @staticmethod\n","    def build(width, height, depth, classes, stages, filters,\n","        reg=0.0001, bnEps=2e-5, bnMom=0.9):\n","        # initialize the input shape to be \"channels last\" and the\n","        # channels dimension itself\n","        inputShape = (height, width, depth)\n","        chanDim = -1\n","\n","        # if we are using \"channels first\", update the input shape\n","        # and channels dimension\n","        if K.image_data_format() == \"channels_first\":\n","            inputShape = (depth, height, width)\n","            chanDim = 1\n","\n","        # set the input and apply BN\n","        inputs = Input(shape=inputShape)\n","        x = BatchNormalization(axis=chanDim, epsilon=bnEps,\n","            momentum=bnMom)(inputs)\n","\n","        # apply CONV => BN => ACT => POOL to reduce spatial size\n","        x = Conv2D(filters[0], (5, 5), use_bias=False,\n","            padding=\"same\", kernel_regularizer=l2(reg))(x)\n","        x = BatchNormalization(axis=chanDim, epsilon=bnEps,\n","            momentum=bnMom)(x)\n","        x = Activation(\"relu\")(x)\n","        x = ZeroPadding2D((1, 1))(x)\n","        x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n","\n","        # loop over the number of stages\n","        for i in range(0, len(stages)):\n","            # initialize the stride, then apply a residual module\n","            # used to reduce the spatial size of the input volume\n","            stride = (1, 1) if i == 0 else (2, 2)\n","            x = ResNet.residual_module(x, filters[i + 1], stride,\n","                chanDim, red=True, bnEps=bnEps, bnMom=bnMom)\n","\n","            # loop over the number of layers in the stage\n","            for j in range(0, stages[i] - 1):\n","                # apply a ResNet module\n","                x = ResNet.residual_module(x, filters[i + 1],\n","                    (1, 1), chanDim, bnEps=bnEps, bnMom=bnMom)\n","\n","        # apply BN => ACT => POOL\n","        x = BatchNormalization(axis=chanDim, epsilon=bnEps,\n","            momentum=bnMom)(x)\n","        x = Activation(\"relu\")(x)\n","        x = AveragePooling2D((8, 8))(x)\n","\n","        # softmax classifier\n","        x = Flatten()(x)\n","        x = Dense(classes, kernel_regularizer=l2(reg))(x)\n","        x = Activation(\"softmax\")(x)\n","\n","        # create the model\n","        model = Model(inputs, x, name=\"resnet\")\n","\n","        # return the constructed network architecture\n","        return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"harfVxpc414V","colab_type":"code","outputId":"810527a8-734b-49e5-bb0f-d7c7c554ccbf","executionInfo":{"status":"ok","timestamp":1585665135489,"user_tz":300,"elapsed":2512,"user":{"displayName":"Xavier Navarro","photoUrl":"","userId":"02647649664502991915"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["'''\n","opt = SGD(lr=INIT_LR, momentum=0.9, decay=INIT_LR / EPOCHS)\n","model = ResNet.build(144, 256, 3, 3, (2, 3, 4),\n","    (32, 128, 128, 256), reg=0.0001)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n","    metrics=[\"accuracy\"])\n","'''"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[INFO] compiling model...\n"],"name":"stdout"}]}]}