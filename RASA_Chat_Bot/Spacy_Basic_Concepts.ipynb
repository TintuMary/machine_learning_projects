{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greet  :  ['hello', 'hi', 'hey']\n",
      "goodbye  :  ['bye', 'farewell']\n",
      "thankyou  :  ['thank', 'thx']\n"
     ]
    }
   ],
   "source": [
    "patterns = {'greet': ['hello', 'hi', 'hey'], 'goodbye': ['bye', 'farewell'], 'thankyou': ['thank', 'thx']}\n",
    "for intent, key in patterns.items():\n",
    "    print(intent, \" : \", key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_sentences:  3\n",
      "embedding_dim:  300\n"
     ]
    }
   ],
   "source": [
    "sentences = ['Hey', 'Hi', 'How are you']\n",
    "# Calculate the length of sentences\n",
    "n_sentences = len(sentences)\n",
    "print('n_sentences: ', n_sentences)\n",
    "# Calculate the dimensionality of nlp\n",
    "embedding_dim = nlp.vocab.vectors_length\n",
    "print('embedding_dim: ', embedding_dim)\n",
    "# Initialize the array with zeros: X\n",
    "X = np.zeros((n_sentences, embedding_dim))\n",
    "\n",
    "# Iterate over the sentences\n",
    "for idx, sentence in enumerate(sentences):\n",
    "    # Pass each each sentence to the nlp object to create a document\n",
    "    doc = nlp(sentence)\n",
    "    # Save the document's .vector attribute to the corresponding row in X\n",
    "    X[idx, :] = doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DATE': None, 'ORG': None, 'PERSON': None}\n",
      "Marry PERSON\n",
      "Google ORG\n",
      "2001 DATE\n",
      "{'DATE': '2001', 'ORG': 'Google', 'PERSON': 'Marry'}\n",
      "Shanghai  :  Singapore\n",
      "[to, flight]\n",
      "[from, flight]\n",
      "red  :  in\n",
      "red  :  jacket\n",
      "color red belongs to item jacket\n",
      "blue  :  pajama\n",
      "color blue belongs to item pajama\n"
     ]
    }
   ],
   "source": [
    "include_entities = ['DATE', 'ORG', 'PERSON']\n",
    "ents = dict.fromkeys(include_entities)\n",
    "print(ents)\n",
    "doc = nlp(\"My friend Marry is working in Google since 2001\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "    if ent.label_ in include_entities:\n",
    "        ents[ent.label_] = ent.text\n",
    "print(ents)    \n",
    "    \n",
    "doc = nlp('a flight to Shanghai from Singapore')\n",
    "print(doc[3], ' : ', doc[5])\n",
    "shanghai, singapore = doc[3], doc[5]\n",
    "print(list(shanghai.ancestors))\n",
    "print(list(singapore.ancestors))\n",
    "\n",
    "\n",
    "doc = nlp(\"let's see that jacket in red and some blue pajama\")\n",
    "items = [doc[4], doc[10]]  # [jacket, jeans]\n",
    "\n",
    "colors = [doc[6], doc[9]]  # [red, blue]\n",
    "for color in colors:\n",
    "    for tok in color.ancestors:\n",
    "        print(color, \" : \", tok)\n",
    "        if tok in items:\n",
    "            print(\"color {} belongs to item {}\".format(color, tok))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sushi]\n",
      "[pizza]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('not sushi, maybe pizza?')\n",
    "indices = [1, 4]\n",
    "ents, negated_ents = [], []\n",
    "start = 0\n",
    "for i in indices:\n",
    "    phrase = \"{}\".format(doc[start:i])\n",
    "    if \"not\" in phrase or \"n't\" in phrase:\n",
    "        negated_ents.append(doc[i])\n",
    "    else:\n",
    "        ents.append(doc[i])\n",
    "    start = i\n",
    "    \n",
    "print(negated_ents)\n",
    "print(ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_message = \"\"\"\n",
    "i would like to find a flight from charlotte\n",
    "to las vegas that makes a stop in st. louis\"\"\"\n",
    "\n",
    "test_x = nlp(test_message).vector\n",
    "scores = [cosine_similarity(X[i,:], test_x)  for i in range(len(sentences_train) ]\n",
    "\n",
    "labels_train[np.argmax(scores)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rasaenv",
   "language": "python",
   "name": "rasaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
