{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Doc2Vec Model\n",
    "=============\n",
    "\n",
    "Introduces Gensim's Doc2Vec model and demonstrates its use on the Lee Corpus.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2Vec is a `core_concepts_model` that represents each\n",
    "`core_concepts_document` as a `core_concepts_vector`.  This\n",
    "tutorial introduces the model and demonstrates how to train and assess it.\n",
    "\n",
    "Here's a list of what we'll be doing:\n",
    "\n",
    "0. Review the relevant models: bag-of-words, Word2Vec, Doc2Vec\n",
    "1. Load and preprocess the training and test corpora (see `core_concepts_corpus`)\n",
    "2. Train a Doc2Vec `core_concepts_model` model using the training corpus\n",
    "3. Demonstrate how the trained model can be used to infer a `core_concepts_vector`\n",
    "4. Assess the model\n",
    "5. Test the model on the test corpus\n",
    "\n",
    "Review: Bag-of-words\n",
    "--------------------\n",
    "\n",
    ".. Note:: Feel free to skip these review sections if you're already familiar with the models.\n",
    "\n",
    "You may be familiar with the `bag-of-words model\n",
    "<https://en.wikipedia.org/wiki/Bag-of-words_model>`_ from the\n",
    "`core_concepts_vector` section.\n",
    "This model transforms each document to a fixed-length vector of integers.\n",
    "For example, given the sentences:\n",
    "\n",
    "- ``John likes to watch movies. Mary likes movies too.``\n",
    "- ``John also likes to watch football games. Mary hates football.``\n",
    "\n",
    "The model outputs the vectors:\n",
    "\n",
    "- ``[1, 2, 1, 1, 2, 1, 1, 0, 0, 0, 0]``\n",
    "- ``[1, 1, 1, 1, 0, 1, 0, 1, 2, 1, 1]``\n",
    "\n",
    "Each vector has 10 elements, where each element counts the number of times a\n",
    "particular word occurred in the document.\n",
    "The order of elements is arbitrary.\n",
    "In the example above, the order of the elements corresponds to the words:\n",
    "``[\"John\", \"likes\", \"to\", \"watch\", \"movies\", \"Mary\", \"too\", \"also\", \"football\", \"games\", \"hates\"]``.\n",
    "\n",
    "Bag-of-words models are surprisingly effective, but have several weaknesses.\n",
    "\n",
    "First, they lose all information about word order: \"John likes Mary\" and\n",
    "\"Mary likes John\" correspond to identical vectors. There is a solution: bag\n",
    "of `n-grams <https://en.wikipedia.org/wiki/N-gram>`__\n",
    "models consider word phrases of length n to represent documents as\n",
    "fixed-length vectors to capture local word order but suffer from data\n",
    "sparsity and high dimensionality.\n",
    "\n",
    "Second, the model does not attempt to learn the meaning of the underlying\n",
    "words, and as a consequence, the distance between vectors doesn't always\n",
    "reflect the difference in meaning.  The ``Word2Vec`` model addresses this\n",
    "second problem.\n",
    "\n",
    "Review: ``Word2Vec`` Model\n",
    "--------------------------\n",
    "\n",
    "``Word2Vec`` is a more recent model that embeds words in a lower-dimensional\n",
    "vector space using a shallow neural network. The result is a set of\n",
    "word-vectors where vectors close together in vector space have similar\n",
    "meanings based on context, and word-vectors distant to each other have\n",
    "differing meanings. For example, ``strong`` and ``powerful`` would be close\n",
    "together and ``strong`` and ``Paris`` would be relatively far.\n",
    "\n",
    "Gensim's :py:class:`~gensim.models.word2vec.Word2Vec` class implements this model.\n",
    "\n",
    "With the ``Word2Vec`` model, we can calculate the vectors for each **word** in a document.\n",
    "But what if we want to calculate a vector for the **entire document**\\ ?\n",
    "We could average the vectors for each word in the document - while this is quick and crude, it can often be useful.\n",
    "However, there is a better way...\n",
    "\n",
    "Introducing: Paragraph Vector\n",
    "-----------------------------\n",
    "\n",
    ".. Important:: In Gensim, we refer to the Paragraph Vector model as ``Doc2Vec``.\n",
    "\n",
    "Le and Mikolov in 2014 introduced the `Doc2Vec algorithm <https://cs.stanford.edu/~quocle/paragraph_vector.pdf>`__, which usually outperforms such simple-averaging of ``Word2Vec`` vectors.\n",
    "\n",
    "The basic idea is: act as if a document has another floating word-like\n",
    "vector, which contributes to all training predictions, and is updated like\n",
    "other word-vectors, but we will call it a doc-vector. Gensim's\n",
    ":py:class:`~gensim.models.doc2vec.Doc2Vec` class implements this algorithm.\n",
    "\n",
    "There are two implementations:\n",
    "\n",
    "1. Paragraph Vector - Distributed Memory (PV-DM)\n",
    "2. Paragraph Vector - Distributed Bag of Words (PV-DBOW)\n",
    "\n",
    ".. Important::\n",
    "  Don't let the implementation details below scare you.\n",
    "  They're advanced material: if it's too much, then move on to the next section.\n",
    "\n",
    "PV-DM is analogous to Word2Vec CBOW. The doc-vectors are obtained by training\n",
    "a neural network on the synthetic task of predicting a center word based an\n",
    "average of both context word-vectors and the full document's doc-vector.\n",
    "\n",
    "PV-DBOW is analogous to Word2Vec SG. The doc-vectors are obtained by training\n",
    "a neural network on the synthetic task of predicting a target word just from\n",
    "the full document's doc-vector. (It is also common to combine this with\n",
    "skip-gram testing, using both the doc-vector and nearby word-vectors to\n",
    "predict a single target word, but only one at a time.)\n",
    "\n",
    "Prepare the Training and Test Data\n",
    "----------------------------------\n",
    "\n",
    "For this tutorial, we'll be training our model using the `Lee Background\n",
    "Corpus\n",
    "<https://hekyll.services.adelaide.edu.au/dspace/bitstream/2440/28910/1/hdl_28910.pdf>`_\n",
    "included in gensim. This corpus contains 314 documents selected from the\n",
    "Australian Broadcasting Corporationâ€™s news mail service, which provides text\n",
    "e-mails of headline stories and covers a number of broad topics.\n",
    "\n",
    "And we'll test our model by eye using the much shorter `Lee Corpus\n",
    "<https://hekyll.services.adelaide.edu.au/dspace/bitstream/2440/28910/1/hdl_28910.pdf>`_\n",
    "which contains 50 documents.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "# Set file names for train and test data\n",
    "test_data_dir = os.path.join(gensim.__path__[0], 'test', 'test_data')\n",
    "lee_train_file = os.path.join(test_data_dir, 'lee_background.cor')\n",
    "lee_test_file = os.path.join(test_data_dir, 'lee.cor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a Function to Read and Preprocess Text\n",
    "---------------------------------------------\n",
    "\n",
    "Below, we define a function to:\n",
    "\n",
    "- open the train/test file (with latin encoding)\n",
    "- read the file line-by-line\n",
    "- pre-process each line (tokenize text into individual words, remove punctuation, set to lowercase, etc)\n",
    "\n",
    "The file we're reading is a **corpus**.\n",
    "Each line of the file is a **document**.\n",
    "\n",
    ".. Important::\n",
    "  To train the model, we'll need to associate a tag/number with each document\n",
    "  of the training corpus. In our case, the tag is simply the zero-based line\n",
    "  number.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smart_open\n",
    "\n",
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            tokens = gensim.utils.simple_preprocess(line)\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "\n",
    "train_corpus = list(read_corpus(lee_train_file))\n",
    "test_corpus = list(read_corpus(lee_test_file, tokens_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the training corpus\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TaggedDocument(words=['hundreds', 'of', 'people', 'have', 'been', 'forced', 'to', 'vacate', 'their', 'homes', 'in', 'the', 'southern', 'highlands', 'of', 'new', 'south', 'wales', 'as', 'strong', 'winds', 'today', 'pushed', 'huge', 'bushfire', 'towards', 'the', 'town', 'of', 'hill', 'top', 'new', 'blaze', 'near', 'goulburn', 'south', 'west', 'of', 'sydney', 'has', 'forced', 'the', 'closure', 'of', 'the', 'hume', 'highway', 'at', 'about', 'pm', 'aedt', 'marked', 'deterioration', 'in', 'the', 'weather', 'as', 'storm', 'cell', 'moved', 'east', 'across', 'the', 'blue', 'mountains', 'forced', 'authorities', 'to', 'make', 'decision', 'to', 'evacuate', 'people', 'from', 'homes', 'in', 'outlying', 'streets', 'at', 'hill', 'top', 'in', 'the', 'new', 'south', 'wales', 'southern', 'highlands', 'an', 'estimated', 'residents', 'have', 'left', 'their', 'homes', 'for', 'nearby', 'mittagong', 'the', 'new', 'south', 'wales', 'rural', 'fire', 'service', 'says', 'the', 'weather', 'conditions', 'which', 'caused', 'the', 'fire', 'to', 'burn', 'in', 'finger', 'formation', 'have', 'now', 'eased', 'and', 'about', 'fire', 'units', 'in', 'and', 'around', 'hill', 'top', 'are', 'optimistic', 'of', 'defending', 'all', 'properties', 'as', 'more', 'than', 'blazes', 'burn', 'on', 'new', 'year', 'eve', 'in', 'new', 'south', 'wales', 'fire', 'crews', 'have', 'been', 'called', 'to', 'new', 'fire', 'at', 'gunning', 'south', 'of', 'goulburn', 'while', 'few', 'details', 'are', 'available', 'at', 'this', 'stage', 'fire', 'authorities', 'says', 'it', 'has', 'closed', 'the', 'hume', 'highway', 'in', 'both', 'directions', 'meanwhile', 'new', 'fire', 'in', 'sydney', 'west', 'is', 'no', 'longer', 'threatening', 'properties', 'in', 'the', 'cranebrook', 'area', 'rain', 'has', 'fallen', 'in', 'some', 'parts', 'of', 'the', 'illawarra', 'sydney', 'the', 'hunter', 'valley', 'and', 'the', 'north', 'coast', 'but', 'the', 'bureau', 'of', 'meteorology', 'claire', 'richards', 'says', 'the', 'rain', 'has', 'done', 'little', 'to', 'ease', 'any', 'of', 'the', 'hundred', 'fires', 'still', 'burning', 'across', 'the', 'state', 'the', 'falls', 'have', 'been', 'quite', 'isolated', 'in', 'those', 'areas', 'and', 'generally', 'the', 'falls', 'have', 'been', 'less', 'than', 'about', 'five', 'millimetres', 'she', 'said', 'in', 'some', 'places', 'really', 'not', 'significant', 'at', 'all', 'less', 'than', 'millimetre', 'so', 'there', 'hasn', 'been', 'much', 'relief', 'as', 'far', 'as', 'rain', 'is', 'concerned', 'in', 'fact', 'they', 've', 'probably', 'hampered', 'the', 'efforts', 'of', 'the', 'firefighters', 'more', 'because', 'of', 'the', 'wind', 'gusts', 'that', 'are', 'associated', 'with', 'those', 'thunderstorms'], tags=[0]), TaggedDocument(words=['indian', 'security', 'forces', 'have', 'shot', 'dead', 'eight', 'suspected', 'militants', 'in', 'night', 'long', 'encounter', 'in', 'southern', 'kashmir', 'the', 'shootout', 'took', 'place', 'at', 'dora', 'village', 'some', 'kilometers', 'south', 'of', 'the', 'kashmiri', 'summer', 'capital', 'srinagar', 'the', 'deaths', 'came', 'as', 'pakistani', 'police', 'arrested', 'more', 'than', 'two', 'dozen', 'militants', 'from', 'extremist', 'groups', 'accused', 'of', 'staging', 'an', 'attack', 'on', 'india', 'parliament', 'india', 'has', 'accused', 'pakistan', 'based', 'lashkar', 'taiba', 'and', 'jaish', 'mohammad', 'of', 'carrying', 'out', 'the', 'attack', 'on', 'december', 'at', 'the', 'behest', 'of', 'pakistani', 'military', 'intelligence', 'military', 'tensions', 'have', 'soared', 'since', 'the', 'raid', 'with', 'both', 'sides', 'massing', 'troops', 'along', 'their', 'border', 'and', 'trading', 'tit', 'for', 'tat', 'diplomatic', 'sanctions', 'yesterday', 'pakistan', 'announced', 'it', 'had', 'arrested', 'lashkar', 'taiba', 'chief', 'hafiz', 'mohammed', 'saeed', 'police', 'in', 'karachi', 'say', 'it', 'is', 'likely', 'more', 'raids', 'will', 'be', 'launched', 'against', 'the', 'two', 'groups', 'as', 'well', 'as', 'other', 'militant', 'organisations', 'accused', 'of', 'targetting', 'india', 'military', 'tensions', 'between', 'india', 'and', 'pakistan', 'have', 'escalated', 'to', 'level', 'not', 'seen', 'since', 'their', 'war'], tags=[1])]\n"
     ]
    }
   ],
   "source": [
    "print(train_corpus[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the testing corpus looks like this:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'national', 'executive', 'of', 'the', 'strife', 'torn', 'democrats', 'last', 'night', 'appointed', 'little', 'known', 'west', 'australian', 'senator', 'brian', 'greig', 'as', 'interim', 'leader', 'shock', 'move', 'likely', 'to', 'provoke', 'further', 'conflict', 'between', 'the', 'party', 'senators', 'and', 'its', 'organisation', 'in', 'move', 'to', 'reassert', 'control', 'over', 'the', 'party', 'seven', 'senators', 'the', 'national', 'executive', 'last', 'night', 'rejected', 'aden', 'ridgeway', 'bid', 'to', 'become', 'interim', 'leader', 'in', 'favour', 'of', 'senator', 'greig', 'supporter', 'of', 'deposed', 'leader', 'natasha', 'stott', 'despoja', 'and', 'an', 'outspoken', 'gay', 'rights', 'activist'], ['cash', 'strapped', 'financial', 'services', 'group', 'amp', 'has', 'shelved', 'million', 'plan', 'to', 'buy', 'shares', 'back', 'from', 'investors', 'and', 'will', 'raise', 'million', 'in', 'fresh', 'capital', 'after', 'profits', 'crashed', 'in', 'the', 'six', 'months', 'to', 'june', 'chief', 'executive', 'paul', 'batchelor', 'said', 'the', 'result', 'was', 'solid', 'in', 'what', 'he', 'described', 'as', 'the', 'worst', 'conditions', 'for', 'stock', 'markets', 'in', 'years', 'amp', 'half', 'year', 'profit', 'sank', 'per', 'cent', 'to', 'million', 'or', 'share', 'as', 'australia', 'largest', 'investor', 'and', 'fund', 'manager', 'failed', 'to', 'hit', 'projected', 'per', 'cent', 'earnings', 'growth', 'targets', 'and', 'was', 'battered', 'by', 'falling', 'returns', 'on', 'share', 'markets']]\n"
     ]
    }
   ],
   "source": [
    "print(test_corpus[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the testing corpus is just a list of lists and does not contain\n",
    "any tags.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Model\n",
    "------------------\n",
    "\n",
    "Now, we'll instantiate a Doc2Vec model with a vector size with 50 dimensions and\n",
    "iterating over the training corpus 40 times. We set the minimum word count to\n",
    "2 in order to discard words with very few occurrences. (Without a variety of\n",
    "representative examples, retaining such infrequent words can often make a\n",
    "model worse!) Typical iteration counts in the published `Paragraph Vector paper <https://cs.stanford.edu/~quocle/paragraph_vector.pdf>`__\n",
    "results, using 10s-of-thousands to millions of docs, are 10-20. More\n",
    "iterations take more time and eventually reach a point of diminishing\n",
    "returns.\n",
    "\n",
    "However, this is a very very small dataset (300 documents) with shortish\n",
    "documents (a few hundred words). Adding training passes can sometimes help\n",
    "with such small datasets.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-15 11:01:15,750 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a vocabulary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-15 11:01:19,424 : INFO : collecting all words and their counts\n",
      "2020-07-15 11:01:19,425 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2020-07-15 11:01:19,439 : INFO : collected 6981 word types and 300 unique tags from a corpus of 300 examples and 58152 words\n",
      "2020-07-15 11:01:19,440 : INFO : Loading a fresh vocabulary\n",
      "2020-07-15 11:01:19,451 : INFO : effective_min_count=2 retains 3955 unique words (56% of original 6981, drops 3026)\n",
      "2020-07-15 11:01:19,452 : INFO : effective_min_count=2 leaves 55126 word corpus (94% of original 58152, drops 3026)\n",
      "2020-07-15 11:01:19,469 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2020-07-15 11:01:19,470 : INFO : sample=0.001 downsamples 46 most-common words\n",
      "2020-07-15 11:01:19,471 : INFO : downsampling leaves estimated 42390 word corpus (76.9% of prior 55126)\n",
      "2020-07-15 11:01:19,482 : INFO : estimated required memory for 3955 words and 50 dimensions: 3619500 bytes\n",
      "2020-07-15 11:01:19,484 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, the vocabulary is a dictionary (accessible via\n",
    "``model.wv.vocab``\\ ) of all of the unique words extracted from the training\n",
    "corpus along with the count (e.g., ``model.wv.vocab['penalty'].count`` for\n",
    "counts for the word ``penalty``\\ ).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, train the model on the corpus.\n",
    "If the BLAS library is being used, this should take no more than 3 seconds.\n",
    "If the BLAS library is not being used, this should take no more than 2\n",
    "minutes, so use BLAS if you value your time.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-15 11:01:34,530 : INFO : training model with 3 workers on 3955 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-07-15 11:01:34,598 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:34,604 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:34,605 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:34,606 : INFO : EPOCH - 1 : training on 58152 raw words (42636 effective words) took 0.1s, 593375 effective words/s\n",
      "2020-07-15 11:01:34,669 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:34,674 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:34,674 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:34,675 : INFO : EPOCH - 2 : training on 58152 raw words (42681 effective words) took 0.1s, 647674 effective words/s\n",
      "2020-07-15 11:01:34,741 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:34,745 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:34,748 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:34,749 : INFO : EPOCH - 3 : training on 58152 raw words (42734 effective words) took 0.1s, 598551 effective words/s\n",
      "2020-07-15 11:01:34,813 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:34,820 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:34,823 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:34,824 : INFO : EPOCH - 4 : training on 58152 raw words (42738 effective words) took 0.1s, 597710 effective words/s\n",
      "2020-07-15 11:01:34,891 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:34,895 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:34,898 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:34,899 : INFO : EPOCH - 5 : training on 58152 raw words (42648 effective words) took 0.1s, 594595 effective words/s\n",
      "2020-07-15 11:01:34,966 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:34,971 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:34,972 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:34,973 : INFO : EPOCH - 6 : training on 58152 raw words (42778 effective words) took 0.1s, 607802 effective words/s\n",
      "2020-07-15 11:01:35,041 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:35,043 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:35,044 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:35,045 : INFO : EPOCH - 7 : training on 58152 raw words (42654 effective words) took 0.1s, 631701 effective words/s\n",
      "2020-07-15 11:01:35,112 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:35,117 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:35,120 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:35,121 : INFO : EPOCH - 8 : training on 58152 raw words (42628 effective words) took 0.1s, 578380 effective words/s\n",
      "2020-07-15 11:01:35,190 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:35,192 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:35,197 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:35,198 : INFO : EPOCH - 9 : training on 58152 raw words (42737 effective words) took 0.1s, 581087 effective words/s\n",
      "2020-07-15 11:01:35,269 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:35,270 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:35,271 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:35,273 : INFO : EPOCH - 10 : training on 58152 raw words (42846 effective words) took 0.1s, 598211 effective words/s\n",
      "2020-07-15 11:01:35,341 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:35,344 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:35,345 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:35,346 : INFO : EPOCH - 11 : training on 58152 raw words (42709 effective words) took 0.1s, 606449 effective words/s\n",
      "2020-07-15 11:01:35,424 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:35,427 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:35,430 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:35,431 : INFO : EPOCH - 12 : training on 58152 raw words (42625 effective words) took 0.1s, 529553 effective words/s\n",
      "2020-07-15 11:01:35,507 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:35,525 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:35,528 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:35,530 : INFO : EPOCH - 13 : training on 58152 raw words (42655 effective words) took 0.1s, 451992 effective words/s\n",
      "2020-07-15 11:01:35,626 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:35,633 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:35,635 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:35,636 : INFO : EPOCH - 14 : training on 58152 raw words (42710 effective words) took 0.1s, 465238 effective words/s\n",
      "2020-07-15 11:01:35,731 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:35,749 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:35,759 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:35,761 : INFO : EPOCH - 15 : training on 58152 raw words (42681 effective words) took 0.1s, 359682 effective words/s\n",
      "2020-07-15 11:01:35,857 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:35,867 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:35,868 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:35,869 : INFO : EPOCH - 16 : training on 58152 raw words (42716 effective words) took 0.1s, 404878 effective words/s\n",
      "2020-07-15 11:01:35,951 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:35,958 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:35,960 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:35,961 : INFO : EPOCH - 17 : training on 58152 raw words (42731 effective words) took 0.1s, 505580 effective words/s\n",
      "2020-07-15 11:01:36,024 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:36,031 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:36,032 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:36,033 : INFO : EPOCH - 18 : training on 58152 raw words (42706 effective words) took 0.1s, 613618 effective words/s\n",
      "2020-07-15 11:01:36,107 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:36,110 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:36,111 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:36,112 : INFO : EPOCH - 19 : training on 58152 raw words (42627 effective words) took 0.1s, 557133 effective words/s\n",
      "2020-07-15 11:01:36,178 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:36,180 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:36,183 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:36,184 : INFO : EPOCH - 20 : training on 58152 raw words (42661 effective words) took 0.1s, 617347 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-15 11:01:36,253 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:36,255 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:36,256 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:36,256 : INFO : EPOCH - 21 : training on 58152 raw words (42775 effective words) took 0.1s, 616953 effective words/s\n",
      "2020-07-15 11:01:36,321 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:36,323 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:36,324 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:36,325 : INFO : EPOCH - 22 : training on 58152 raw words (42662 effective words) took 0.1s, 653594 effective words/s\n",
      "2020-07-15 11:01:36,392 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:36,395 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:36,396 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:36,397 : INFO : EPOCH - 23 : training on 58152 raw words (42683 effective words) took 0.1s, 636912 effective words/s\n",
      "2020-07-15 11:01:36,463 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:36,464 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:36,466 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:36,467 : INFO : EPOCH - 24 : training on 58152 raw words (42665 effective words) took 0.1s, 640394 effective words/s\n",
      "2020-07-15 11:01:36,532 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:36,534 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:36,537 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:36,538 : INFO : EPOCH - 25 : training on 58152 raw words (42695 effective words) took 0.1s, 648486 effective words/s\n",
      "2020-07-15 11:01:36,605 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:36,606 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:36,607 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:36,608 : INFO : EPOCH - 26 : training on 58152 raw words (42791 effective words) took 0.1s, 647518 effective words/s\n",
      "2020-07-15 11:01:36,670 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:36,672 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:36,673 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:36,674 : INFO : EPOCH - 27 : training on 58152 raw words (42685 effective words) took 0.1s, 688974 effective words/s\n",
      "2020-07-15 11:01:36,739 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:36,741 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:36,742 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:36,742 : INFO : EPOCH - 28 : training on 58152 raw words (42608 effective words) took 0.1s, 652454 effective words/s\n",
      "2020-07-15 11:01:36,810 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:36,811 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:36,814 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:36,815 : INFO : EPOCH - 29 : training on 58152 raw words (42566 effective words) took 0.1s, 619263 effective words/s\n",
      "2020-07-15 11:01:36,884 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:36,886 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:36,888 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:36,889 : INFO : EPOCH - 30 : training on 58152 raw words (42749 effective words) took 0.1s, 610266 effective words/s\n",
      "2020-07-15 11:01:36,954 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:36,957 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:36,960 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:36,961 : INFO : EPOCH - 31 : training on 58152 raw words (42721 effective words) took 0.1s, 615635 effective words/s\n",
      "2020-07-15 11:01:37,026 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:37,030 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:37,031 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:37,032 : INFO : EPOCH - 32 : training on 58152 raw words (42679 effective words) took 0.1s, 628283 effective words/s\n",
      "2020-07-15 11:01:37,099 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:37,100 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:37,101 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:37,102 : INFO : EPOCH - 33 : training on 58152 raw words (42668 effective words) took 0.1s, 641401 effective words/s\n",
      "2020-07-15 11:01:37,168 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:37,172 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:37,174 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:37,175 : INFO : EPOCH - 34 : training on 58152 raw words (42784 effective words) took 0.1s, 607382 effective words/s\n",
      "2020-07-15 11:01:37,246 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:37,248 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:37,248 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:37,249 : INFO : EPOCH - 35 : training on 58152 raw words (42840 effective words) took 0.1s, 604080 effective words/s\n",
      "2020-07-15 11:01:37,317 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:37,322 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:37,324 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:37,325 : INFO : EPOCH - 36 : training on 58152 raw words (42696 effective words) took 0.1s, 624008 effective words/s\n",
      "2020-07-15 11:01:37,391 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:37,393 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:37,394 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:37,396 : INFO : EPOCH - 37 : training on 58152 raw words (42605 effective words) took 0.1s, 627752 effective words/s\n",
      "2020-07-15 11:01:37,463 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:37,464 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:37,465 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:37,466 : INFO : EPOCH - 38 : training on 58152 raw words (42716 effective words) took 0.1s, 633248 effective words/s\n",
      "2020-07-15 11:01:37,533 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:37,537 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:37,541 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:37,542 : INFO : EPOCH - 39 : training on 58152 raw words (42705 effective words) took 0.1s, 586279 effective words/s\n",
      "2020-07-15 11:01:37,608 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-15 11:01:37,611 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-15 11:01:37,611 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-15 11:01:37,612 : INFO : EPOCH - 40 : training on 58152 raw words (42739 effective words) took 0.1s, 643249 effective words/s\n",
      "2020-07-15 11:01:37,614 : INFO : training on a 2326080 raw words (1707933 effective words) took 3.1s, 554218 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the trained model to infer a vector for any piece of text\n",
    "by passing a list of words to the ``model.infer_vector`` function. This\n",
    "vector can then be compared with other vectors via cosine similarity.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07751817  0.02800005  0.01521451 -0.10456034  0.06511893  0.01522871\n",
      " -0.21672998 -0.03492664  0.4017482  -0.01237417  0.01007352 -0.02576625\n",
      " -0.1280731  -0.07276308 -0.12329874  0.15926166 -0.15908918 -0.09750891\n",
      "  0.12303556  0.12752998  0.37516263  0.13863486 -0.04241408 -0.03366408\n",
      " -0.2843566   0.00964921 -0.00927703  0.23377624  0.1852463   0.2028149\n",
      "  0.01985336  0.05845246  0.0970552   0.00367544 -0.00296842  0.19928724\n",
      " -0.13666993 -0.0637742  -0.1777087   0.09105444 -0.06693419 -0.03261606\n",
      "  0.1025117  -0.02495266  0.16009551 -0.14639178  0.0568004   0.29999125\n",
      "  0.03628466  0.07689967]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['only', 'you', 'can', 'prevent', 'forest', 'fires'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that ``infer_vector()`` does *not* take a string, but rather a list of\n",
    "string tokens, which should have already been tokenized the same way as the\n",
    "``words`` property of original training document objects.\n",
    "\n",
    "Also note that because the underlying training/inference algorithms are an\n",
    "iterative approximation problem that makes use of internal randomization,\n",
    "repeated inferences of the same text will return slightly different vectors.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assessing the Model\n",
    "-------------------\n",
    "\n",
    "To assess our new model, we'll first infer new vectors for each document of\n",
    "the training corpus, compare the inferred vectors with the training corpus,\n",
    "and then returning the rank of the document based on self-similarity.\n",
    "Basically, we're pretending as if the training corpus is some new unseen data\n",
    "and then seeing how they compare with the trained model. The expectation is\n",
    "that we've likely overfit our model (i.e., all of the ranks will be less than\n",
    "2) and so we should be able to find similar documents very easily.\n",
    "Additionally, we'll keep track of the second ranks for a comparison of less\n",
    "similar documents.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['indian', 'security', 'forces', 'have', 'shot', 'dead', 'eight', 'suspected', 'militants', 'in', 'night', 'long', 'encounter', 'in', 'southern', 'kashmir', 'the', 'shootout', 'took', 'place', 'at', 'dora', 'village', 'some', 'kilometers', 'south', 'of', 'the', 'kashmiri', 'summer', 'capital', 'srinagar', 'the', 'deaths', 'came', 'as', 'pakistani', 'police', 'arrested', 'more', 'than', 'two', 'dozen', 'militants', 'from', 'extremist', 'groups', 'accused', 'of', 'staging', 'an', 'attack', 'on', 'india', 'parliament', 'india', 'has', 'accused', 'pakistan', 'based', 'lashkar', 'taiba', 'and', 'jaish', 'mohammad', 'of', 'carrying', 'out', 'the', 'attack', 'on', 'december', 'at', 'the', 'behest', 'of', 'pakistani', 'military', 'intelligence', 'military', 'tensions', 'have', 'soared', 'since', 'the', 'raid', 'with', 'both', 'sides', 'massing', 'troops', 'along', 'their', 'border', 'and', 'trading', 'tit', 'for', 'tat', 'diplomatic', 'sanctions', 'yesterday', 'pakistan', 'announced', 'it', 'had', 'arrested', 'lashkar', 'taiba', 'chief', 'hafiz', 'mohammed', 'saeed', 'police', 'in', 'karachi', 'say', 'it', 'is', 'likely', 'more', 'raids', 'will', 'be', 'launched', 'against', 'the', 'two', 'groups', 'as', 'well', 'as', 'other', 'militant', 'organisations', 'accused', 'of', 'targetting', 'india', 'military', 'tensions', 'between', 'india', 'and', 'pakistan', 'have', 'escalated', 'to', 'level', 'not', 'seen', 'since', 'their', 'war'], tags=[1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.docvecs)\n",
    "print(len(train_corpus))\n",
    "train_corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.9644030332565308), (48, 0.8956092596054077), (255, 0.841506838798523), (40, 0.8384165167808533), (8, 0.8297841548919678), (33, 0.8284482955932617), (272, 0.8082559704780579), (264, 0.7642050981521606), (9, 0.7375155687332153), (105, 0.7303707599639893), (19, 0.7262861728668213), (25, 0.7073076963424683), (10, 0.7064156532287598), (62, 0.6761486530303955), (4, 0.6670585870742798), (113, 0.6641255021095276), (109, 0.6563208103179932), (198, 0.6536864042282104), (46, 0.6507307291030884), (189, 0.6398293972015381), (84, 0.6396191120147705), (89, 0.6116921901702881), (219, 0.6057193875312805), (126, 0.5903477668762207), (188, 0.5853989124298096), (77, 0.5808756351470947), (42, 0.578768253326416), (63, 0.5783545970916748), (144, 0.5723164081573486), (43, 0.5705066919326782), (52, 0.5694836974143982), (15, 0.5629546046257019), (2, 0.547138512134552), (178, 0.5243591666221619), (172, 0.5123133659362793), (5, 0.5118585824966431), (79, 0.5077247023582458), (171, 0.507560670375824), (240, 0.5067178010940552), (21, 0.505714476108551), (11, 0.5028947591781616), (39, 0.5006062388420105), (256, 0.49874332547187805), (78, 0.4920520782470703), (180, 0.48860883712768555), (222, 0.48627763986587524), (123, 0.47060665488243103), (86, 0.46876776218414307), (27, 0.4661063551902771), (24, 0.46492326259613037), (18, 0.4641120433807373), (7, 0.46251633763313293), (108, 0.45904186367988586), (288, 0.4510745406150818), (223, 0.44978588819503784), (290, 0.44510576128959656), (181, 0.4417962431907654), (281, 0.43835651874542236), (136, 0.4361743927001953), (182, 0.43245387077331543), (124, 0.4312589466571808), (32, 0.42476969957351685), (282, 0.42292797565460205), (289, 0.4213705062866211), (236, 0.42048054933547974), (238, 0.4166219234466553), (141, 0.4153605103492737), (193, 0.41480162739753723), (242, 0.41286423802375793), (205, 0.41274574398994446), (36, 0.4103330373764038), (296, 0.40750032663345337), (53, 0.4057818353176117), (99, 0.4039115607738495), (72, 0.4030105471611023), (70, 0.4022001624107361), (202, 0.40094757080078125), (230, 0.39827412366867065), (185, 0.39774006605148315), (91, 0.39724260568618774), (165, 0.3957836627960205), (280, 0.3957793712615967), (16, 0.39364492893218994), (76, 0.386557936668396), (191, 0.38550636172294617), (298, 0.38396334648132324), (286, 0.3832642436027527), (30, 0.3823721408843994), (190, 0.37499696016311646), (149, 0.36646223068237305), (139, 0.3654698133468628), (208, 0.36357325315475464), (161, 0.36209404468536377), (127, 0.362015962600708), (285, 0.36094775795936584), (96, 0.35920870304107666), (169, 0.3519485592842102), (228, 0.3509753942489624), (51, 0.34940487146377563), (237, 0.3449648320674896), (253, 0.34244123101234436), (133, 0.3423849046230316), (59, 0.3411939740180969), (164, 0.3388305902481079), (183, 0.33846184611320496), (47, 0.33426159620285034), (196, 0.33116984367370605), (175, 0.3295328617095947), (254, 0.3292684257030487), (22, 0.32650017738342285), (163, 0.3252563774585724), (1, 0.32328498363494873), (100, 0.32279172539711), (120, 0.32207775115966797), (207, 0.3217732310295105), (212, 0.321137011051178), (69, 0.32055312395095825), (137, 0.3184719979763031), (58, 0.3176431655883789), (117, 0.3168141841888428), (204, 0.31469541788101196), (277, 0.3142879605293274), (92, 0.3141515851020813), (31, 0.31324613094329834), (243, 0.31271475553512573), (239, 0.30961018800735474), (167, 0.3095390498638153), (81, 0.309065043926239), (248, 0.30902740359306335), (98, 0.3033856749534607), (179, 0.3024618625640869), (284, 0.301006019115448), (13, 0.30098146200180054), (271, 0.3001280426979065), (266, 0.29937034845352173), (162, 0.29886120557785034), (210, 0.2978399693965912), (291, 0.2956174910068512), (142, 0.2953045666217804), (227, 0.294030100107193), (268, 0.29377853870391846), (95, 0.2917894124984741), (211, 0.29172348976135254), (112, 0.290230929851532), (49, 0.28969240188598633), (174, 0.285545289516449), (217, 0.2827416956424713), (50, 0.28212302923202515), (14, 0.27956125140190125), (263, 0.2793506383895874), (152, 0.27837085723876953), (65, 0.2769898772239685), (71, 0.27578073740005493), (234, 0.27496322989463806), (119, 0.27356523275375366), (45, 0.27230358123779297), (251, 0.27176082134246826), (203, 0.27117329835891724), (54, 0.26866430044174194), (67, 0.26863595843315125), (55, 0.2655943036079407), (159, 0.26479393243789673), (35, 0.2610652446746826), (44, 0.2592554986476898), (104, 0.25901147723197937), (83, 0.2577996253967285), (121, 0.254421204328537), (129, 0.2537246644496918), (226, 0.25340238213539124), (177, 0.2532733976840973), (154, 0.25304755568504333), (156, 0.25119659304618835), (115, 0.24531584978103638), (265, 0.24514955282211304), (145, 0.24364805221557617), (66, 0.2405553162097931), (294, 0.24035821855068207), (102, 0.23918144404888153), (150, 0.2386653572320938), (260, 0.23775145411491394), (225, 0.23670046031475067), (224, 0.23614805936813354), (135, 0.23610268533229828), (166, 0.23483113944530487), (122, 0.23368991911411285), (73, 0.23368777334690094), (192, 0.23337960243225098), (258, 0.23039932548999786), (276, 0.23039750754833221), (195, 0.22917424142360687), (218, 0.22882887721061707), (140, 0.22510769963264465), (28, 0.22208909690380096), (107, 0.22122341394424438), (82, 0.21969006955623627), (88, 0.2186935544013977), (215, 0.21747395396232605), (128, 0.21608510613441467), (278, 0.21269503235816956), (146, 0.2112632691860199), (101, 0.210302472114563), (213, 0.2099851816892624), (187, 0.20543578267097473), (261, 0.20340213179588318), (287, 0.20250704884529114), (85, 0.20059198141098022), (6, 0.20057347416877747), (257, 0.20014920830726624), (209, 0.19967013597488403), (143, 0.19949862360954285), (56, 0.19839096069335938), (231, 0.1958543062210083), (151, 0.19566677510738373), (295, 0.19565033912658691), (220, 0.19481022655963898), (87, 0.19458240270614624), (249, 0.19266481697559357), (37, 0.19039425253868103), (293, 0.189061239361763), (106, 0.18892981112003326), (125, 0.18715626001358032), (186, 0.1836998164653778), (148, 0.18177323043346405), (34, 0.18094320595264435), (168, 0.1801539957523346), (244, 0.1783834844827652), (93, 0.17763815820217133), (275, 0.17493166029453278), (114, 0.17157022655010223), (216, 0.17142325639724731), (206, 0.17074859142303467), (270, 0.17069046199321747), (199, 0.16913749277591705), (38, 0.16882921755313873), (221, 0.16711387038230896), (274, 0.16680920124053955), (279, 0.16647662222385406), (200, 0.16532118618488312), (61, 0.16517144441604614), (201, 0.16377153992652893), (292, 0.1590014547109604), (299, 0.1567055583000183), (110, 0.14773236215114594), (252, 0.1476621925830841), (273, 0.14401212334632874), (138, 0.1427231729030609), (229, 0.14202038943767548), (246, 0.13989999890327454), (155, 0.13382472097873688), (20, 0.13361354172229767), (80, 0.13355332612991333), (176, 0.13275589048862457), (68, 0.12978315353393555), (241, 0.12603817880153656), (259, 0.12558797001838684), (233, 0.12321443110704422), (297, 0.12248894572257996), (74, 0.1212000772356987), (170, 0.12102526426315308), (17, 0.11626021564006805), (64, 0.11532135307788849), (94, 0.11484557390213013), (26, 0.11183883249759674), (118, 0.110608771443367), (232, 0.1103343516588211), (132, 0.09999564290046692), (130, 0.09870190173387527), (41, 0.09841546416282654), (247, 0.09802546352148056), (160, 0.09586421400308609), (250, 0.094992995262146), (269, 0.09214705228805542), (97, 0.09089323878288269), (267, 0.08862261474132538), (57, 0.08778112381696701), (153, 0.08728188276290894), (184, 0.08236049115657806), (158, 0.07486044615507126), (262, 0.07101722806692123), (60, 0.07011212408542633), (245, 0.0649348795413971), (173, 0.06473630666732788), (75, 0.06000995635986328), (12, 0.057996008545160294), (131, 0.05157199501991272), (90, 0.047954268753528595), (111, 0.04343872517347336), (23, 0.042732879519462585), (116, 0.036236755549907684), (147, 0.035951271653175354), (235, 0.021671190857887268), (157, 0.011628273874521255), (283, 0.0018808841705322266), (29, -0.000999055802822113), (134, -0.00940907746553421), (197, -0.031291790306568146), (103, -0.03256813436746597), (3, -0.035561323165893555), (194, -0.04150983691215515), (214, -0.04460088536143303)]\n",
      "*********\n",
      "[0, 48, 255, 40, 8, 33, 272, 264, 9, 105, 19, 25, 10, 62, 4, 113, 109, 198, 46, 189, 84, 89, 219, 126, 188, 77, 42, 63, 144, 43, 52, 15, 2, 178, 172, 5, 79, 171, 240, 21, 11, 39, 256, 78, 180, 222, 123, 86, 27, 24, 18, 7, 108, 288, 223, 290, 181, 281, 136, 182, 124, 32, 282, 289, 236, 238, 141, 193, 242, 205, 36, 296, 53, 99, 72, 70, 202, 230, 185, 91, 165, 280, 16, 76, 191, 298, 286, 30, 190, 149, 139, 208, 161, 127, 285, 96, 169, 228, 51, 237, 253, 133, 59, 164, 183, 47, 196, 175, 254, 22, 163, 1, 100, 120, 207, 212, 69, 137, 58, 117, 204, 277, 92, 31, 243, 239, 167, 81, 248, 98, 179, 284, 13, 271, 266, 162, 210, 291, 142, 227, 268, 95, 211, 112, 49, 174, 217, 50, 14, 263, 152, 65, 71, 234, 119, 45, 251, 203, 54, 67, 55, 159, 35, 44, 104, 83, 121, 129, 226, 177, 154, 156, 115, 265, 145, 66, 294, 102, 150, 260, 225, 224, 135, 166, 122, 73, 192, 258, 276, 195, 218, 140, 28, 107, 82, 88, 215, 128, 278, 146, 101, 213, 187, 261, 287, 85, 6, 257, 209, 143, 56, 231, 151, 295, 220, 87, 249, 37, 293, 106, 125, 186, 148, 34, 168, 244, 93, 275, 114, 216, 206, 270, 199, 38, 221, 274, 279, 200, 61, 201, 292, 299, 110, 252, 273, 138, 229, 246, 155, 20, 80, 176, 68, 241, 259, 233, 297, 74, 170, 17, 64, 94, 26, 118, 232, 132, 130, 41, 247, 160, 250, 269, 97, 267, 57, 153, 184, 158, 262, 60, 245, 173, 75, 12, 131, 90, 111, 23, 116, 147, 235, 157, 283, 29, 134, 197, 103, 3, 194, 214]\n",
      "*********\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count how each document ranks with respect to the training corpus\n",
    "\n",
    "NB. Results vary between runs due to random seeding and very small corpus\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "******\n",
      "[(48, 0.8956092596054077), (141, 0.7633010149002075), (21, 0.8507062196731567), (269, 0.7022351026535034), (105, 0.7780813574790955), (13, 0.6745691299438477), (17, 0.8056340217590332), (46, 0.8727773427963257), (48, 0.9072319865226746), (8, 0.780312180519104), (264, 0.8200471997261047), (62, 0.7727470397949219), (34, 0.6882292032241821), (82, 0.7527008056640625), (208, 0.9082902073860168), (27, 0.8575989603996277), (112, 0.8819214105606079), (6, 0.8561192154884338), (2, 0.7358227968215942), (40, 0.7830510139465332), (150, 0.6708983182907104), (2, 0.8976994752883911), (108, 0.7800480723381042), (56, 0.7294143438339233), (113, 0.670259416103363), (10, 0.8676186800003052), (12, 0.742906928062439), (15, 0.8987475633621216), (56, 0.771320104598999), (214, 0.8472210168838501), (149, 0.6961805820465088), (251, 0.7515329122543335), (21, 0.7447936534881592), (8, 0.8827731013298035), (12, 0.6516283750534058), (127, 0.7533993721008301), (224, 0.5282929539680481), (118, 0.882978081703186), (211, 0.7684085369110107), (15, 0.8438243269920349), (48, 0.9183499217033386), (75, 0.7669377326965332), (182, 0.7475167512893677), (21, 0.9064302444458008), (81, 0.8730484843254089), (130, 0.7524449825286865), (15, 0.8163369297981262), (139, 0.8641430139541626), (0, 0.9224908947944641), (160, 0.6119062900543213), (127, 0.8504372239112854), (1, 0.7625263929367065), (25, 0.8354349136352539), (202, 0.7405284643173218), (23, 0.7617705464363098), (112, 0.8857406377792358), (28, 0.7783777713775635), (74, 0.7658812403678894), (183, 0.8757026195526123), (72, 0.9499826431274414), (93, 0.8576022386550903), (204, 0.7081265449523926), (188, 0.7649178504943848), (178, 0.6822943091392517), (83, 0.8575232028961182), (142, 0.7486264109611511), (76, 0.798346757888794), (135, 0.8937368392944336), (22, 0.7628995180130005), (166, 0.7671136856079102), (165, 0.7072103023529053), (59, 0.7533891201019287), (59, 0.9211050868034363), (83, 0.8887428641319275), (261, 0.7982051372528076), (160, 0.8037620782852173), (13, 0.7617706656455994), (84, 0.7149544358253479), (106, 0.8252977132797241), (109, 0.7956148386001587), (94, 0.8000921010971069), (44, 0.8869008421897888), (276, 0.762723982334137), (73, 0.8622578978538513), (105, 0.7717534303665161), (227, 0.8406007289886475), (82, 0.7617679834365845), (247, 0.6752322912216187), (276, 0.8743170499801636), (84, 0.8208914995193481), (73, 0.795930027961731), (296, 0.7194805145263672), (64, 0.7579272985458374), (110, 0.9089281558990479), (80, 0.8424403071403503), (22, 0.7127401828765869), (113, 0.6968563199043274), (147, 0.8227338194847107), (107, 0.9508885145187378), (278, 0.7167813777923584), (54, 0.8434360027313232), (260, 0.8531033992767334), (106, 0.8475618362426758), (247, 0.8020753860473633), (104, 0.9581465125083923), (84, 0.8172581791877747), (270, 0.784244179725647), (98, 0.93397456407547), (251, 0.7976685762405396), (79, 0.7521511316299438), (93, 0.8859744071960449), (158, 0.751510500907898), (104, 0.9607291221618652), (77, 0.7726718187332153), (284, 0.7947167158126831), (119, 0.930627703666687), (197, 0.9104816913604736), (120, 0.9527772665023804), (37, 0.9007961750030518), (119, 0.928286075592041), (117, 0.9516022205352783), (251, 0.7410271167755127), (226, 0.7673612236976624), (205, 0.6895018815994263), (237, 0.6880185604095459), (231, 0.9007731676101685), (109, 0.6633743643760681), (133, 0.8582861423492432), (135, 0.9148222804069519), (38, 0.7070600390434265), (45, 0.7908338904380798), (227, 0.6538099050521851), (118, 0.9167335033416748), (127, 0.8421661853790283), (250, 0.7945559024810791), (117, 0.8761232495307922), (108, 0.7721425294876099), (203, 0.8078340888023376), (286, 0.5472071170806885), (104, 0.8578605651855469), (167, 0.6963249444961548), (133, 0.745884120464325), (119, 0.8104995489120483), (1, 0.6866281032562256), (7, 0.7150791883468628), (81, 0.902911365032196), (104, 0.8455116152763367), (97, 0.8087102174758911), (60, 0.8822101950645447), (30, 0.7622836828231812), (156, 0.9542432427406311), (185, 0.7199435830116272), (148, 0.7241355180740356), (50, 0.7848350405693054), (218, 0.7927795052528381), (204, 0.7284067869186401), (156, 0.9554059505462646), (274, 0.7114105224609375), (111, 0.8132355213165283), (58, 0.8397676944732666), (75, 0.7903296947479248), (263, 0.8226110935211182), (119, 0.7808692455291748), (298, 0.656758189201355), (65, 0.7593639492988586), (70, 0.7085697054862976), (69, 0.7793447971343994), (140, 0.7615368366241455), (161, 0.7594921588897705), (223, 0.6869497895240784), (244, 0.882922351360321), (193, 0.7385478019714355), (251, 0.7271023988723755), (197, 0.8563464283943176), (167, 0.7050431966781616), (150, 0.7853546142578125), (192, 0.8426249623298645), (145, 0.791321873664856), (9, 0.7253997325897217), (22, 0.8226853609085083), (154, 0.7644973993301392), (188, 0.7963337898254395), (191, 0.9216156601905823), (58, 0.8541027307510376), (250, 0.8332452774047852), (206, 0.7707436084747314), (234, 0.7221639752388), (135, 0.9389019012451172), (181, 0.7909802198410034), (123, 0.7496168613433838), (70, 0.6896705627441406), (182, 0.9351613521575928), (176, 0.8310354948043823), (171, 0.813912570476532), (103, 0.8235254287719727), (135, 0.9083749055862427), (207, 0.8591440916061401), (110, 0.8738579750061035), (84, 0.7148256897926331), (185, 0.7803895473480225), (183, 0.833728551864624), (250, 0.9000957608222961), (180, 0.6604366898536682), (291, 0.7635493874549866), (129, 0.6721144318580627), (121, 0.8079328536987305), (199, 0.83751380443573), (241, 0.819057822227478), (242, 0.8846604824066162), (162, 0.7499128580093384), (225, 0.857616662979126), (79, 0.7885473966598511), (157, 0.7096524238586426), (168, 0.7443767189979553), (29, 0.7775053977966309), (17, 0.8682634830474854), (243, 0.7517930865287781), (234, 0.6940614581108093), (154, 0.7287544012069702), (79, 0.7918490767478943), (148, 0.9000685214996338), (245, 0.7249162197113037), (185, 0.8126461505889893), (141, 0.8143571615219116), (181, 0.7041289806365967), (210, 0.8164132833480835), (233, 0.8231378793716431), (85, 0.7982027530670166), (218, 0.7596983909606934), (270, 0.8479220867156982), (236, 0.9518368244171143), (125, 0.906329870223999), (241, 0.9619618058204651), (226, 0.776152491569519), (210, 0.8219678997993469), (60, 0.8570032119750977), (236, 0.9466935396194458), (251, 0.7614568471908569), (53, 0.7734123468399048), (265, 0.8427337408065796), (66, 0.7410761117935181), (241, 0.958306074142456), (14, 0.8495246171951294), (88, 0.8286507725715637), (170, 0.7991378307342529), (251, 0.7102383375167847), (111, 0.8441731333732605), (262, 0.8513413667678833), (91, 0.8312538862228394), (243, 0.7491903901100159), (184, 0.8845012187957764), (31, 0.7756116986274719), (106, 0.7356720566749573), (34, 0.5834603905677795), (168, 0.823996901512146), (272, 0.8087702989578247), (205, 0.7878059148788452), (226, 0.6680264472961426), (118, 0.8127124905586243), (201, 0.9376111030578613), (101, 0.7977074980735779), (74, 0.7984777092933655), (247, 0.8687254786491394), (271, 0.9390044808387756), (10, 0.7492750883102417), (239, 0.8397111892700195), (258, 0.8376994132995605), (93, 0.8749258518218994), (50, 0.8112130165100098), (26, 0.6990346908569336), (106, 0.8505668044090271), (271, 0.941025972366333), (48, 0.8816555142402649), (278, 0.835026741027832), (38, 0.7656958699226379), (146, 0.833575963973999), (88, 0.8855991363525391), (85, 0.9176797866821289), (262, 0.8249685764312744), (244, 0.8800885677337646), (215, 0.7428743243217468), (288, 0.947555661201477), (150, 0.7908040285110474), (258, 0.5705327987670898), (107, 0.7948619723320007), (251, 0.8194981813430786), (210, 0.6310154795646667), (262, 0.8415341377258301), (288, 0.946853756904602), (298, 0.6997101902961731), (234, 0.6923851370811462), (203, 0.8354631662368774), (13, 0.8268346786499023), (130, 0.7831480503082275), (137, 0.6731739640235901), (80, 0.6004465818405151), (285, 0.7020128965377808), (20, 0.6910915374755859), (22, 0.7688831090927124), (104, 0.8360364437103271)]\n"
     ]
    }
   ],
   "source": [
    "print(ranks)\n",
    "print('******')\n",
    "print(second_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 293, 1: 7})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, greater than 95% of the inferred documents are found to be most\n",
    "similar to itself and about 5% of the time it is mistakenly most similar to\n",
    "another document. Checking the inferred-vector against a\n",
    "training-vector is a sort of 'sanity check' as to whether the model is\n",
    "behaving in a usefully consistent manner, though not a real 'accuracy' value.\n",
    "\n",
    "This is great and not entirely surprising. We can take a look at an example:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (299): Â«australia will take on france in the doubles rubber of the davis cup tennis final today with the tie levelled at wayne arthurs and todd woodbridge are scheduled to lead australia in the doubles against cedric pioline and fabrice santoro however changes can be made to the line up up to an hour before the match and australian team captain john fitzgerald suggested he might do just that we ll make team appraisal of the whole situation go over the pros and cons and make decision french team captain guy forget says he will not make changes but does not know what to expect from australia todd is the best doubles player in the world right now so expect him to play he said would probably use wayne arthurs but don know what to expect really pat rafter salvaged australia davis cup campaign yesterday with win in the second singles match rafter overcame an arm injury to defeat french number one sebastien grosjean in three sets the australian says he is happy with his form it not very pretty tennis there isn too many consistent bounces you are playing like said bit of classic old grass court rafter said rafter levelled the score after lleyton hewitt shock five set loss to nicholas escude in the first singles rubber but rafter says he felt no added pressure after hewitt defeat knew had good team to back me up even if we were down he said knew could win on the last day know the boys can win doubles so even if we were down still feel we are good enough team to win and vice versa they are good enough team to beat us as wellÂ»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d50,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (299, 0.9368760585784912): Â«australia will take on france in the doubles rubber of the davis cup tennis final today with the tie levelled at wayne arthurs and todd woodbridge are scheduled to lead australia in the doubles against cedric pioline and fabrice santoro however changes can be made to the line up up to an hour before the match and australian team captain john fitzgerald suggested he might do just that we ll make team appraisal of the whole situation go over the pros and cons and make decision french team captain guy forget says he will not make changes but does not know what to expect from australia todd is the best doubles player in the world right now so expect him to play he said would probably use wayne arthurs but don know what to expect really pat rafter salvaged australia davis cup campaign yesterday with win in the second singles match rafter overcame an arm injury to defeat french number one sebastien grosjean in three sets the australian says he is happy with his form it not very pretty tennis there isn too many consistent bounces you are playing like said bit of classic old grass court rafter said rafter levelled the score after lleyton hewitt shock five set loss to nicholas escude in the first singles rubber but rafter says he felt no added pressure after hewitt defeat knew had good team to back me up even if we were down he said knew could win on the last day know the boys can win doubles so even if we were down still feel we are good enough team to win and vice versa they are good enough team to beat us as wellÂ»\n",
      "\n",
      "SECOND-MOST (104, 0.8360364437103271): Â«australian cricket captain steve waugh has supported fast bowler brett lee after criticism of his intimidatory bowling to the south african tailenders in the first test in adelaide earlier this month lee was fined for giving new zealand tailender shane bond an unsportsmanlike send off during the third test in perth waugh says tailenders should not be protected from short pitched bowling these days you re earning big money you ve got responsibility to learn how to bat he said mean there no times like years ago when it was not professional and sort of bowlers code these days you re professional our batsmen work very hard at their batting and expect other tailenders to do likewise meanwhile waugh says his side will need to guard against complacency after convincingly winning the first test by runs waugh says despite the dominance of his side in the first test south africa can never be taken lightly it only one test match out of three or six whichever way you want to look at it so there lot of work to go he said but it nice to win the first battle definitely it gives us lot of confidence going into melbourne you know the big crowd there we love playing in front of the boxing day crowd so that will be to our advantage as well south africa begins four day match against new south wales in sydney on thursday in the lead up to the boxing day test veteran fast bowler allan donald will play in the warm up match and is likely to take his place in the team for the second test south african captain shaun pollock expects much better performance from his side in the melbourne test we still believe that we didn play to our full potential so if we can improve on our aspects the output we put out on the field will be lot better and we still believe we have side that is good enough to beat australia on our day he saidÂ»\n",
      "\n",
      "MEDIAN (28, 0.271616131067276): Â«united states federal magistrate has refused to free on bail british man accused of trying to detonate his explosives laden shoes on transatlantic flight at hearing in united states federal court federal bureau of investigation agent margaret cronin said richard reid was in possession of functioning improvised device which if placed beside an outer wall could have or would have created large hole in the fuselage of the plane the device contained an explosive called tatp us magistrate judith dein refused to grant bail for reid but left open the possibility of his release later reid is charged with intimidation and interfering with flight crew offenses that carry year jail terms no additional charges were filed he allegedly tried to set fire to his sneakers saturday on an american airlines flight from paris to miami that was diverted to boston investigators say the explosives in his shoes were powerful enough to have created major disasterÂ»\n",
      "\n",
      "LEAST (216, -0.1438172161579132): Â«senior taliban official confirmed the islamic militia would begin handing over its last bastion of kandahar to pashtun tribal leaders on friday this agreement was that taliban should surrender kandahar peacefully to the elders of these areas and we should guarantee the lives and the safety of taliban authorities and all the taliban from tomorrow should start this program former taliban ambassador to pakistan abdul salam zaeef told cnn in telephone interview he insisted that the taliban would not surrender to hamid karzai the new afghan interim leader and pashtun elder who has been cooperating with the united states to calm unrest among the southern tribes the taliban will surrender to elders not to karzai karzai and other persons which they want to enter kandahar by the support of america they don allow to enter kandahar city he said the taliban will surrender the weapons the ammunition to eldersÂ»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Document ({}): Â«{}Â»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: Â«%sÂ»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above that the most similar document (usually the same text) is has a\n",
    "similarity score approaching 1.0. However, the similarity score for the\n",
    "second-ranked documents should be significantly lower (assuming the documents\n",
    "are in fact different) and the reasoning becomes obvious when we examine the\n",
    "text itself.\n",
    "\n",
    "We can run the next cell repeatedly to see a sampling other target-document\n",
    "comparisons.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Document (148): Â«the israeli government has declared palestinian leader yasser arafat irrelevant and has decided to break off all contacts with him the dramatic move followed palestinian ambush on bus carrying israeli settlers in the west bank that killed people and double suicide attack in the gaza strip that injured four israelis in response israeli jets and helicopters have attacked palestinian targets across the gaza strip and the west bank the israelis say they hold mr arafat directly responsible for the latest incidents and will have nothing to do with him the government position was spelt out by spokesman raanan gissin in no way does it imply or was there any directive to hurt to harm or to expel arafat personally he said we are not attacking arafat personally we don have quarrel with arafat the person we have real quarrel and real fight and struggle against terrorism against arafat when he represents terrorism when he support terrorismÂ»\n",
      "\n",
      "Similar Document (60, 0.8822101950645447): Â«israel has rejected palestinian leader yasser arafat bid to make his annual visit to bethlehem for christmas eve during an security cabinet meeting early today the security cabinet made its decision based on the fact that arafat is not working to dismantle terror organizations and to foil terror attacks against israel and to arrest and punish terrorists including the murderers of tourism minister rhavam zeevi statement from prime minister ariel sharon office said earlier mr arafat declared he would walk to bethlehem for christmas eve mass if he has to if israeli authorities refused him access to the biblical town mr arafat statement comes as palestinians in gaza buried six teenagers killed in the worst internal palestinian violence in seven years the funerals in gaza were peaceful with palestinian police staying away and mourners agreeing no weapons were to be carried this has been difficult week for yasser arafat he put his reputation on the line by ordering the arrest of some key palestinian militants in the most important radical group hamas then declared an end to its campaign of suicide bombings and other attacks against israel another smaller but important radical group islamic jihad might follow hamas lead but the key to all this is israel reaction if it eases its blockade of towns in the west bank then yasser arafat will have something to show for his effortsÂ»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the corpus and infer a vector from the model\n",
    "import random\n",
    "doc_id = random.randint(0, len(train_corpus) - 1)\n",
    "\n",
    "# Compare and print the second-most-similar document\n",
    "print('Train Document ({}): Â«{}Â»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "sim_id = second_ranks[doc_id]\n",
    "print('Similar Document {}: Â«{}Â»\\n'.format(sim_id, ' '.join(train_corpus[sim_id[0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Model\n",
    "-----------------\n",
    "\n",
    "Using the same approach above, we'll infer the vector for a randomly chosen\n",
    "test document, and compare the document to our model by eye.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.3858131  -0.52708906  1.4218415  -0.09822421 -0.01559543 -0.08172829\n",
      " -1.072969    1.0291349  -0.17651416  0.17764072 -0.7391784   1.7546471\n",
      "  0.18698724 -0.41928306 -0.8157573  -0.84245527 -0.3420765  -0.49765253\n",
      " -0.5656549   0.30210254  1.7268561  -0.15544082 -0.24494027  2.181014\n",
      "  0.6312407   0.927488    0.99560535 -1.9537703   0.3402982   0.05598187\n",
      "  1.0644572  -0.05322277 -0.8752399   0.4873316   0.9833575   0.05787877\n",
      "  1.1370159  -1.0773258  -0.17170334 -0.5841276   0.5860302   1.771755\n",
      "  0.4847734   0.46831453  0.0275401  -0.54280305 -1.788937   -1.4750798\n",
      " -0.11820523  0.35908893]\n",
      "Test Document (13): Â«queensland senator andrew bartlett has launched last minute bid to rescue the australian democrats from split that threatens to destroy the party with nominations for the party leadership to close on wednesday night senator bartlett met last night with deputy leader aden ridgeway to offer him place on unity ticket and set up reform process to begin healing the party wounds party sources said senator ridgeway who turned against former leader natasha stott despoja is still expected to contest the leadership against one of her two supporters senator bartlett or brian greig installed as interim leader by the party executive last thursdayÂ»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d50,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (131, 0.6174739599227905): Â«the new solomon islands prime minister has told his people that there are tough times ahead sir allan kemakeza the parliamentary leader of the people alliance party was elected prime minister on the first ballot sir allan heads up team consisting of the surviving members of the outgoing government and large grouping of newly elected independents one of those held one of the most senior positions in the malaita eagle force militia that conducted last year coup while others who have backed him were elected after being endorsed by the rival guadalcanal militia the isatabu freedom movement that ethnic conflict has left the solomons economy close to collapse and hundreds of high powered guns remain with the militants sir allan is putting his trust in god the times ahead are not going to be easy he said these will be times of sacrifice sir allan says that he also hopes to get agreement on disarming rival militias in the country within his first days in office in an attempt to remove any remaining high powered weapons from the community he believes it was his contacts with the grass root militias on both sides of the ethnic war that led to the success of the townsville peace conference that brought the war to halt sir allan former policeman says the police force part of which took part in last year coup needs to be overhauled both must go together the disarmament program as well as the restructuring of the police force he said he says law and order will be one of his government priorities palestinian leader yasser arafat call for an end to attacks on israelis has been met with mixture of hope scepticism and defiance under enormous international pressure to halt the violence mr arafat has called for halt to all armed operations against israel including suicide bombings and vowed that the perpetrators would be punished france britain and the united states have welcomed the announcement the israeli cabinet minister ephraim sneh says while it is positive sign the palestinian authority has to act on its words if he proves that he really means to act very very forcefully sincerely effectively and seriously against the islamic jihad and hamas and his own tanzin movement that will be positive sign he saidÂ»\n",
      "\n",
      "MEDIAN (208, 0.18487559258937836): Â«israeli tanks and troops have launched two incursions in the gaza strip near the palestinian self rule city of khan yunis arresting several people and searching houses witnesses say undercover soldiers wearing masks arrived first followed by tanks and additional troops palestinian officials say they were looking for iffam abu daka one of the leaders of the militant democratic front earlier an israeli fighter jet struck three buildings in the palestinian police headquarters in gaza city injuring at least people palestinian officials say two four storey buildings inside the compound were engulfed in flames and destroyedÂ»\n",
      "\n",
      "LEAST (272, -0.2784530520439148): Â«the storm clean up in sydney will resume in earnest this morning as fresh crews are brought in to replace state emergency service ses personnel who worked through the night the storm hit sydney early yesterday afternoon and two schoolgirls died when tree fell on them at reserve at hornsby heights in the city north number of other people were injured as the storm brought down trees and power poles and lifted roofs new south wales emergency services minister bob debus says welfare and emergency funding arrangements have been put in place with the declaration of natural disaster areas in campbeltown hornsby warringah and kurringai welfare services become available if they are needed local government is refunded any money it spends on the clean up or that it spends on repairing its own infrastructure low interest loans if they are needed are available to small business to help them get back on their feet again mr debus said energy australia says power has been restored to customers and work will continue today to reconnect those still without electricity energy australia peter leete says work will concentrate around the worst hit areas the worst of the problems we have still got are in sydney northern suburbs which seem to be the worst hit of all and that around hornsby st ives turramurra and frenches forest mr leete said four hundred ses volunteers are responding to more than calls for assistance the volunteers have worked throughout the night to remove trees from homes and roads the ses laura goodin says it will take several days before the damage is cleared up while the ses has received fewer calls for help than in the storm two weeks ago many of the jobs in this storm are actually quite complicated involving large trees or extensively damaged homes and businesses we re estimating that most of the tasks will be completed by friday if no new storms develop ms goodin said outside sydney the storms caused damage in north east of the state and the lower hunter scores of homes and farm buildings have been damaged and literally hundreds of trees have been brought down the storms accompanied by gale force winds and hail left large areas around tamworth gunnedah and quirindi without electricity and telephone servicesÂ»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(test_corpus) - 1)\n",
    "inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "print(inferred_vector)\n",
    "sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document ({}): Â«{}Â»\\n'.format(doc_id, ' '.join(test_corpus[doc_id])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: Â«%sÂ»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "----------\n",
    "\n",
    "Let's review what we've seen in this tutorial:\n",
    "\n",
    "0. Review the relevant models: bag-of-words, Word2Vec, Doc2Vec\n",
    "1. Load and preprocess the training and test corpora (see `core_concepts_corpus`)\n",
    "2. Train a Doc2Vec `core_concepts_model` model using the training corpus\n",
    "3. Demonstrate how the trained model can be used to infer a `core_concepts_vector`\n",
    "4. Assess the model\n",
    "5. Test the model on the test corpus\n",
    "\n",
    "That's it! Doc2Vec is a great way to explore relationships between documents.\n",
    "\n",
    "Additional Resources\n",
    "--------------------\n",
    "\n",
    "If you'd like to know more about the subject matter of this tutorial, check out the links below.\n",
    "\n",
    "* `Word2Vec Paper <https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf>`_\n",
    "* `Doc2Vec Paper <https://cs.stanford.edu/~quocle/paragraph_vector.pdf>`_\n",
    "* `Dr. Michael D. Lee's Website <http://faculty.sites.uci.edu/mdlee>`_\n",
    "* `Lee Corpus <http://faculty.sites.uci.edu/mdlee/similarity-data/>`__\n",
    "* `IMDB Doc2Vec Tutorial <doc2vec-IMDB.ipynb>`_\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
