{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook is to split the list of audio files into chunk with chunk size of 3 Sec.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import librosa.display\n",
    "from pathlib import Path \n",
    "import random\n",
    "import librosa\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audioClassification(audio, sr, refID, melSpectogramPath):\n",
    "    #Split audio in chunks with each chunk size of 3 sec.\n",
    "    split_audio_duration = 3*sr\n",
    "    startIndex = 0\n",
    "    image_predictions = {} \n",
    "\n",
    "    if len(audio) > split_audio_duration:\n",
    "        iteration = int(np.ceil(len(audio)/split_audio_duration))\n",
    "        for i in range(iteration):\n",
    "            endIndex = startIndex + split_audio_duration\n",
    "            if endIndex > len(audio):\n",
    "                endIndex = len(audio)\n",
    "            split_audio = audio[startIndex: endIndex]\n",
    "            startIndex = endIndex + 1\n",
    "            \n",
    "            #Generate MelSpectogram Images\n",
    "            imagePath = generateMelspectrogram(split_audio, sr, melSpectogramPath, refID, i)\n",
    "            #image_predictions[str(i)] = self.predictAudioImageClass(imagePath)\n",
    "    else:\n",
    "        split_audio = audio[startIndex: len(audio)]\n",
    "        self.generateMelspectrogram(split_audio, sr, melSpectogramPath, refID, 0)\n",
    "\n",
    "    return image_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateMelspectrogram(split_audio, sr, melSpectogramPath, refID, i):\n",
    "    fig = plt.figure(figsize=[0.72, 0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "\n",
    "    fileName = os.path.join(melSpectogramPath, refID + '_' + str(i) + '.png')\n",
    "\n",
    "    S = librosa.feature.melspectrogram(y=split_audio, sr=sr)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    plt.savefig(fileName, dpi=400, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close('all')\n",
    "    return fileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = '/audio-processing'\n",
    "audio_path = os.path.join(basepath,'audio') \n",
    "melSpectogramPath = os.path.join(basepath,'mel-spectogram-images') \n",
    "os.makedirs(melSpectogramPath)  \n",
    "\n",
    "#Processing all audio files present into the folder\n",
    "files= list(Path(audio_path).glob('*.wav'))\n",
    "for audio_file in files:\n",
    "    file = str(audio_file).split('\\\\')[-1].split('.')[0]\n",
    "    print('processing file: ', file)\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "    audioClassification(audio, sr, file, melSpectogramPath)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
