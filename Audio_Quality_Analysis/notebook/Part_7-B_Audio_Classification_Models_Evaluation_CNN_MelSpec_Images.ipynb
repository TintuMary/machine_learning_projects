{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook is how to evaluate CNN Model which is built upon MelSpectogram images. \n",
    "A. Evaluation against good and bad (noise) signals\n",
    "B. Evaluate real audio signals to see whether they do contain noise or not\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.models.load_model('/Models/CNN-Image-MelSpc-0422/AudioQuality_MobileNet_TL_GD_V1_04222.h5',custom_objects={'KerasLayer':hub.KerasLayer})\n",
    "model1.load_weights('/Models/CNN-Image-MelSpc-0422/AudioQualityWeights_MobileNet_TL_GD_V1_0422.h5')\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Models/CNN-Image-MelSpc-0422/labelEncoderFile_04222020_v1.pkl', 'rb') as fid:\n",
    "    le_loaded = pickle.load(fid)\n",
    "le_loaded.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImagesForMixData(model):\n",
    "    parent_dir = 'D:/Abhishek/Machine Learning Models/Audio Data Analysis/Models/spectrogram'\n",
    "    sub_dirs= ['noise', 'good']\n",
    "    sub_sub_good_dirs= ['flicker', 'spear_good', 'urban']\n",
    "    sub_sub_noise_dirs= ['audio_mixed_noise', 'spear_noise', 'only_noise']\n",
    "    file_ext = \"*.png\"\n",
    "    \n",
    "    images = []\n",
    "    lables = []\n",
    "    predictLable = []\n",
    "    img_width, img_height = 224, 224\n",
    "    for l, sub_dir in enumerate(sub_dirs):\n",
    "        print('Processing folder: ', sub_dir)\n",
    "        if sub_dir == 'good':\n",
    "            processed_sub_dir = sub_sub_good_dirs\n",
    "        \n",
    "        if sub_dir == 'noise':\n",
    "            processed_sub_dir = sub_sub_noise_dirs   \n",
    "            \n",
    "        for l, sub_sub_dir in enumerate(processed_sub_dir):\n",
    "            \n",
    "            for fn in glob.glob(os.path.join(parent_dir, sub_dir, sub_sub_dir, file_ext)):\n",
    "\n",
    "                img = image.load_img(fn, target_size=(img_width, img_height))\n",
    "                img = image.img_to_array(img)\n",
    "                \n",
    "                img = np.expand_dims(img, axis=0)\n",
    "                img=img/255\n",
    "                \n",
    "                predictLable.append(model.predict_classes(img)[0])\n",
    "                images.append(img)\n",
    "\n",
    "                if sub_dir == 'noise':\n",
    "                    lables.append(1)\n",
    "\n",
    "                if sub_dir == 'good':\n",
    "                    lables.append(0)\n",
    "\n",
    "    return predictLable, lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_result, actualresult_result = getImagesForMixData(model1)\n",
    "\n",
    "classification_report = metrics.classification_report(actualresult_result, prediction_result)\n",
    "print(\"Classification report: \\n\", classification_report)\n",
    "confusion_matrix = metrics.confusion_matrix(actualresult_result, prediction_result)\n",
    "print(\"Confusion matrix: \\n\",confusion_matrix)\n",
    "\n",
    "print(\"Accuracy Score: \", accuracy_score(actualresult_result, prediction_result))\n",
    "print(\"F1 Score: \", f1_score(actualresult_result, prediction_result, average='weighted'))\n",
    "print(\"Precision Score: \", precision_score(actualresult_result, prediction_result, average='weighted'))\n",
    "print(\"Recall Score: \", recall_score(actualresult_result, prediction_result, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audioImageExtraction(audio, sr, refID, melSpectogramPath, model, le):\n",
    "    split_audio_duration = 1*sr\n",
    "    startIndex = 0\n",
    "    image_predictions = {} \n",
    "\n",
    "    if len(audio) > split_audio_duration:\n",
    "        iteration = int(np.ceil(len(audio)/split_audio_duration))\n",
    "        for i in range(iteration):\n",
    "            endIndex = startIndex + split_audio_duration\n",
    "            if endIndex > len(audio):\n",
    "                endIndex = len(audio)\n",
    "            split_audio = audio[startIndex: endIndex]\n",
    "            startIndex = endIndex + 1\n",
    "            imagePath = generateMelspectrogram(split_audio, sr, melSpectogramPath, refID, i)\n",
    "            image_predictions[str(i)] = predictAudioImageClass(imagePath)\n",
    "    else:\n",
    "        split_audio = audio[startIndex: len(audio)]\n",
    "        self.generateMelspectrogram(split_audio, sr, melSpectogramPath, refID, 0)\n",
    "\n",
    "    return image_predictions\n",
    "\n",
    "def generateMelspectrogram(split_audio, sr, melSpectogramPath, refID, i):\n",
    "    fig = plt.figure(figsize=[0.72, 0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "\n",
    "    fileName = os.path.join(melSpectogramPath, refID + '_' + str(i) + '.png')\n",
    "\n",
    "    S = librosa.feature.melspectrogram(y=split_audio, sr=sr)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    plt.savefig(fileName, dpi=400, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close('all')\n",
    "    return fileName\n",
    "\n",
    "def predictAudioImageClass(imagePath, model, le):\n",
    "        newsize = (224, 224)\n",
    "        img = cv2.imread(imagePath)\n",
    "        img = cv2.resize(img, newsize, interpolation=cv2.INTER_AREA)\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = img / 255\n",
    "        prediction_result = model.predict_classes(img)[0]\n",
    "        predictionValue = le.inverse_transform([prediction_result])\n",
    "        return predictionValue[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melSpectogramPath = Path('/mel-spectogram-images')   \n",
    "audio_path = Path('/audio/') \n",
    "\n",
    "files= list(Path(audio_path).glob('*.wav'))\n",
    "for audio_file in files:\n",
    "    file = str(audio_file).split('\\\\')[-1].split('.')[0]\n",
    "    print('processing file: ', file)\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "    predictions = audioImageExtraction(audio, sr, file, melSpectogramPath, model, le_loaded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorFlowEnv",
   "language": "python",
   "name": "tensorflowenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
