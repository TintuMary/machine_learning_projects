{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook is how to evaluate CNN Model which is built upon MFCC Numerica values. \n",
    "A. Evaluation against good and bad (noise) signals\n",
    "B. Evaluation aginst mixed signal\n",
    "C. Evaluation against Spear data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "from keras import models\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pad_len = 174\n",
    "\n",
    "def extract_features_with_padding(audio, sample_rate):\n",
    "    try:\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \")\n",
    "        return None \n",
    "     \n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_from_sound(signal,noise,SNR):\n",
    "    try:\n",
    "        RMS_s=math.sqrt(np.mean(signal**2))\n",
    "        #required RMS of noise\n",
    "        RMS_n=math.sqrt(RMS_s**2/(pow(10,SNR/20)))\n",
    "\n",
    "        #current RMS of noise\n",
    "        RMS_n_current=math.sqrt(np.mean(noise**2))\n",
    "        noise=noise*(RMS_n/RMS_n_current)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None\n",
    "    \n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sound(file_path):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_path, sr=22050, res_type='kaiser_fast') \n",
    "        trim_signal = librosa.effects.trim(audio)\n",
    "        total_duration = 4*sample_rate\n",
    "        split_signal = trim_signal[0]\n",
    "        if len(trim_signal[0]) > total_duration:\n",
    "            split_signal=trim_signal[0][0:total_duration]\n",
    "        \n",
    "        aud_feature = extract_features_with_padding(split_signal, sample_rate)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "    return aud_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateAgainstMixData():\n",
    "    parent_dir = '/Models/audio_data'\n",
    "    sub_dirs= ['noise', 'good']\n",
    "    sub_sub_good_dirs= ['flicker', 'spear_good', 'urban']\n",
    "    sub_sub_noise_dirs= ['audio_mixed_noise', 'spear_noise', 'only_noise']\n",
    "    file_ext = \"*.wav\"\n",
    "    \n",
    "    features = []\n",
    "\n",
    "    for l, sub_dir in enumerate(sub_dirs):\n",
    "        print('Processing folder: ', sub_dir)\n",
    "        if sub_dir == 'good':\n",
    "            processed_sub_dir = sub_sub_good_dirs\n",
    "        \n",
    "        if sub_dir == 'noise':\n",
    "            processed_sub_dir = sub_sub_noise_dirs   \n",
    "            \n",
    "        for l, sub_sub_dir in enumerate(processed_sub_dir):\n",
    "            \n",
    "            for fn in glob.glob(os.path.join(parent_dir, sub_dir, sub_sub_dir, file_ext)):\n",
    "\n",
    "                feature = process_sound(fn)\n",
    "\n",
    "                if sub_dir == 'noise':\n",
    "                    features.append([feature, 'noise'])\n",
    "\n",
    "                if sub_dir == 'good':\n",
    "                    features.append([feature, 'good'])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 39, 173, 16)       80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 19, 86, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 19, 86, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 18, 85, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 9, 42, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 9, 42, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 41, 64)         8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 4, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 4, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 3, 19, 128)        32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 1, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 43,570\n",
      "Trainable params: 43,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model = tf.keras.models.load_model('/content/drive/My Drive/Image_Quality_Analysis/model/ImageQuality_TL_GD_V1_0408.h5',custom_objects={'KerasLayer':hub.KerasLayer})\n",
    "model = models.load_model('/Models/CNN-MFCC-0418/SoundClassification_model_With_good_noise_V1_04182020_v1.h5')\n",
    "model.load_weights('SoundClassification_Weight_With_good_noise_V1_04182020_v1.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\618757\\Anaconda3\\envs\\tensorFlowEnv\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22.2.post1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['good', 'noise'], dtype='<U5')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/Models/CNN-MFCC-0418/labelEncoderFile_With_good_noise_LE_04182020_v1.pkl', 'rb') as fid:\n",
    "    le_loaded = pickle.load(fid)\n",
    "le_loaded.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder:  noise\n",
      "Processing folder:  good\n",
      "total feature lenght:  90\n",
      "['good' 'good' 'noise' 'noise' 'noise' 'good' 'good' 'good' 'good' 'good'\n",
      " 'good' 'noise' 'good' 'noise' 'good' 'good' 'good' 'good' 'noise' 'good'\n",
      " 'good' 'good' 'good' 'noise' 'good' 'noise' 'noise' 'good' 'good' 'good'\n",
      " 'noise' 'noise' 'noise' 'good' 'good' 'good' 'noise' 'noise' 'good'\n",
      " 'good' 'noise' 'good' 'noise' 'noise' 'noise' 'noise' 'noise' 'noise'\n",
      " 'noise' 'noise' 'noise' 'noise' 'noise' 'noise' 'noise' 'noise' 'noise'\n",
      " 'noise' 'noise' 'noise' 'good' 'good' 'good' 'good' 'good' 'good' 'good'\n",
      " 'good' 'good' 'good' 'good' 'good' 'good' 'good' 'good' 'good' 'good'\n",
      " 'good' 'good' 'good' 'good' 'good' 'noise' 'noise' 'good' 'good' 'good'\n",
      " 'good' 'good' 'good']\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        good       0.51      0.93      0.66        30\n",
      "       noise       0.94      0.55      0.69        60\n",
      "\n",
      "    accuracy                           0.68        90\n",
      "   macro avg       0.73      0.74      0.68        90\n",
      "weighted avg       0.80      0.68      0.68        90\n",
      "\n",
      "Confusion matrix: \n",
      " [[28  2]\n",
      " [27 33]]\n",
      "Accuracy Score:  0.6777777777777778\n",
      "F1 Score:  0.682765737874097\n",
      "Precision Score:  0.7982683982683981\n",
      "Recall Score:  0.6777777777777778\n"
     ]
    }
   ],
   "source": [
    "# This Section is to evaluate model agaisnt Good/Noise data\n",
    "\n",
    "features = validateAgainstMixData()\n",
    "\n",
    "print('total feature lenght: ' , len(features))\n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "actualresult_result = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "X = np.expand_dims(X, axis=3)\n",
    "\n",
    "predict = model.predict(X)\n",
    "predict=np.round(predict,decimals=5)\n",
    "result = map(lambda v : np.argmax(v), predict)\n",
    "prediction_result = np.array(list(result))\n",
    "prediction_result = le_loaded.inverse_transform(prediction_result)\n",
    "print(prediction_result)\n",
    "\n",
    "\n",
    "classification_report = metrics.classification_report(actualresult_result, prediction_result)\n",
    "print(\"Classification report: \\n\", classification_report)\n",
    "confusion_matrix = metrics.confusion_matrix(actualresult_result, prediction_result)\n",
    "print(\"Confusion matrix: \\n\",confusion_matrix)\n",
    "\n",
    "print(\"Accuracy Score: \", accuracy_score(actualresult_result, prediction_result))\n",
    "print(\"F1 Score: \", f1_score(actualresult_result, prediction_result, average='weighted'))\n",
    "print(\"Precision Score: \", precision_score(actualresult_result, prediction_result, average='weighted'))\n",
    "print(\"Recall Score: \", recall_score(actualresult_result, prediction_result, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Section is to evaluate model agaisnt mixed data\n",
    "\n",
    "jack_hammer3_file_path='102305-6-0-0-dog-bark.wav'\n",
    "signal, sr = librosa.load(jack_hammer3_file_path,sr=22050,  res_type='kaiser_fast')\n",
    "\n",
    "noise_file = 'Air_FX_01.wav'\n",
    "noise_sample1, sr1 = librosa.load(noise_file, sr=None)\n",
    "noise_sample = noise_sample1+noise_sample1+noise_sample1\n",
    "\n",
    "if(len(noise_sample) > len(signal)):\n",
    "    noise_sample=noise_sample[0:len(signal)]\n",
    "\n",
    "if(len(noise_sample) < len(signal)):\n",
    "    signal=signal[0:len(noise_sample)]\n",
    "\n",
    "noise3=get_noise_from_sound(signal,noise_sample,SNR=56)\n",
    "if noise3 is not None:\n",
    "    signal_noise3=signal+noise3\n",
    "\n",
    "    mfcc = extract_features_with_padding(signal_noise3, sr)\n",
    "    if mfcc is not None:\n",
    "        class_label = noise_file\n",
    "        mfcc = np.array([mfcc])\n",
    "        mfcc = np.expand_dims(mfcc, axis=3)\n",
    "                    \n",
    "\n",
    "predict = model.predict(mfcc)\n",
    "predict=np.round(predict,decimals=5)\n",
    "result = map(lambda v : np.argmax(v), predict)\n",
    "prediction_result = np.array(list(result))\n",
    "print(prediction_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Section is to evaluate model agaisnt Spear data\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "features = []\n",
    "\n",
    "parent_dir = '/SpEAR-speech-database-master/data'\n",
    "sub_dirs= ['Lombard', 'Monaural', 'Noisy_Recordings', 'TIMIT']\n",
    "sub_dirs= ['noise', 'good']\n",
    "file_ext = \"*.wav\"\n",
    "\n",
    "file_names = []\n",
    "for l, sub_dir in enumerate(sub_dirs):\n",
    "    print('Processing folder: ', sub_dir)\n",
    "    for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "        feature = process_sound(fn)\n",
    "        file_names.append(sub_dir+'/'+fn)\n",
    "        \n",
    "        if sub_dir == 'confusion':\n",
    "            features.append([feature, 'noise'])\n",
    "            \n",
    "        if sub_dir == 'Lombard':\n",
    "            features.append([feature, 'noise'])\n",
    "            \n",
    "        if sub_dir == 'Monaural':\n",
    "            features.append([feature, 'good'])\n",
    "            \n",
    "        if sub_dir == 'Noisy_Recordings':\n",
    "            features.append([feature, 'noise'])\n",
    "            \n",
    "        if sub_dir == 'noise':\n",
    "            features.append([feature, 'noise'])\n",
    "            \n",
    "        if sub_dir == 'good':\n",
    "            features.append([feature, 'good'])\n",
    "            \n",
    "        if sub_dir == 'TIMIT':\n",
    "            features.append([feature, 'good'])\n",
    "\n",
    "\n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "actualresult_result = np.array(featuresdf.class_label.tolist())\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "X = np.expand_dims(X, axis=3)\n",
    "\n",
    "predict = model.predict(X)\n",
    "predict=np.round(predict,decimals=5)\n",
    "result = map(lambda v : np.argmax(v), predict)\n",
    "prediction_result = np.array(list(result))\n",
    "prediction_result = le_loaded.inverse_transform(prediction_result)\n",
    "\n",
    "for i in range(len(prediction_result)):\n",
    "    print(file_names[i] , ' : ', prediction_result[i])\n",
    "\n",
    "\n",
    "classification_report = metrics.classification_report(actualresult_result, prediction_result)\n",
    "print(\"Classification report: \\n\", classification_report)\n",
    "confusion_matrix = metrics.confusion_matrix(actualresult_result, prediction_result)\n",
    "print(\"Confusion matrix: \\n\",confusion_matrix)\n",
    "\n",
    "print(\"Accuracy Score: \", accuracy_score(actualresult_result, prediction_result))\n",
    "print(\"F1 Score: \", f1_score(actualresult_result, prediction_result, average='weighted'))\n",
    "print(\"Precision Score: \", precision_score(actualresult_result, prediction_result, average='weighted'))\n",
    "print(\"Recall Score: \", recall_score(actualresult_result, prediction_result, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorFlowEnv",
   "language": "python",
   "name": "tensorflowenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
