{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Why do we need HDF5 file - Its an efficeint way to handle Image processing while model building.\n",
    "It helps in reducing out of meory error. \n",
    "\n",
    "This notebook basically explains- \n",
    "A. How to generate HDF5 file from Images.\n",
    "B. How to extract files from HDF5 file\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import glob\n",
    "import numpy as np\n",
    "import h5py\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_path = 'Audio_Classification_Train_HDF5_0423_v1_.hdf5'  # file path for the created .hdf5 file\n",
    "train_path = '/dataset_1/train/*/*.png' # the original data path\n",
    "shuffle_data = True  # shuffle the addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11203\n"
     ]
    }
   ],
   "source": [
    "# First part - read the images and store into variable\n",
    "addrs = glob.glob(train_path)\n",
    "labels = [0 if 'good' in addr else 1 for addr in addrs]\n",
    "\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if shuffle_data:\n",
    "    c = list(zip(addrs, labels))  # use zip() to bind the images and labels together\n",
    "    shuffle(c)\n",
    "\n",
    "    (addrs, labels) = zip(*c)  # *c is used to separate all the tuples in the list c,\n",
    "    # \"addrs\" then contains all the shuffled paths and\n",
    "    # \"labels\" contains all the shuffled labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11191\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# Second Part - Split between train and test data\n",
    "\n",
    "train_addrs = addrs[0:int(0.999 * len(addrs))]\n",
    "train_labels = labels[0:int(0.999 * len(labels))]\n",
    "\n",
    "test_addrs = addrs[int(0.999 * len(addrs)):]\n",
    "test_labels = labels[int(0.999 * len(labels)):]\n",
    "\n",
    "print(len(train_addrs))\n",
    "print(len(test_addrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd Part - Initialize HDF5 file object.\n",
    "\n",
    "train_shape = (len(train_addrs), 224, 224, 3)\n",
    "test_shape = (len(test_addrs), 224, 224, 3)\n",
    "\n",
    "# open a hdf5 file and create earrays\n",
    "f = h5py.File(hdf5_path, mode='w')\n",
    "\n",
    "# PIL.Image: the pixels range is 0-255,dtype is uint.\n",
    "# matplotlib: the pixels range is 0-1,dtype is float.\n",
    "f.create_dataset(\"train_img\", train_shape, np.uint8)\n",
    "f.create_dataset(\"test_img\", test_shape, np.uint8)\n",
    "\n",
    "# the \".create_dataset\" object is like a dictionary, the \"train_labels\" is the key.\n",
    "f.create_dataset(\"train_labels\", (len(train_addrs),), np.uint8)\n",
    "f[\"train_labels\"][...] = train_labels\n",
    "\n",
    "f.create_dataset(\"test_labels\", (len(test_addrs),), np.uint8)\n",
    "f[\"test_labels\"][...] = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 1000/11191\n",
      "Train data: 2000/11191\n",
      "Train data: 3000/11191\n",
      "Train data: 4000/11191\n",
      "Train data: 5000/11191\n",
      "Train data: 6000/11191\n",
      "Train data: 7000/11191\n",
      "Train data: 8000/11191\n",
      "Train data: 9000/11191\n",
      "Train data: 10000/11191\n",
      "Train data: 11000/11191\n"
     ]
    }
   ],
   "source": [
    "######################## 4th part: write the images into HDF5 object #########################\n",
    "\n",
    "# loop over train paths\n",
    "for i in range(len(train_addrs)):\n",
    "\n",
    "    if i % 1000 == 0 and i > 1:\n",
    "        print('Train data: {}/{}'.format(i, len(train_addrs)))\n",
    "    try:\n",
    "        addr = train_addrs[i]\n",
    "        img = cv2.imread(addr)\n",
    "        img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)  # resize to (128,128)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # cv2 load images as BGR, convert it to RGB\n",
    "        f[\"train_img\"][i, ...] = img[None]\n",
    "    except Exception as e:\n",
    "        print('Error in: ', i)\n",
    "\n",
    "# loop over test paths\n",
    "for i in range(len(test_addrs)):\n",
    "\n",
    "    if i % 1000 == 0 and i > 1:\n",
    "        print('Test data: {}/{}'.format(i, len(test_addrs)))\n",
    "    try:\n",
    "        addr = test_addrs[i]\n",
    "        img = cv2.imread(addr)\n",
    "        img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        f[\"test_img\"][i, ...] = img[None]\n",
    "    except Exception as e:\n",
    "        print('Error in: ', i)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11191\n"
     ]
    }
   ],
   "source": [
    "# 5th part - Read HDF5 file and extract content of it\n",
    "\n",
    "dataset = h5py.File(hdf5_path, \"r\")\n",
    "train_labels=np.array(dataset[\"train_labels\"])\n",
    "train_labels = train_labels.reshape((len(train_labels),-1))\n",
    "print((len(train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=(dataset['train_img'])[0]\n",
    "img=img/255.\n",
    "img.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorFlowEnv",
   "language": "python",
   "name": "tensorflowenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
