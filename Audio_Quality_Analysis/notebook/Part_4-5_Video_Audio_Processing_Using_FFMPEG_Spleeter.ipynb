{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook basically explains about FFMPEG library usage- \n",
    "A. How to use FFMPEG library to split vide into multiple chunks\n",
    "B. How to use FFMPEG library to extract audio from video file\n",
    "C. How to get complete video/audio file duration \n",
    "D. How to detect silence using FFMPEG library\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import IPython.display as ipd\n",
    "# % pylab inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob \n",
    "import librosa.display\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_video(input_video_file):\n",
    "    '''\n",
    "    Command line command to split vide into chunks using ffmpeg\n",
    "    ffmpeg -i input.mp4 -c copy -map 0 -segment_time 00:20:00 -f segment -reset_timestamps 1 output%03d.mp4\n",
    "    '''\n",
    "    extract_sound_cmd = [\n",
    "         'ffmpeg',\n",
    "         '-y',  # overwrite if exists\n",
    "         '-i', input_video_file,\n",
    "         '-c', 'copy',\n",
    "         '-map', '0',\n",
    "         '-segment_time', '00:10:00',\n",
    "         '-f', 'segment',\n",
    "         '-reset_timestamps', '1',\n",
    "         '-loglevel', 'error',\n",
    "         \n",
    "         'D:/Abhishek/Machine Learning Models/Subtitle-Sync/github-repo/SubtitleSynchronizer/data/THENUN/video_split/video%03d.mp4'\n",
    "     ]\n",
    "    output = subprocess.call(extract_sound_cmd)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio():\n",
    "    input_video_file = '/THENUN.mp4'\n",
    "    output_sound_file = '/THENUN.flac'\n",
    "    \n",
    "    extract_sound_cmd = [\n",
    "         'ffmpeg',\n",
    "         '-y',  # overwrite if exists\n",
    "         '-loglevel', 'error',\n",
    "         '-i', input_video_file,  # input\n",
    "         '-ac', '1',  # convert to mono\n",
    "         output_sound_file\n",
    "     ]\n",
    "     subprocess.call(extract_sound_cmd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def detect_silence_using_ffmpeg():\n",
    "    '''\n",
    "    Command line command to detect silence range using ffmpeg\n",
    "    ffmpeg -i \"input.mov\" -af silencedetect=noise=-30dB:d=0.5 -f null - 2> vol.txt\n",
    "    '''\n",
    "    input_video_file = 'D:/Abhishek/Machine Learning Models/Subtitle-Sync/github-repo/SubtitleSynchronizer/data/THENUN.mp4'\n",
    "\n",
    "    extract_sound_cmd = [\n",
    "         'ffmpeg',\n",
    "         '-i', input_video_file,\n",
    "         '-af', 'silencedetect=noise=-30dB:d=0.5',\n",
    "         '-f', 'null', '-', '2>',\n",
    "         'vol.txt'\n",
    "     ]\n",
    "    output = subprocess.call(extract_sound_cmd)\n",
    "    print(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_length(filename):\n",
    "    result = subprocess.run([\"ffprobe\", \"-v\", \"error\", \"-show_entries\",\n",
    "                             \"format=duration\", \"-of\",\n",
    "                             \"default=noprint_wrappers=1:nokey=1\", filename],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT)\n",
    "    return float(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitAudio(audio, sr):\n",
    "    #Split audio in chunks with each chunk size of 3 sec.\n",
    "    split_audio_duration = 3*sr\n",
    "    startIndex = 0\n",
    "    image_predictions = {} \n",
    "\n",
    "    if len(audio) > split_audio_duration:\n",
    "        iteration = int(np.ceil(len(audio)/split_audio_duration))\n",
    "        for i in range(iteration):\n",
    "            endIndex = startIndex + split_audio_duration\n",
    "            if endIndex > len(audio):\n",
    "                endIndex = len(audio)\n",
    "            split_audio = audio[startIndex: endIndex]\n",
    "            startIndex = endIndex + 1\n",
    "            \n",
    "            extractVocalSignals(split_audio, sr)\n",
    "    else:\n",
    "        split_audio = audio[startIndex: len(audio)]\n",
    "        extractVocalSignals(split_audio, sr)\n",
    "\n",
    "    return image_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractVocalSignals(split_audio, sr):\n",
    "    extract_sound_cmd = [\n",
    "         'spleeter',\n",
    "         'separate',  # overwrite if exists\n",
    "         '-i', split_audio,  # input\n",
    "         '-p', 'spleeter:2stems',  # convert to mono\n",
    "        '-d', '600',\n",
    "        '-o', 'Output'\n",
    "     ]\n",
    "    output = subprocess.call(extract_sound_cmd)\n",
    "    print('output: ', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5646.211\n"
     ]
    }
   ],
   "source": [
    "print(get_length('D:/Abhishek/Machine Learning Models/Subtitle-Sync/video/new/GardenofEvil.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video_file = 'D:/Abhishek/Machine Learning Models/Subtitle-Sync/github-repo/SubtitleSynchronizer/data/THENUN.mp4'\n",
    "split_video(input_video_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorFlowEnv",
   "language": "python",
   "name": "tensorflowenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
