{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this notebook builds a CNN model for audio classification which is using\n",
    "A. HDF5 file\n",
    "B. Custom generator to extract images from HDF5 file and feed into Neural Network\n",
    "C. Need TensorFlow 2.1.0\n",
    "D. It is based on transfer learnng (TL) which is using MobileNet CNN model\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_feature_generator(hdf5_path, bs, startIndex, endIndex, numClasses=2, mode=\"train\"):\n",
    "    dataset = h5py.File(hdf5_path, \"r\")\n",
    "    train_labels=np.array(dataset[\"train_labels\"])\n",
    "    i=startIndex\n",
    "    while True:\n",
    "        train_batch_imgs = []\n",
    "        labels = []\n",
    "        \n",
    "        while len(train_batch_imgs) < bs:\n",
    "            if endIndex < i:\n",
    "                break;\n",
    "            \n",
    "            img=(dataset['train_img'])[i]\n",
    "            img=img/255.\n",
    "            train_batch_imgs.append(img) \n",
    "            labels.append(train_labels[i])\n",
    "            \n",
    "            i = i+1\n",
    "\n",
    "        yield (np.array(train_batch_imgs), np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_path = 'Audio_Classification_Train_HDF5_0423_v1_.hdf5'\n",
    "\n",
    "dataset = h5py.File(hdf5_path, \"r\")\n",
    "train_labels=np.array(dataset[\"train_labels\"])\n",
    "train_labels = train_labels.reshape((len(train_labels),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=(dataset['train_img'])[0]\n",
    "img=img/255.\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGen = image_feature_generator(hdf5_path, 32,0, 10000, 2, mode=\"train\")\n",
    "valGen = image_feature_generator(hdf5_path, 32,10001, 11191, 2, mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(224 * 224 * 3,), activation=\"relu\"))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "opt = SGD(lr=1e-3, momentum=0.9, decay=1e-3 / 25)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "                    hub.KerasLayer(\n",
    "                        \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\",\n",
    "                        output_shape=[1280], trainable=False\n",
    "                    ),\n",
    "                    tf.keras.layers.Dropout(0.4),\n",
    "                    tf.keras.layers.Dense(2, activation='softmax')\n",
    "                    ])\n",
    "\n",
    "model.build([None, 224, 224, 3])\n",
    "model.summary()\n",
    "\n",
    "model.compile( optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = np.ceil(10000/32)\n",
    "val_steps_per_epoch = np.ceil(1191/32)\n",
    "\n",
    "hist = model.fit_generator( trainGen, epochs=10, verbose=1,\n",
    "                            steps_per_epoch=steps_per_epoch,\n",
    "                            validation_data=trainGen,\n",
    "                            validation_steps=val_steps_per_epoch\n",
    "                           ).history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorFlowEnv",
   "language": "python",
   "name": "tensorflowenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
