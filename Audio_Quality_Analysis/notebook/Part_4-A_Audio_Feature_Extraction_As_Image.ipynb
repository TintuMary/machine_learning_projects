{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook basically explains- \n",
    "A. How to extract the Audio features in form of audio MelSpectogram and save it in Image format.\n",
    "B. How to Iterate over Urban/Flicker/Spear audio dataset and convert them into MelSpectogram-Images\n",
    "C. How to mix Urban/Flicker audio dataset with noise signal and convert them into MelSpectogram-Images\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import librosa.display\n",
    "from pathlib import Path \n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_from_sound(signal,noise,SNR):\n",
    "    try:\n",
    "        RMS_s=math.sqrt(np.mean(signal**2))\n",
    "        #required RMS of noise\n",
    "        RMS_n=math.sqrt(RMS_s**2/(pow(10,SNR/20)))\n",
    "\n",
    "        #current RMS of noise\n",
    "        RMS_n_current=math.sqrt(np.mean(noise**2))\n",
    "        noise=noise*(RMS_n/RMS_n_current)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None\n",
    "    \n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is to convert single audio file into MelSpectogram image\n",
    "\n",
    "audio_file = '101415-3-0-2-gun-shot.wav'\n",
    "samples,sample_rate = librosa.load(audio_file, sr=22050, res_type='kaiser_fast')\n",
    "\n",
    "fig = plt.figure(figsize=[0.72,0.72])\n",
    "ax = fig.add_subplot(111)\n",
    "ax.axes.get_xaxis().set_visible(False)\n",
    "ax.axes.get_yaxis().set_visible(False)\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "filename  = audio_file.replace('.wav','.png')\n",
    "S = librosa.feature.melspectrogram(y=samples, sr=sample_rate)\n",
    "librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "plt.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is to convert Spear audio data into MelSpectogram images\n",
    "audio_parent_dir = Path('/SpEAR-speech-database-master/data')\n",
    "spectorgram_parent_dir = Path('/SpEAR-speech-database-master/spectorgram')\n",
    "\n",
    "sub_dirs= ['Lombard', 'Monaural', 'Noisy_Recordings', 'TIMIT']\n",
    "sub_dirs= ['confusion']\n",
    "file_ext = \"*.wav\"\n",
    "\n",
    "file_names = []\n",
    "for l, sub_dir in enumerate(sub_dirs):\n",
    "    print('Processing folder: ', sub_dir)\n",
    "    os.mkdir(spectorgram_parent_dir/sub_dir)\n",
    "    for fn in glob.glob(os.path.join(audio_parent_dir, sub_dir, file_ext)):\n",
    "        samples, sample_rate = librosa.load(fn)\n",
    "        fig = plt.figure(figsize=[0.72,0.72])\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        ax.set_frame_on(False)\n",
    "        filename  = spectorgram_parent_dir/sub_dir/Path(fn).name.replace('.wav','.png')\n",
    "        S = librosa.feature.melspectrogram(y=samples, sr=sample_rate)\n",
    "        librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "        plt.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "        plt.close('all')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is to convert Urban audio data into MelSpectogram images\n",
    "def create_urban_mel_spectrograms(fold):\n",
    "    spectrogram_path = Path('/spectrogram/noise/')  \n",
    "    audio_path = Path('/audio_data/noise/')  \n",
    "    print(f'Processing fold {fold}')\n",
    "    \n",
    "    files= list(Path(audio_path/f'{fold}').glob('*.wav'))\n",
    "    os.mkdir(spectrogram_path/fold)\n",
    "    for audio_file in files:\n",
    "        samples, sample_rate = librosa.load(audio_file)\n",
    "        fig = plt.figure(figsize=[0.72,0.72])\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        ax.set_frame_on(False)\n",
    "        filename  = spectrogram_path/fold/Path(audio_file).name.replace('.wav','.png')\n",
    "        S = librosa.feature.melspectrogram(y=samples, sr=sample_rate)\n",
    "        librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "        plt.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "        plt.close('all')\n",
    "        \n",
    "for i in range(1, 11):\n",
    "    create_urban_mel_spectrograms(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is to mix Urban audio data with nose and then convert into MelSpectogram images\n",
    "\n",
    "def create_urban_spectrograms_with_noise(fold, noisePath, noisetype):\n",
    "    spectrogram_path = Path('/spectrogram/noise/audio_mixed_noise/')  \n",
    "    audio_path = Path('/audio_data/good/')  \n",
    "    noise_file_path = '/audio_data/noise/only_noise/'\n",
    "    \n",
    "    crackle_noise_files = ['Crackle_02.wav', 'Crackling_Fireplace.wav', 'Tape_Noise_02.wav']\n",
    "    electric_noise_files= ['Air_FX_01.wav', 'electriccurrent.wav', 'EMOTOR.wav', 'ESPARK1.wav', 'fire.wav', 'Gate_Filtered_01(130BPM).wav', 'ha.wav', 'hi-tensionpower.wav', 'Juno_60_Raw_b.wav']\n",
    "    other_noise_files = ['Noise_09.wav', 'Noise_Hit_01.wav', 'Perc_Hit_06.wav']\n",
    "    white_pink_brown_noise_files = ['brown.wav', 'pink.wav', 'white.wav', 'noise.wav']\n",
    "    spear_noise_files= ['f16noiseR2_16.wav', 'factoryR1_16.wav', 'pinkR5_16.wav', 'volvoR1_16.wav']\n",
    "    all_noise_files = ['f16noiseR2_16.wav', 'factoryR1_16.wav', 'pinkR5_16.wav', 'brown.wav', 'pink.wav', 'white.wav', 'noise.wav', 'Noise_09.wav','Crackling_Fireplace.wav','Air_FX_01.wav', 'electriccurrent.wav', 'EMOTOR.wav', 'ESPARK1.wav', 'fire.wav', 'Gate_Filtered_01(130BPM).wav', 'hi-tensionpower.wav', 'Juno_60_Raw_b.wav']\n",
    "    \n",
    "    print(f'Processing fold {fold} and NoiseType {noisetype}')\n",
    "    \n",
    "    filenames = random.sample(os.listdir(Path(audio_path/f'{fold}')), 10)\n",
    "    for audio_file in filenames:\n",
    "        try:\n",
    "            \n",
    "            samples, sample_rate = librosa.load(Path(audio_path/f'{fold}'/audio_file))\n",
    "\n",
    "            if noisetype == 'crackle_noise_files':\n",
    "                noise_file= str(random.choice(crackle_noise_files))\n",
    "            elif noisetype == 'electric_noise_files':\n",
    "                noise_file= str(random.choice(electric_noise_files))\n",
    "            elif noisetype == 'other_noise_files':\n",
    "                noise_file= str(random.choice(other_noise_files))\n",
    "            elif noisetype == 'white_pink_brown_noise_files':\n",
    "                noise_file= str(random.choice(white_pink_brown_noise_files))\n",
    "            else:\n",
    "                noise_file= str(random.choice(all_noise_files))\n",
    "\n",
    "            noise_sample, sr1 = librosa.load(noise_file_path +str(noise_file), res_type='kaiser_fast')\n",
    "            if(len(noise_sample) > len(samples)):\n",
    "                  noise_sample=noise_sample[0:len(samples)]\n",
    "\n",
    "            if(len(noise_sample) < len(samples)):\n",
    "                samples=samples[0:len(noise_sample)]\n",
    "\n",
    "            mixed_noise_signal1 = get_noise_from_sound(samples,noise_sample,SNR=10)\n",
    "            mixed_noise_signal = samples + mixed_noise_signal1\n",
    "            \n",
    "            trim_signal = librosa.effects.trim(mixed_noise_signal)\n",
    "            total_duration = 4*sample_rate\n",
    "            split_signal = trim_signal[0] \n",
    "            if len(trim_signal[0]) > total_duration:\n",
    "                split_signal=trim_signal[0][0:total_duration]\n",
    "            \n",
    "            # For Generating wav file \n",
    "            fileName = Path(audio_file).name\n",
    "            librosa.output.write_wav(fileName, split_signal, sample_rate)\n",
    "            \n",
    "            \n",
    "            # for Generating Spectrogram for noise image\n",
    "            fig = plt.figure(figsize=[0.72,0.72])\n",
    "            ax = fig.add_subplot(111)\n",
    "            ax.axes.get_xaxis().set_visible(False)\n",
    "            ax.axes.get_yaxis().set_visible(False)\n",
    "            ax.set_frame_on(False)\n",
    "            filename  = spectrogram_path/Path(audio_file).name.replace('.wav','.png')\n",
    "            S = librosa.feature.melspectrogram(y=split_signal, sr=sample_rate)\n",
    "            librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "            plt.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "            plt.close('all')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Error encountered while parsing file: \", audio_file) \n",
    "\n",
    "create_urban_spectrograms_with_noise('flicker', 'Electric_noise', 'all_noise_files' )\n",
    "create_urban_spectrograms_with_noise('spear_good', 'other', 'all_noise_files' )\n",
    "create_urban_spectrograms_with_noise('urban', 'spear_noise', 'all_noise_files' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is to convert Flciker audio data into MelSpectogram images\n",
    "\n",
    "def create_flicker_spectrograms():\n",
    "    spectrogram_path = Path('/flickr_audio.tar/spectrogram/')  \n",
    "    audio_path = Path('/flickr_audio.tar/flickr_audio/wavs/')  \n",
    "    \n",
    "    for audio_file in list(Path(audio_path).glob('*.wav')):\n",
    "        samples, sample_rate = librosa.load(audio_file)\n",
    "        fig = plt.figure(figsize=[0.72,0.72])\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        ax.set_frame_on(False)\n",
    "        filename  = spectrogram_path/Path(audio_file).name.replace('.wav','.png')\n",
    "        S = librosa.feature.melspectrogram(y=samples, sr=sample_rate)\n",
    "        librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "        plt.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "        plt.close('all')\n",
    "        \n",
    "create_flicker_spectrograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4001\n"
     ]
    }
   ],
   "source": [
    "# This section is to mix Urban audio with noise data and convert them into MelSpectogram images\n",
    "\n",
    "def create_flciker_spectrograms_with_noise():\n",
    "    spectrogram_path = Path('D:/Abhishek/Machine Learning Models/Audio Data Analysis/flickr_audio.tar/spectrogram_noise/')  \n",
    "    audio_path = Path('D:/Abhishek/Machine Learning Models/Audio Data Analysis/flickr_audio.tar/flickr_audio/wavs/') \n",
    "    all_noise_files = ['f16noiseR2_16.wav', 'factoryR1_16.wav', 'pinkR5_16.wav', 'brown.wav', 'pink.wav', 'white.wav', 'noise.wav', 'Noise_09.wav','Crackling_Fireplace.wav','Air_FX_01.wav', 'electriccurrent.wav', 'EMOTOR.wav', 'ESPARK1.wav', 'fire.wav', 'Gate_Filtered_01(130BPM).wav', 'ha.wav', 'hi-tensionpower.wav', 'Juno_60_Raw_b.wav']\n",
    "    noise_file_path = 'D:/Abhishek/Machine Learning Models/Audio Data Analysis/Final_Audio_Signals/noise/'\n",
    "    \n",
    "    filenames = random.sample(os.listdir(Path(audio_path)), 4001)\n",
    "    print(len(filenames))\n",
    "    for audio_file in filenames:\n",
    "        try:\n",
    "            \n",
    "            samples, sample_rate = librosa.load(Path(audio_path/audio_file))\n",
    "\n",
    "            noise_file= str(random.choice(all_noise_files))\n",
    "            noise_sample, sr1 = librosa.load(noise_file_path +str(noise_file), res_type='kaiser_fast')\n",
    "            \n",
    "            if(len(noise_sample) > len(samples)):\n",
    "                  noise_sample=noise_sample[0:len(samples)]\n",
    "\n",
    "            if(len(noise_sample) < len(samples)):\n",
    "                samples=samples[0:len(noise_sample)]\n",
    "\n",
    "            mixed_noise_signal1 = get_noise_from_sound(samples,noise_sample,SNR=10)\n",
    "            mixed_noise_signal = samples + mixed_noise_signal1\n",
    "            \n",
    "            trim_signal = librosa.effects.trim(mixed_noise_signal)\n",
    "            total_duration = 4*sample_rate\n",
    "            split_signal = trim_signal[0] \n",
    "            if len(trim_signal[0]) > total_duration:\n",
    "                split_signal=trim_signal[0][0:total_duration]\n",
    "\n",
    "\n",
    "            fig = plt.figure(figsize=[0.72,0.72])\n",
    "            ax = fig.add_subplot(111)\n",
    "            ax.axes.get_xaxis().set_visible(False)\n",
    "            ax.axes.get_yaxis().set_visible(False)\n",
    "            ax.set_frame_on(False)\n",
    "            filename  = spectrogram_path/Path(audio_file).name.replace('.wav','.png')\n",
    "            S = librosa.feature.melspectrogram(y=split_signal, sr=sample_rate)\n",
    "            librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "            plt.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "            plt.close('all')\n",
    "        except Exception as e:\n",
    "              print(\"Error encountered while parsing file: \", audio_file) \n",
    "\n",
    "create_flciker_spectrograms_with_noise()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorFlowEnv",
   "language": "python",
   "name": "tensorflowenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
