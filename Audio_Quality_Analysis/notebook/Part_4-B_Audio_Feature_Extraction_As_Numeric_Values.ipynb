{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook basically explains- \n",
    "A. How to extract the Audio features in form of MFCC/Melc/ZCR values (from librosa library) and save it in either CSV file or Numpy Array format.\n",
    "B. How to Iterate over Urban audio dataset and convert them into MFCC values\n",
    "C. How to mix Urban audio dataset with noise signal and convert them into MFCC values\n",
    "D. How to use pyAudioAnalysis library to extract the audio feature values.\n",
    "\n",
    "Note: There are three different ways to get the MFCC values for given audio as mentioned into this notebook.\n",
    "a. MFCC base\n",
    "b. Scaled MFCC feature\n",
    "c. MFCC features with padding\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import librosa\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import math  \n",
    "import numpy as np\n",
    "from pyAudioAnalysis import audioBasicIO\n",
    "from pyAudioAnalysis import ShortTermFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract MFCC\n",
    "def extract_mfcc_features(audio, sample_rate):\n",
    "    try:\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None \n",
    "    return mfccsscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc_features_scaled(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None \n",
    "    return mfccsscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pad_len = 174\n",
    "def extract_mfcc_features_with_padding(audio, sample_rate):\n",
    "    try:\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \")\n",
    "        return None \n",
    "     \n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_white_noise(signal,SNR) :\n",
    "    #RMS value of signal\n",
    "    RMS_s=math.sqrt(np.mean(signal**2))\n",
    "    #RMS values of noise\n",
    "    RMS_n=math.sqrt(RMS_s**2/(pow(10,SNR/20)))\n",
    "    #Additive white gausian noise. Thereore mean=0\n",
    "    #Because sample length is large (typically > 40000)\n",
    "    #we can use the population formula for standard daviation.\n",
    "    #because mean=0 STD=RMS\n",
    "    STD_n=RMS_n\n",
    "    noise=np.random.normal(0, STD_n, signal.shape[0])\n",
    "    return noise\n",
    "\n",
    "def get_noise_from_sound(signal,noise,SNR):\n",
    "    try:\n",
    "        RMS_s=math.sqrt(np.mean(signal**2))\n",
    "        #required RMS of noise\n",
    "        RMS_n=math.sqrt(RMS_s**2/(pow(10,SNR/20)))\n",
    "\n",
    "        #current RMS of noise\n",
    "        RMS_n_current=math.sqrt(np.mean(noise**2))\n",
    "        noise=noise*(RMS_n/RMS_n_current)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \")\n",
    "        return None\n",
    "    \n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is to extract audio feature values using librosa lib for given single audio file\n",
    "features_df = pd.DataFrame()\n",
    "audio_file = '101415-3-0-2-gun-shot.wav'\n",
    "audio, sample_rate = librosa.load(audio_file, sr=22050, res_type='kaiser_fast')\n",
    "\n",
    "mfcc_df = pd.DataFrame([np.mean(librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40).T, axis=0)])\n",
    "mel_df = pd.DataFrame([np.mean(librosa.feature.melspectrogram(y=audio, sr=sample_rate).T, axis=0)])\n",
    "zcr = pd.DataFrame([np.mean(librosa.feature.zero_crossing_rate(y= audio))])\n",
    "\n",
    "wrkng_df1 = pd.concat([mfcc_transformed, mel_spect_transformed], axis=1)\n",
    "features_df = pd.concat([features_df, wrkng_df1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is to extract audio feature values using PyAudioAnalysis lib for given single audio file\n",
    "audio_file = '101415-3-0-2-gun-shot.wav'\n",
    "audio, sample_rate = librosa.load(audio_file, sr=22050, res_type='kaiser_fast')\n",
    "\n",
    "aud_feature, f_name = ShortTermFeatures.feature_extraction(audio, sample_rate, 0.050*sample_rate, 0.025*sample_rate)\n",
    "aud_feature_scaled = np.mean(aud_feature.T,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is to convert Urban audio data into mfcc values.\n",
    "parent_dir = '/UrbanSound8K.tar/UrbanSound8K/audio'\n",
    "sub_dirs= ['fold1', 'fold2', 'fold3', 'fold4', 'fold5', 'fold6', 'fold7', 'fold8', 'fold9', 'fold10']\n",
    "file_ext = \"*.wav\"\n",
    "\n",
    "features= []\n",
    "n = 0\n",
    "for l, sub_dir in enumerate(sub_dirs):\n",
    "    print('Processing folder: ', sub_dir)\n",
    "    for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "        n = n+1\n",
    "        if n%1000 == 0:\n",
    "            print('processing reocrd: ', n)\n",
    "        \n",
    "        signal,sr = librosa.load(fn)\n",
    "        mfcc = extract_mfcc_features(signal, sr)\n",
    "        class_label = \"original\"\n",
    "        features.append([mfcc, class_label])\n",
    "        \n",
    "        \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "#Save into CSV file\n",
    "featuresdf.to_csv (r'D:\\audio_dataframe.csv', index = False, header=True)\n",
    "\n",
    "#Save into Numpy array\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "np.save('result_np_array_Y1_SNR10' , y)\n",
    "np.save('result_np_array_X1_SNR10' , X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is to mix Urban audio data with noise signal and convert into mfcc values.\n",
    "\n",
    "hop_length = 512\n",
    "n_fft = 2048\n",
    "\n",
    "#image_parent_dir = 'D:/Abhishek/Machine Learning Models/Audio Data Analysis/UrbanSound8K.tar/UrbanSound8K/images/'\n",
    "parent_dir = 'D:/Abhishek/Machine Learning Models/Audio Data Analysis/UrbanSound8K.tar/UrbanSound8K/audio'\n",
    "sub_dirs= ['fold1', 'fold2', 'fold3', 'fold4', 'fold5', 'fold6', 'fold7', 'fold8', 'fold9', 'fold10']\n",
    "file_ext = \"*.wav\"\n",
    "\n",
    "noise_files = ['white_noise', 'Noise_09.wav', 'Noise_Hit_01.wav', 'Tape_Noise_02.wav', 'Perc_Hit_06.wav']\n",
    "\n",
    "noise_features= []\n",
    "n = 0\n",
    "\n",
    "for l, sub_dir in enumerate(sub_dirs):\n",
    "    print('Processing folder: ', sub_dir)\n",
    "    for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "        n = n+1\n",
    "            \n",
    "        if n%1000 == 0:\n",
    "            print('processing reocrd: ', n)\n",
    "        \n",
    "        signal,sr = librosa.load(fn, res_type='kaiser_fast')\n",
    "        \n",
    "        if mfcc is not None:\n",
    "            noise_file= str(random.choice(noise_files))\n",
    "        \n",
    "            if noise_file == 'white_noise':\n",
    "                noise=get_white_noise(signal,SNR=10)\n",
    "                signal_noise=signal+noise\n",
    "\n",
    "                mfcc = extract_features_with_padding(signal_noise, sr)\n",
    "                class_label = \"white_noise\"\n",
    "                noise_features.append([mfcc, class_label])\n",
    "            else:\n",
    "                noise_sample, sr1 = librosa.load(noise_file, sr=None)\n",
    "                \n",
    "                if(len(noise_sample) > len(signal)):\n",
    "                    noise_sample=noise_sample[0:len(signal)]\n",
    "\n",
    "                if(len(noise_sample) < len(signal)):\n",
    "                    signal=signal[0:len(noise_sample)]\n",
    "\n",
    "                noise3=get_noise_from_sound(signal,noise_sample,SNR=10)\n",
    "                \n",
    "                if noise3 is not None:\n",
    "                    signal_noise3=signal+noise3\n",
    "                    \n",
    "                    trim_signal = librosa.effects.trim(signal_noise3)\n",
    "                    total_duration = 4*sr\n",
    "                    split_signal = trim_signal[0] \n",
    "                    if len(trim_signal[0]) > total_duration:\n",
    "                        split_signal=trim_signal[0][0:total_duration]\n",
    "                    \n",
    "                    mfcc = extract_features_with_padding(split_signal, sr)\n",
    "                    if mfcc is not None:\n",
    "                        class_label = \"real_noise\"\n",
    "                        noise_features.append([mfcc, class_label])\n",
    "        \n",
    "\n",
    "noise_featuresdf = pd.DataFrame(noise_features, columns=['feature','class_label'])\n",
    "noise_featuresdf.to_csv (r'D:\\noise_audio_dataframe.csv', index = False, header=True)\n",
    "\n",
    "X = np.array(noise_featuresdf.feature.tolist())\n",
    "y = np.array(noise_featuresdf.class_label.tolist())\n",
    "\n",
    "np.save('noise_result_np_array_Y1_SNR10' , y)\n",
    "np.save('noise_result_np_array_X1_SNR10' , X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames= [featuresdf, noise_featuresdf]\n",
    "result = pd.concat(frames)\n",
    "result = shuffle(result)\n",
    "result.to_csv (r'D:\\final_audio_dataframe.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load numpy array \n",
    "result_y_numpy_data = np.load('result_np_array_Y.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  8732  files\n"
     ]
    }
   ],
   "source": [
    "# This section is to iterate over Urban MetaData CSV file and convert corresponding audio data into mfcc values.\n",
    "\n",
    "fulldatasetpath = '/UrbanSound8K.tar/UrbanSound8K/audio/'\n",
    "\n",
    "metadata = pd.read_csv(fulldatasetpath + '../metadata/UrbanSound8K.csv')\n",
    "\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "for index, row in metadata.iterrows():\n",
    "    \n",
    "    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    \n",
    "    class_label = row[\"class\"]\n",
    "    data = extract_features_scaled(file_name)\n",
    "    \n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), ' files')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorFlowEnv",
   "language": "python",
   "name": "tensorflowenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
