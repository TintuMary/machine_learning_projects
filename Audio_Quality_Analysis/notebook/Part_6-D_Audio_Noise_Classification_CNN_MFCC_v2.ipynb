{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Part_6-D_Audio_Noise_Classification_CNN_MFCC_v2.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMLHj7B/7R9AdX60l0GM7FP"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"PJ2pqgHZwhNd","colab_type":"code","colab":{}},"source":["'''\n","This Notebook provides implementation how to build Neural network based model for Audio Classification. \n","\n","A. download urban, flicker dataset and iterate over it to get the MFCC values \n","B. Mix urban/flicker audio with noise and get MFCC values\n","C. Use these generated MFCC values for model building\n"," \n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FvffP8PkMuwE","colab_type":"code","colab":{}},"source":["import urllib.request\n","urllib.request.urlretrieve (\"https://zenodo.org/record/1203745/files/UrbanSound8K.tar.gz\",\"a.tar.gz\")\n","import tarfile\n","tar = tarfile.open(\"a.tar.gz\")\n","tar.extractall()\n","tar.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-GhbAY-uzwmH","colab_type":"code","colab":{}},"source":["!wget https://os.unil.cloud.switch.ch/fma/fma_small.zip\n","!unzip fma_small.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pv1Agfo17lku","colab_type":"code","colab":{}},"source":["!wget https://groups.csail.mit.edu/sls/downloads/flickraudio/downloads/flickr_audio.tar.gz\n","!gunzip -d flickr_audio.tar.gz\n","!tar -xvf flickr_audio.tar"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GO-OEP5VXvhM","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import math\n","\n","from tqdm import tqdm\n","from librosa import display\n","import librosa\n","import sklearn.metrics as metrics\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from keras.utils import to_categorical\n","import sklearn.metrics as metrics\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G3ikw01fX88y","colab_type":"code","colab":{}},"source":["def extract_mfcc_scaled_features(file_name):\n","   \n","    try:\n","        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n","        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n","        mfccsscaled = np.mean(mfccs.T,axis=0)\n","        \n","    except Exception as e:\n","        print(\"Error encountered while parsing file: \", file)\n","        return None \n","     \n","    return mfccsscaled"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OPRRl6vQn8NN","colab_type":"code","colab":{}},"source":["max_pad_len = 174\n","\n","def extract_features_with_padding(file_name):\n","   \n","    try:\n","        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n","        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n","        pad_width = max_pad_len - mfccs.shape[1]\n","        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n","        \n","    except Exception as e:\n","        print(\"Error encountered while parsing file: \", file_name)\n","        return None \n","     \n","    return mfccs\n","\n","def extract_mfcc_features_with_padding(audio, sample_rate):\n","    try:\n","        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n","        pad_width = max_pad_len - mfccs.shape[1]\n","        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n","        \n","    except Exception as e:\n","        print(\"Error encountered while parsing file: \")\n","        return None \n","     \n","    return mfccs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hjtiDBTvsFb0","colab_type":"code","colab":{}},"source":["#given a signal, noise (audio) and desired SNR, this gives the noise (scaled version of noise input) that gives the desired SNR\n","\n","def get_noise_from_sound(signal,noise,SNR):\n","    RMS_s=np.sqrt(np.mean(signal**2))\n","    #required RMS of noise\n","    RMS_n=np.sqrt(RMS_s**2/(pow(10,SNR/20)))\n","    #current RMS of noise\n","    RMS_n_current=np.sqrt(np.mean(noise**2))\n","\n","    noise=noise*(RMS_n/RMS_n_current)\n","    return noise"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M0ozyOmyhSzS","colab_type":"code","outputId":"07139c69-a9e1-4323-c110-19180d869cd2","executionInfo":{"status":"ok","timestamp":1587227771904,"user_tz":300,"elapsed":540,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CihGWRBdKA6i","colab_type":"code","colab":{}},"source":["#extarct samples of original flickr audio\n","import random\n","flicker_features= []\n","urban_features=[]\n","music_features=[]\n","original_audio = pd.DataFrame()\n","crackle_noise_files = ['Crackle_02.wav', 'Crackling_Fireplace.wav', 'Tape_Noise_02.wav']\n","electric_noise_files= ['Air_FX_01.wav', 'electriccurrent.wav', 'EMOTOR.wav', 'ESPARK1.wav', 'fire.wav', 'Gate_Filtered_01(130BPM).wav', 'ha.wav', 'hi-tensionpower.wav', 'Juno_60_Raw_b.wav']\n","other_noise_files = ['Noise_09.wav', 'Noise_Hit_01.wav', 'Perc_Hit_06.wav']\n","white_pink_brown_noise_files = ['brown.wav', 'pink.wav', 'white.wav', 'noise.wav']\n","spear_noise_files = ['f16noiseR2_16.wav', 'factoryR1_16.wav', 'pinkR5_16.wav', 'volvoR1_16.wav']\n","\n","Files=os.listdir('/content/flickr_audio/wavs')\n","n=0\n","for file in Files:\n","  n = n +1\n","  if n%1000 ==0:\n","    print('processed records', n) \n","  \n","  if n> 3000:\n","    break;\n","  \n","  signal, sample_rate = librosa.load('/content/flickr_audio/wavs/'+ str(file), res_type='kaiser_fast') \n","  \n","  noise_file= str(random.choice(spear_noise_files))\n","  noise_sample, sr1 = librosa.load('/content/Spear_Noise/'+str(noise_file), res_type='kaiser_fast')\n","  \n","  if(len(noise_sample) > len(signal)):\n","      noise_sample=noise_sample[0:len(signal)]\n","\n","  if(len(noise_sample) < len(signal)):\n","      signal=signal[0:len(noise_sample)]\n","\n","  mixed_noise_signal = get_noise_from_sound(signal,noise_sample,SNR=10)\n","\n","  trim_signal = librosa.effects.trim(mixed_noise_signal)\n","  total_duration = 4*sample_rate\n","  split_signal = trim_signal[0] \n","  if len(trim_signal[0]) > total_duration:\n","    split_signal=trim_signal[0][0:total_duration]\n","\n","  aud_feature = extract_mfcc_features_with_padding(split_signal, sample_rate)\n","  if aud_feature is not None:\n","    class_label = \"spear_noise\"\n","    flicker_features.append([aud_feature, class_label])\n","\n","print('Processing done for Flicker Sound with', len(flicker_features))\n","\n","inner_n=0\n","outer_n=0\n","\n","folders=os.listdir('/content/UrbanSound8K/audio')\n","for folder in folders:\n","  if outer_n > 3000:\n","    break;\n","  if outer_n%1000 ==0:\n","    print('processed records', outer_n)\n","  if folder != '.DS_Store' :\n","    files = os.listdir('/content/UrbanSound8K/audio/'+ str(folder))\n","    inner_n = 0\n","    for file in files:\n","      if file != '.DS_Store':\n","        inner_n = inner_n +1\n","        outer_n = outer_n+1\n","        if inner_n > 350:\n","          break;\n","        try:\n","          signal, sample_rate = librosa.load('/content/UrbanSound8K/audio/'+ str(folder)+'/'+str(file) , res_type='kaiser_fast') \n","\n","          noise_file= str(random.choice(spear_noise_files))\n","          noise_sample, sr1 = librosa.load('/content/Spear_Noise/'+str(noise_file), res_type='kaiser_fast')\n","\n","          if(len(noise_sample) > len(signal)):\n","              noise_sample=noise_sample[0:len(signal)]\n","\n","          if(len(noise_sample) < len(signal)):\n","              signal=signal[0:len(noise_sample)]\n","\n","          mixed_noise_signal = get_noise_from_sound(signal,noise_sample,SNR=10)\n","\n","          trim_signal = librosa.effects.trim(mixed_noise_signal)\n","          total_duration = 4*sample_rate\n","          split_signal = trim_signal[0] \n","          if len(trim_signal[0]) > total_duration:\n","            split_signal=trim_signal[0][0:total_duration]\n","\n","          aud_feature = extract_mfcc_features_with_padding(split_signal, sample_rate)\n","          if aud_feature is not None:\n","            class_label = \"spear_noise\"\n","            urban_features.append([aud_feature, class_label])\n","        except Exception as e:\n","          print(\"Error encountered while parsing file: \", file)\n","\n","print('Processing done for Urban Sound with ', len(urban_features))\n","\n","\n","inner_n=0\n","outer_n=0\n","\n","folders=os.listdir('/content/fma_small')\n","for folder in folders:\n","  if outer_n > 3000:\n","    break;\n","  if outer_n%1000 ==0:\n","    print('processed records', outer_n)\n","  if folder != '.DS_Store' and folder != 'README.txt' and folder != 'checksums' :\n","    files = os.listdir('/content/fma_small/'+ str(folder))\n","    inner_n = 0\n","\n","    for file in files:\n","      if file != '.DS_Store' and file != 'README.txt' and file != 'checksums':\n","        inner_n = inner_n +1\n","        outer_n = outer_n+1\n","        if inner_n > 100:\n","          break;\n","        try:\n","          signal, sample_rate = librosa.load('/content/fma_small/'+ str(folder)+'/'+str(file) , res_type='kaiser_fast') \n","\n","          noise_file= str(random.choice(spear_noise_files))\n","          print(outer_n , ' : InnerN-> ', inner_n, ' : Folder-> ', folder, ' : File:', file)\n","          noise_sample, sr1 = librosa.load('/content/Spear_Noise/'+str(noise_file), res_type='kaiser_fast')\n","\n","          if(len(noise_sample) > len(signal)):\n","              noise_sample=noise_sample[0:len(signal)]\n","\n","          if(len(noise_sample) < len(signal)):\n","              signal=signal[0:len(noise_sample)]\n","\n","          mixed_noise_signal = get_noise_from_sound(signal,noise_sample,SNR=10)\n","\n","          trim_signal = librosa.effects.trim(mixed_noise_signal)\n","          total_duration = 4*sample_rate\n","          split_signal = trim_signal[0] \n","          if len(trim_signal[0]) > total_duration:\n","            split_signal=trim_signal[0][0:total_duration]\n","\n","          aud_feature = extract_mfcc_features_with_padding(split_signal, sample_rate)\n","          if aud_feature is not None:\n","            class_label = \"spear_noise\"\n","            music_features.append([aud_feature, class_label])\n","        except Exception as e:\n","          print(\"Error encountered while parsing file: \", file)\n","\n","print(len(flicker_features))\n","print(len(urban_features))\n","print(len(music_features))\n","\n","temp = np.concatenate((flicker_features, urban_features), axis=0)\n","final_noise_feature = np.concatenate((temp, music_features), axis=0)\n","\n","print(len(final_noise_feature))\n","\n","featuresdf = pd.DataFrame(final_noise_feature, columns=['feature','class_label'])\n","spear_noise_X = np.array(featuresdf.feature.tolist())\n","spear_noise_y = np.array(featuresdf.class_label.tolist())\n","\n","np.save('/content/drive/My Drive/Audio_Quality_Analysis/data/spear_noise_6K_np_array_Y' , spear_noise_y)\n","np.save('/content/drive/My Drive/Audio_Quality_Analysis/data/spear_noise_6K_np_array_X' , spear_noise_X)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4p3oPzSVg3_2","colab_type":"code","outputId":"acdac9f7-04da-4e42-ccab-9d091bde2397","executionInfo":{"status":"ok","timestamp":1587235077108,"user_tz":300,"elapsed":61820,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["creckling_noise_X = np.load('/content/drive/My Drive/Audio_Quality_Analysis/data/creckling_noise_9K_np_array_X.npy', allow_pickle=True)\n","creckling_noise_X = creckling_noise_X[:4000]\n","creckling_noise_y = np.full((len(creckling_noise_X)), 'noise')\n","print('creckling_noise len: ', len(creckling_noise_X))\n","\n","electric_noise_X = np.load('/content/drive/My Drive/Audio_Quality_Analysis/data/electric_noise_9K_np_array_X.npy', allow_pickle=True)\n","electric_noise_X = electric_noise_X[:4000]\n","electric_noise_y = np.full((len(electric_noise_X)), 'noise')\n","print('electric_noise_ len: ', len(electric_noise_X))\n","\n","other_noise_X = np.load('/content/drive/My Drive/Audio_Quality_Analysis/data/other_noise_9K_np_array_X.npy', allow_pickle=True)\n","other_noise_X = other_noise_X[:4000]\n","other_noise_y = np.full((len(other_noise_X)), 'noise')\n","print('other_noise_ len: ', len(other_noise_X))\n","\n","real_noise_X = np.load('/content/drive/My Drive/Audio_Quality_Analysis/data/real_noise_9K_np_array_X.npy', allow_pickle=True)\n","real_noise_X = real_noise_X[:4000]\n","real_noise_y = np.full((len(real_noise_X)), 'noise')\n","print('real_noise_ len: ', len(real_noise_X))\n","\n","flicker_sound_X = np.load('/content/drive/My Drive/Audio_Quality_Analysis/data/flicker_sound_15K_np_array_X.npy', allow_pickle=True)\n","flicker_sound_X = flicker_sound_X[:9000]\n","flicker_sound_y = np.full((len(flicker_sound_X)), 'good')\n","print('flicker_sound_ len: ', len(flicker_sound_X))\n","\n","music_sound_X = np.load('/content/drive/My Drive/Audio_Quality_Analysis/data/music_sound_8K_np_array_X.npy', allow_pickle=True)\n","music_sound_y = np.full((len(music_sound_X)), 'good')\n","print('music_sound_ len: ', len(music_sound_X))\n","\n","spear_noise_X = np.array(featuresdf.feature.tolist())\n","spear_noise_y = np.full((len(spear_noise_X)), 'noise') \n","print('spear_noise_ len: ', len(spear_noise_X))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["creckling_noise len:  4000\n","electric_noise_ len:  4000\n","other_noise_ len:  4000\n","real_noise_ len:  4000\n","flicker_sound_ len:  9000\n","music_sound_ len:  7997\n","spear_noise_ len:  6023\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["\"\\nurban_sound_X = np.load('/content/drive/My Drive/Audio_Quality_Analysis/data/result_np_array_X_padding_0410.npy', allow_pickle=True)\\nurban_sound_y = np.full((len(urban_sound_X)), 'urban_sound')\\nprint('urban_sound_ len: ', len(urban_sound_X))\\n\""]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"spZhAHgjoUP1","colab_type":"code","outputId":"e4492f27-d362-40a8-c7fd-6060022099b9","executionInfo":{"status":"ok","timestamp":1587235123977,"user_tz":300,"elapsed":3929,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["final_X = np.concatenate((creckling_noise_X, electric_noise_X, other_noise_X, real_noise_X, flicker_sound_X, music_sound_X, spear_noise_X ), axis=0)\n","final_y = np.concatenate((creckling_noise_y, electric_noise_y, other_noise_y, real_noise_y, flicker_sound_y, music_sound_y, spear_noise_y ), axis=0)\n","\n","print(len(final_X))\n","print(len(final_y))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["39020\n","39020\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PXGFaj-Rc-KM","colab_type":"code","colab":{}},"source":["# Encode the classification labels\n","from sklearn.preprocessing import LabelEncoder\n","import pickle\n","from keras.utils import to_categorical\n","le = LabelEncoder()\n","yy = to_categorical(le.fit_transform(final_y))\n","\n","with open('/content/drive/My Drive/Audio_Quality_Analysis/model/labelEncoderFile_With_good_noise_LE_04182020_v1.pkl', 'wb') as fid:\n","    pickle.dump(le, fid)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tg05aecUpxb3","colab_type":"code","outputId":"27c60c03-3177-4bb1-c786-145bfff16ae8","executionInfo":{"status":"ok","timestamp":1587235155311,"user_tz":300,"elapsed":690,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(final_X.shape)\n","print(yy.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(39020, 40, 174)\n","(39020, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RDCpsOWDdBSh","colab_type":"code","outputId":"5b1ce5af-dc63-416a-9902-ca02411bc675","executionInfo":{"status":"ok","timestamp":1587235179029,"user_tz":300,"elapsed":2864,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# split the dataset \n","from sklearn.model_selection import train_test_split \n","\n","x_train, x_test, y_train, y_test = train_test_split(final_X, yy, test_size=0.2, random_state = 42)\n","print(x_train.shape)\n","print(x_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(31216, 40, 174)\n","(7804, 40, 174)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eQc3nMujdFXE","colab_type":"code","outputId":"1a2c0037-6c97-46b7-c8dc-80d92fcbd289","executionInfo":{"status":"ok","timestamp":1587235198558,"user_tz":300,"elapsed":7260,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":646}},"source":["import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n","from keras.optimizers import Adam\n","from keras.utils import np_utils\n","from sklearn import metrics \n","\n","num_rows = 40\n","num_columns = 174\n","num_channels = 1\n","\n","x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n","x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n","\n","num_labels = yy.shape[1]\n","filter_size = 2\n","\n","# Construct model \n","model = Sequential()\n","model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n","model.add(MaxPooling2D(pool_size=2))\n","model.add(Dropout(0.2))\n","\n","model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n","model.add(MaxPooling2D(pool_size=2))\n","model.add(Dropout(0.2))\n","\n","model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n","model.add(MaxPooling2D(pool_size=2))\n","model.add(Dropout(0.2))\n","\n","model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n","model.add(MaxPooling2D(pool_size=2))\n","model.add(Dropout(0.2))\n","model.add(GlobalAveragePooling2D())\n","\n","model.add(Dense(num_labels, activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n","model.summary()\n","\n","# Calculate pre-training accuracy \n","score = model.evaluate(x_test, y_test, verbose=0)\n","accuracy = 100*score[1]\n","\n","print(\"Pre-training accuracy: %.4f%%\" % accuracy)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_9 (Conv2D)            (None, 39, 173, 16)       80        \n","_________________________________________________________________\n","max_pooling2d_9 (MaxPooling2 (None, 19, 86, 16)        0         \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 19, 86, 16)        0         \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 18, 85, 32)        2080      \n","_________________________________________________________________\n","max_pooling2d_10 (MaxPooling (None, 9, 42, 32)         0         \n","_________________________________________________________________\n","dropout_10 (Dropout)         (None, 9, 42, 32)         0         \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 8, 41, 64)         8256      \n","_________________________________________________________________\n","max_pooling2d_11 (MaxPooling (None, 4, 20, 64)         0         \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 4, 20, 64)         0         \n","_________________________________________________________________\n","conv2d_12 (Conv2D)           (None, 3, 19, 128)        32896     \n","_________________________________________________________________\n","max_pooling2d_12 (MaxPooling (None, 1, 9, 128)         0         \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 1, 9, 128)         0         \n","_________________________________________________________________\n","global_average_pooling2d_3 ( (None, 128)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 2)                 258       \n","=================================================================\n","Total params: 43,570\n","Trainable params: 43,570\n","Non-trainable params: 0\n","_________________________________________________________________\n","Pre-training accuracy: 55.6253%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lhAdjBrFdS9q","colab_type":"code","outputId":"be3e9eb1-3c3a-459f-a038-8f27f273bcb0","executionInfo":{"status":"ok","timestamp":1587239708745,"user_tz":300,"elapsed":4467030,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from keras.callbacks import ModelCheckpoint \n","from datetime import datetime \n","\n","num_epochs = 50\n","num_batch_size = 32\n","\n","# checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5', verbose=1, save_best_only=True)\n","start = datetime.now()\n","\n","# model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n","model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), verbose=1)\n","\n","duration = datetime.now() - start\n","print(\"Training completed in time: \", duration)\n","\n","model.save(\"/content/drive/My Drive/Audio_Quality_Analysis/model/SoundClassification_model_With_good_noise_V1_04182020_v1.h5\")\n","model.save_weights(\"/content/drive/My Drive/Audio_Quality_Analysis/model/SoundClassification_Weight_With_good_noise_V1_04182020_v1.h5\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 31216 samples, validate on 7804 samples\n","Epoch 1/50\n","31216/31216 [==============================] - 91s 3ms/step - loss: 0.1059 - accuracy: 0.9675 - val_loss: 0.0273 - val_accuracy: 0.9932\n","Epoch 2/50\n","31216/31216 [==============================] - 91s 3ms/step - loss: 0.0218 - accuracy: 0.9949 - val_loss: 0.0242 - val_accuracy: 0.9935\n","Epoch 3/50\n","31216/31216 [==============================] - 91s 3ms/step - loss: 0.0137 - accuracy: 0.9968 - val_loss: 0.0098 - val_accuracy: 0.9971\n","Epoch 4/50\n","31216/31216 [==============================] - 94s 3ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.0085 - val_accuracy: 0.9979\n","Epoch 5/50\n","31216/31216 [==============================] - 90s 3ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.0170 - val_accuracy: 0.9954\n","Epoch 6/50\n","31216/31216 [==============================] - 90s 3ms/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 0.0085 - val_accuracy: 0.9973\n","Epoch 7/50\n","31216/31216 [==============================] - 89s 3ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.0077 - val_accuracy: 0.9981\n","Epoch 8/50\n","31216/31216 [==============================] - 89s 3ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0092 - val_accuracy: 0.9976\n","Epoch 9/50\n","31216/31216 [==============================] - 89s 3ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.0088 - val_accuracy: 0.9968\n","Epoch 10/50\n","31216/31216 [==============================] - 89s 3ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0035 - val_accuracy: 0.9991\n","Epoch 11/50\n","31216/31216 [==============================] - 89s 3ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.0041 - val_accuracy: 0.9982\n","Epoch 12/50\n","31216/31216 [==============================] - 88s 3ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0025 - val_accuracy: 0.9994\n","Epoch 13/50\n","31216/31216 [==============================] - 89s 3ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0100 - val_accuracy: 0.9978\n","Epoch 14/50\n","31216/31216 [==============================] - 88s 3ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0062 - val_accuracy: 0.9983\n","Epoch 15/50\n","31216/31216 [==============================] - 88s 3ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0040 - val_accuracy: 0.9987\n","Epoch 16/50\n","31216/31216 [==============================] - 89s 3ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.0037 - val_accuracy: 0.9986\n","Epoch 17/50\n","31216/31216 [==============================] - 91s 3ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0080 - val_accuracy: 0.9983\n","Epoch 18/50\n","31216/31216 [==============================] - 90s 3ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0034 - val_accuracy: 0.9991\n","Epoch 19/50\n","31216/31216 [==============================] - 89s 3ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0053 - val_accuracy: 0.9986\n","Epoch 20/50\n","31216/31216 [==============================] - 92s 3ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0037 - val_accuracy: 0.9992\n","Epoch 21/50\n","31216/31216 [==============================] - 91s 3ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0125 - val_accuracy: 0.9973\n","Epoch 22/50\n","31216/31216 [==============================] - 90s 3ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0049 - val_accuracy: 0.9988\n","Epoch 23/50\n","31216/31216 [==============================] - 90s 3ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.0038 - val_accuracy: 0.9990\n","Epoch 24/50\n","31216/31216 [==============================] - 90s 3ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0036 - val_accuracy: 0.9991\n","Epoch 25/50\n","31216/31216 [==============================] - 92s 3ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0055 - val_accuracy: 0.9987\n","Epoch 26/50\n","31216/31216 [==============================] - 91s 3ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0057 - val_accuracy: 0.9988\n","Epoch 27/50\n","31216/31216 [==============================] - 91s 3ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0040 - val_accuracy: 0.9991\n","Epoch 28/50\n","31216/31216 [==============================] - 89s 3ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0036 - val_accuracy: 0.9990\n","Epoch 29/50\n","31216/31216 [==============================] - 88s 3ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0021 - val_accuracy: 0.9994\n","Epoch 30/50\n","31216/31216 [==============================] - 88s 3ms/step - loss: 0.0060 - accuracy: 0.9992 - val_loss: 0.0066 - val_accuracy: 0.9990\n","Epoch 31/50\n","31216/31216 [==============================] - 88s 3ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.0051 - val_accuracy: 0.9988\n","Epoch 32/50\n","31216/31216 [==============================] - 89s 3ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.0051 - val_accuracy: 0.9991\n","Epoch 33/50\n","31216/31216 [==============================] - 90s 3ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 8.5251e-04 - val_accuracy: 0.9999\n","Epoch 34/50\n","31216/31216 [==============================] - 89s 3ms/step - loss: 5.6351e-04 - accuracy: 0.9999 - val_loss: 0.0076 - val_accuracy: 0.9985\n","Epoch 35/50\n","31216/31216 [==============================] - 89s 3ms/step - loss: 0.0054 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9990\n","Epoch 36/50\n","31216/31216 [==============================] - 88s 3ms/step - loss: 6.4781e-04 - accuracy: 0.9999 - val_loss: 0.0032 - val_accuracy: 0.9994\n","Epoch 37/50\n","31216/31216 [==============================] - 88s 3ms/step - loss: 8.7223e-04 - accuracy: 0.9998 - val_loss: 0.0020 - val_accuracy: 0.9994\n","Epoch 38/50\n","31216/31216 [==============================] - 88s 3ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.0034 - val_accuracy: 0.9992\n","Epoch 39/50\n","31216/31216 [==============================] - 88s 3ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0292 - val_accuracy: 0.9949\n","Epoch 40/50\n","31216/31216 [==============================] - 88s 3ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0032 - val_accuracy: 0.9992\n","Epoch 41/50\n","31216/31216 [==============================] - 88s 3ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.0043 - val_accuracy: 0.9990\n","Epoch 42/50\n","31216/31216 [==============================] - 88s 3ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0048 - val_accuracy: 0.9988\n","Epoch 43/50\n","31216/31216 [==============================] - 87s 3ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.0028 - val_accuracy: 0.9992\n","Epoch 44/50\n","31216/31216 [==============================] - 88s 3ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0030 - val_accuracy: 0.9991\n","Epoch 45/50\n","31216/31216 [==============================] - 89s 3ms/step - loss: 7.7218e-04 - accuracy: 0.9999 - val_loss: 0.0036 - val_accuracy: 0.9995\n","Epoch 46/50\n","31216/31216 [==============================] - 88s 3ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0141 - val_accuracy: 0.9983\n","Epoch 47/50\n","31216/31216 [==============================] - 90s 3ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0030 - val_accuracy: 0.9994\n","Epoch 48/50\n","31216/31216 [==============================] - 88s 3ms/step - loss: 0.0061 - accuracy: 0.9992 - val_loss: 0.0037 - val_accuracy: 0.9991\n","Epoch 49/50\n","31216/31216 [==============================] - 89s 3ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0020 - val_accuracy: 0.9992\n","Epoch 50/50\n","31216/31216 [==============================] - 89s 3ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0043 - val_accuracy: 0.9991\n","Training completed in time:  1:14:26.269676\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XOwRVFzkdNma","colab_type":"code","outputId":"6abb21a0-6032-49c6-b7e1-2cf958fc75b8","executionInfo":{"status":"ok","timestamp":1587092773512,"user_tz":300,"elapsed":80676,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Evaluating the model on the training and testing set\n","score = model.evaluate(x_train, y_train, verbose=0)\n","print(\"Training Accuracy: \", score[1])\n","\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print(\"Testing Accuracy: \", score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training Accuracy:  0.9941068887710571\n","Testing Accuracy:  0.985007643699646\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0cCrCFjrqS0P","colab_type":"code","outputId":"97f5a9de-2878-4931-ade1-e460443f533c","executionInfo":{"status":"ok","timestamp":1587138133968,"user_tz":300,"elapsed":3913,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":629}},"source":["from keras import models\n","model = models.load_model('/content/drive/My Drive/Audio_Quality_Analysis/model/SoundClassification_model_With_all_sound_V1_04162020.h5')\n","#model = tf.keras.models.load_model('/content/drive/My Drive/Image_Quality_Analysis/model/ImageQuality_TL_GD_V1_0408.h5',custom_objects={'KerasLayer':hub.KerasLayer})\n","model.load_weights('/content/drive/My Drive/Audio_Quality_Analysis/model/SoundClassification_Weight_With_all_sound_V1_04162020.h5')\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 39, 173, 16)       80        \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 19, 86, 16)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 19, 86, 16)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 18, 85, 32)        2080      \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 9, 42, 32)         0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 9, 42, 32)         0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 8, 41, 64)         8256      \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 4, 20, 64)         0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 4, 20, 64)         0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 3, 19, 128)        32896     \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 1, 9, 128)         0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 1, 9, 128)         0         \n","_________________________________________________________________\n","global_average_pooling2d_1 ( (None, 128)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 7)                 903       \n","=================================================================\n","Total params: 44,215\n","Trainable params: 44,215\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FOlzI0Ywf-GP","colab_type":"code","outputId":"f8b0533d-e5f4-483c-ddcb-d4b4e06d4fbf","executionInfo":{"status":"ok","timestamp":1587093525696,"user_tz":300,"elapsed":16656,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":510}},"source":["predict = model1.predict(x_test)\n","predict=np.round(predict,decimals=5)\n","result = map(lambda v : np.argmax(v), predict)\n","prediction_result = np.array(list(result))\n","print(prediction_result)\n","\n","actual=np.round(y_test,decimals=5)\n","actualresult = map(lambda v : np.argmax(v), actual)\n","actualresult_result = np.array(list(actualresult))\n","print(actualresult_result)\n","\n","classification_report = metrics.classification_report(actualresult_result, prediction_result)\n","print(\"Classification report: \\n\", classification_report)\n","confusion_matrix = metrics.confusion_matrix(actualresult_result, prediction_result)\n","print(\"Confusion matrix: \\n\",confusion_matrix)\n","\n","print(\"Accuracy Score: \", accuracy_score(actualresult_result, prediction_result))\n","print(\"F1 Score: \", f1_score(actualresult_result, prediction_result, average='weighted'))\n","print(\"Precision Score: \", precision_score(actualresult_result, prediction_result, average='weighted'))\n","print(\"Recall Score: \", recall_score(actualresult_result, prediction_result, average='weighted'))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[6 4 1 ... 1 6 5]\n","[6 4 1 ... 1 6 5]\n","Classification report: \n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      1789\n","           1       1.00      1.00      1.00      1839\n","           2       1.00      1.00      1.00      1821\n","           3       0.98      0.90      0.94      1557\n","           4       1.00      1.00      1.00      1792\n","           5       1.00      1.00      1.00      1905\n","           6       0.92      0.98      0.95      1770\n","\n","    accuracy                           0.99     12473\n","   macro avg       0.99      0.98      0.98     12473\n","weighted avg       0.99      0.99      0.98     12473\n","\n","Confusion matrix: \n"," [[1789    0    0    0    0    0    0]\n"," [   0 1839    0    0    0    0    0]\n"," [   0    0 1818    0    0    0    3]\n"," [   1    0    2 1406    0    1  147]\n"," [   0    0    0    0 1791    0    1]\n"," [   0    0    0    0    0 1905    0]\n"," [   0    8    0   22    0    2 1738]]\n","Accuracy Score:  0.9850076164515353\n","F1 Score:  0.9849472298012477\n","Precision Score:  0.9856140361589837\n","Recall Score:  0.9850076164515353\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"itINxqGQ8_u2","colab_type":"code","outputId":"45ba0bd7-5475-4fc4-bf0d-5fc1bf0e3bbd","executionInfo":{"status":"ok","timestamp":1587144675410,"user_tz":300,"elapsed":10397,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":530}},"source":["# With only good sound\n","X = np.load('/content/drive/My Drive/Audio_Quality_Analysis/data/result_np_array_X_padding_0410.npy', allow_pickle=True)\n","y = np.full((len(X)), 'urban_sound')\n","\n","with open('/content/drive/My Drive/Audio_Quality_Analysis/model/labelEncoderFile_With_all_sound_LE_04162020.pkl', 'rb') as fid:\n","    le_loaded = pickle.load(fid)\n","yy1 = to_categorical(le_loaded.transform(y))\n","\n","X = np.expand_dims(X, axis=3)\n","x_train1, x_test1, y_train1, y_test1 = train_test_split(X, yy1, test_size=0.9, random_state = 42)\n","\n","predict = model.predict(x_test1)\n","predict=np.round(predict,decimals=5)\n","result = map(lambda v : np.argmax(v), predict)\n","prediction_result = np.array(list(result))\n","print(prediction_result)\n","\n","actual=np.round(y_test1,decimals=5)\n","actualresult = map(lambda v : np.argmax(v), actual)\n","actualresult_result = np.array(list(actualresult))\n","print(actualresult_result)\n","#actualresult_result = np.full((len(y_test1)), 0)\n","\n","classification_report = metrics.classification_report(actualresult_result, prediction_result)\n","print(\"Classification report: \\n\", classification_report)\n","confusion_matrix = metrics.confusion_matrix(actualresult_result, prediction_result)\n","print(\"Confusion matrix: \\n\",confusion_matrix)\n","\n","print(\"Accuracy Score: \", accuracy_score(actualresult_result, prediction_result))\n","print(\"F1 Score: \", f1_score(actualresult_result, prediction_result, average='weighted'))\n","print(\"Precision Score: \", precision_score(actualresult_result, prediction_result, average='weighted'))\n","print(\"Recall Score: \", recall_score(actualresult_result, prediction_result, average='weighted'))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[6 6 6 ... 6 6 6]\n","[6 6 6 ... 6 6 6]\n","Classification report: \n","               precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00         0\n","           1       0.00      0.00      0.00         0\n","           3       0.00      0.00      0.00         0\n","           5       0.00      0.00      0.00         0\n","           6       1.00      0.99      1.00      7859\n","\n","    accuracy                           0.99      7859\n","   macro avg       0.20      0.20      0.20      7859\n","weighted avg       1.00      0.99      1.00      7859\n","\n","Confusion matrix: \n"," [[   0    0    0    0    0]\n"," [   0    0    0    0    0]\n"," [   0    0    0    0    0]\n"," [   0    0    0    0    0]\n"," [   2   17   23    7 7810]]\n","Accuracy Score:  0.9937651100648938\n","F1 Score:  0.9968728061778033\n","Precision Score:  1.0\n","Recall Score:  0.9937651100648938\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"tcdz7PFd0Ndm","colab_type":"code","outputId":"363b7cb4-ddba-45a1-89bb-9e1b6e09cdff","executionInfo":{"status":"ok","timestamp":1587143464355,"user_tz":300,"elapsed":7622,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":513}},"source":["import pickle\n","flicker_sound_X = np.load('/content/drive/My Drive/Audio_Quality_Analysis/data/flicker_sound_15K_np_array_X.npy', allow_pickle=True)\n","flicker_sound_X = flicker_sound_X[9001:len(flicker_sound_X)]\n","flicker_sound_y = np.full((len(flicker_sound_X)), 'flicker_sound')\n","print('flicker_sound_ len: ', len(flicker_sound_X))\n","\n","with open('/content/drive/My Drive/Audio_Quality_Analysis/model/labelEncoderFile_With_all_sound_LE_04162020.pkl', 'rb') as fid:\n","    le_loaded = pickle.load(fid)\n","\n","yy1 = to_categorical(le_loaded.transform(flicker_sound_y))\n","\n","flicker_sound_X = np.expand_dims(flicker_sound_X, axis=3)\n","\n","x_train1, x_test1, y_train1, y_test1 = train_test_split(flicker_sound_X, yy1, test_size=0.9, random_state = 42)\n","\n","predict = model.predict(x_test1)\n","predict=np.round(predict,decimals=5)\n","result = map(lambda v : np.argmax(v), predict)\n","prediction_result = np.array(list(result))\n","print(prediction_result)\n","\n","actual=np.round(y_test1,decimals=5)\n","actualresult = map(lambda v : np.argmax(v), actual)\n","actualresult_result = np.array(list(actualresult))\n","print(actualresult_result)\n","\n","classification_report = metrics.classification_report(actualresult_result, prediction_result)\n","print(\"Classification report: \\n\", classification_report)\n","confusion_matrix = metrics.confusion_matrix(actualresult_result, prediction_result)\n","print(\"Confusion matrix: \\n\",confusion_matrix)\n","\n","print(\"Accuracy Score: \", accuracy_score(actualresult_result, prediction_result))\n","print(\"F1 Score: \", f1_score(actualresult_result, prediction_result, average='weighted'))\n","print(\"Precision Score: \", precision_score(actualresult_result, prediction_result, average='weighted'))\n","print(\"Recall Score: \", recall_score(actualresult_result, prediction_result, average='weighted'))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["flicker_sound_ len:  5998\n","[2 2 2 ... 2 2 2]\n","[2 2 2 ... 2 2 2]\n","Classification report: \n","               precision    recall  f1-score   support\n","\n","           2       1.00      1.00      1.00      5399\n","           3       0.00      0.00      0.00         0\n","           5       0.00      0.00      0.00         0\n","           6       0.00      0.00      0.00         0\n","\n","    accuracy                           1.00      5399\n","   macro avg       0.25      0.25      0.25      5399\n","weighted avg       1.00      1.00      1.00      5399\n","\n","Confusion matrix: \n"," [[5389    5    1    4]\n"," [   0    0    0    0]\n"," [   0    0    0    0]\n"," [   0    0    0    0]]\n","Accuracy Score:  0.9981478051491017\n","F1 Score:  0.9990730441230996\n","Precision Score:  1.0\n","Recall Score:  0.9981478051491017\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"eXFqmOE7Tlfb","colab_type":"code","outputId":"646604c3-e490-4fbb-b155-24feca97fd29","executionInfo":{"status":"ok","timestamp":1587147218088,"user_tz":300,"elapsed":1255,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":496}},"source":["import os\n","features= []\n","folders = os.listdir('/content/fma_small')\n","n=0 ;\n","prcessed_folders=['checksums', 'README.txt', '111','104','027','085','095','091','153','073','062','117','119','140','149','086','101','089','066','084','012','017','070','004','114','053','010','106','040','009','049','130','087','064','050','078','045','002','019','128','005','098','043','103','065','011','032','116','154','148','006','151','034','024','021','097','123','137','099','120','082','033','125','115','008','122','074','113','100','127','139','077','067','129','039','069','041','042','150','143','022','013','075','133','029','044','155','134','023','079','142','124','083','118','141','081','057','018','132','136','072','144','108','145','090','001']\n","for folder in folders:\n","  try:\n","    files = os.listdir('/content/fma_small/'+ str(folder))\n","    print('Processing Start for: ', folder)\n","    for file in files:\n","        if n>100:\n","          break;\n","        n = n+1\n","        try:\n","          audio, sample_rate = librosa.load('/content/fma_small/'+ str(folder)+'/'+str(file), sr=22050, res_type='kaiser_fast') \n","          trim_signal = librosa.effects.trim(audio)\n","          total_duration = 4*sample_rate\n","          split_signal = trim_signal[0] \n","          if len(trim_signal[0]) > total_duration:\n","            split_signal=trim_signal[0][0:total_duration]\n","          \n","          aud_feature = extract_mfcc_features_with_padding(split_signal, sample_rate)\n","          if aud_feature is not None:\n","            class_label = \"music_sound\"\n","            features.append([aud_feature, class_label])\n","        except Exception as e:\n","          print(\"Error encountered while parsing file: \", file)\n","  except Exception as e:\n","        print(\"Error encountered while parsing folder: \", folder)\n","\n","\n","featuresdf_music = pd.DataFrame(features, columns=['feature','class_label'])\n","music_sound_X = np.array(featuresdf_music.feature.tolist())\n","music_sound_y = np.array(featuresdf_music.class_label.tolist())\n","print(len(music_sound_X))\n","print(music_sound_X.shape)\n","\n","with open('/content/drive/My Drive/Audio_Quality_Analysis/model/labelEncoderFile_With_all_sound_LE_04162020.pkl', 'rb') as fid:\n","    le_loaded = pickle.load(fid)\n","\n","yy1 = to_categorical(le_loaded.transform(music_sound_y))\n","\n","music_sound_X = np.expand_dims(music_sound_X, axis=3)\n","\n","x_train1, x_test1, y_train1, y_test1 = train_test_split(music_sound_X, yy1, test_size=0.9, random_state = 42)\n","\n","predict = model.predict(x_test1)\n","predict=np.round(predict,decimals=5)\n","result = map(lambda v : np.argmax(v), predict)\n","prediction_result = np.array(list(result))\n","print(prediction_result)\n","\n","actual=np.round(y_test1,decimals=5)\n","actualresult = map(lambda v : np.argmax(v), actual)\n","actualresult_result = np.array(list(actualresult))\n","print(actualresult_result)\n","\n","classification_report = metrics.classification_report(actualresult_result, prediction_result)\n","print(\"Classification report: \\n\", classification_report)\n","confusion_matrix = metrics.confusion_matrix(actualresult_result, prediction_result)\n","print(\"Confusion matrix: \\n\",confusion_matrix)\n","\n","print(\"Accuracy Score: \", accuracy_score(actualresult_result, prediction_result))\n","print(\"F1 Score: \", f1_score(actualresult_result, prediction_result, average='weighted'))\n","print(\"Precision Score: \", precision_score(actualresult_result, prediction_result, average='weighted'))\n","print(\"Recall Score: \", recall_score(actualresult_result, prediction_result, average='weighted'))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n"," 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 3 3 3 3 3 3 3 6 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n"," 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n","[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n"," 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n"," 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n","Classification report: \n","               precision    recall  f1-score   support\n","\n","           3       1.00      0.98      0.99        91\n","           6       0.00      0.00      0.00         0\n","\n","    accuracy                           0.98        91\n","   macro avg       0.50      0.49      0.49        91\n","weighted avg       1.00      0.98      0.99        91\n","\n","Confusion matrix: \n"," [[89  2]\n"," [ 0  0]]\n","Accuracy Score:  0.978021978021978\n","F1 Score:  0.9888888888888888\n","Precision Score:  1.0\n","Recall Score:  0.978021978021978\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"y9HLm2zwZVWA","colab_type":"code","outputId":"27674f90-da20-45f9-fc22-cd4778be6366","executionInfo":{"status":"ok","timestamp":1587148059556,"user_tz":300,"elapsed":1139,"user":{"displayName":"abhishek khandelwal","photoUrl":"https://lh6.googleusercontent.com/-9_JeiTM6h3w/AAAAAAAAAAI/AAAAAAAAKT0/50pUZ0hooPQ/s64/photo.jpg","userId":"12088551721026822394"}},"colab":{"base_uri":"https://localhost:8080/","height":357}},"source":["#extarct samples of original flickr audio\n","import random\n","\n","flicker_features= []\n","urban_features=[]\n","music_features=[]\n","original_audio = pd.DataFrame()\n","crackle_noise_files = ['Crackle_02.wav', 'Crackling_Fireplace.wav', 'Tape_Noise_02.wav']\n","electric_noise_files= ['Air_FX_01.wav', 'electriccurrent.wav', 'EMOTOR.wav', 'ESPARK1.wav', 'fire.wav', 'Gate_Filtered_01(130BPM).wav', 'ha.wav', 'hi-tensionpower.wav', 'Juno_60_Raw_b.wav']\n","other_noise_files = ['Noise_09.wav', 'Noise_Hit_01.wav', 'Perc_Hit_06.wav']\n","white_pink_brown_noise_files = ['brown.wav', 'pink.wav', 'white.wav', 'noise.wav']\n","\n","inner_n=0\n","outer_n=0\n","\n","folders=os.listdir('/content/UrbanSound8K/audio')\n","for folder in folders:\n","  if outer_n > 30:\n","    break;\n","  if outer_n%1000 ==0:\n","    print('processed records', outer_n)\n","  if folder != '.DS_Store' :\n","    files = os.listdir('/content/UrbanSound8K/audio/'+ str(folder))\n","    inner_n = 0\n","    for file in files:\n","      if file != '.DS_Store':\n","        inner_n = inner_n +1\n","        outer_n = outer_n+1\n","        if inner_n > 3:\n","          break;\n","        try:\n","          signal, sample_rate = librosa.load('/content/UrbanSound8K/audio/'+ str(folder)+'/'+str(file) , res_type='kaiser_fast') \n","          \n","          noise_file= str(random.choice(white_pink_brown_noise_files))\n","          print('Selected noise file: ', noise_file)\n","          noise_sample, sr1 = librosa.load('/content/Noise/white_pink_brown_noise/'+str(noise_file), res_type='kaiser_fast')\n","          print('after loading noise signal')\n","          if(len(noise_sample) > len(signal)):\n","              noise_sample=noise_sample[0:len(signal)]\n","\n","          if(len(noise_sample) < len(signal)):\n","              signal=signal[0:len(noise_sample)]\n","\n","          mixed_noise_signal = get_noise_from_sound(signal,noise_sample,SNR=10)\n","\n","          trim_signal = librosa.effects.trim(mixed_noise_signal)\n","          total_duration = 4*sample_rate\n","          split_signal = trim_signal[0] \n","          if len(trim_signal[0]) > total_duration:\n","            split_signal=trim_signal[0][0:total_duration]\n","\n","          aud_feature = extract_mfcc_features_with_padding(split_signal, sample_rate)\n","          if aud_feature is not None:\n","            class_label = \"real_noise\"\n","            urban_features.append([aud_feature, class_label])\n","        except Exception as e:\n","          print(\"Error encountered while parsing file: \", file)\n","\n","print('Processing done for Urban Sound with ', len(urban_features))\n","inner_n=0\n","outer_n=0\n","\n","folders=os.listdir('/content/fma_small')\n","for folder in folders:\n","  if outer_n > 30:\n","    break;\n","  if outer_n%1000 ==0:\n","    print('processed records', outer_n)\n","  if folder != '.DS_Store' and folder != 'README.txt' and folder != 'checksums' :\n","    files = os.listdir('/content/fma_small/'+ str(folder))\n","    inner_n = 0\n","\n","    for file in files:\n","      if file != '.DS_Store' and file != 'README.txt' and file != 'checksums':\n","        inner_n = inner_n +1\n","        outer_n = outer_n+1\n","        if inner_n > 2:\n","          break;\n","        try:\n","          signal, sample_rate = librosa.load('/content/fma_small/'+ str(folder)+'/'+str(file) , res_type='kaiser_fast') \n","\n","          noise_file= str(random.choice(white_pink_brown_noise_files))\n","          print(outer_n , ' : InnerN-> ', inner_n, ' : Folder-> ', folder, ' : File:', file)\n","          noise_sample, sr1 = librosa.load('/content/Noise/white_pink_brown_noise/'+str(noise_file), res_type='kaiser_fast')\n","\n","          if(len(noise_sample) > len(signal)):\n","              noise_sample=noise_sample[0:len(signal)]\n","\n","          if(len(noise_sample) < len(signal)):\n","              signal=signal[0:len(noise_sample)]\n","\n","          mixed_noise_signal = get_noise_from_sound(signal,noise_sample,SNR=10)\n","\n","          trim_signal = librosa.effects.trim(mixed_noise_signal)\n","          total_duration = 4*sample_rate\n","          split_signal = trim_signal[0] \n","          if len(trim_signal[0]) > total_duration:\n","            split_signal=trim_signal[0][0:total_duration]\n","\n","          aud_feature = extract_mfcc_features_with_padding(split_signal, sample_rate)\n","          if aud_feature is not None:\n","            class_label = \"real_noise\"\n","            music_features.append([aud_feature, class_label])\n","        except Exception as e:\n","          print(\"Error encountered while parsing file: \", file)\n","\n","print(len(flicker_features))\n","print(len(urban_features))\n","print(len(music_features))\n","\n","#temp = np.concatenate((flicker_features, urban_features), axis=0)\n","final_noise_feature = np.concatenate((urban_features, music_features), axis=0)\n","\n","print(len(final_noise_feature))\n","\n","featuresdf = pd.DataFrame(final_noise_feature, columns=['feature','class_label'])\n","real_noise_X = np.array(featuresdf.feature.tolist())\n","real_noise_y = np.array(featuresdf.class_label.tolist())\n","\n","with open('/content/drive/My Drive/Audio_Quality_Analysis/model/labelEncoderFile_With_all_sound_LE_04162020.pkl', 'rb') as fid:\n","    le_loaded = pickle.load(fid)\n","\n","yy1 = to_categorical(le_loaded.transform(real_noise_y))\n","\n","real_noise_X = np.expand_dims(real_noise_X, axis=3)\n","\n","x_train1, x_test1, y_train1, y_test1 = train_test_split(real_noise_X, yy1, test_size=0.9, random_state = 42)\n","\n","predict = model.predict(x_test1)\n","predict=np.round(predict,decimals=5)\n","result = map(lambda v : np.argmax(v), predict)\n","prediction_result = np.array(list(result))\n","print(prediction_result)\n","\n","actual=np.round(y_test1,decimals=5)\n","actualresult = map(lambda v : np.argmax(v), actual)\n","actualresult_result = np.array(list(actualresult))\n","print(actualresult_result)\n","\n","classification_report = metrics.classification_report(actualresult_result, prediction_result)\n","print(\"Classification report: \\n\", classification_report)\n","confusion_matrix = metrics.confusion_matrix(actualresult_result, prediction_result)\n","print(\"Confusion matrix: \\n\",confusion_matrix)\n","\n","print(\"Accuracy Score: \", accuracy_score(actualresult_result, prediction_result))\n","print(\"F1 Score: \", f1_score(actualresult_result, prediction_result, average='weighted'))\n","print(\"Precision Score: \", precision_score(actualresult_result, prediction_result, average='weighted'))\n","print(\"Recall Score: \", recall_score(actualresult_result, prediction_result, average='weighted'))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["46\n","[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n"," 5 5 5 5 5]\n","[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n"," 5 5 5 5 5]\n","Classification report: \n","               precision    recall  f1-score   support\n","\n","           5       1.00      1.00      1.00        42\n","\n","    accuracy                           1.00        42\n","   macro avg       1.00      1.00      1.00        42\n","weighted avg       1.00      1.00      1.00        42\n","\n","Confusion matrix: \n"," [[42]]\n","Accuracy Score:  1.0\n","F1 Score:  1.0\n","Precision Score:  1.0\n","Recall Score:  1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3J_lBKbMlhjl","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","noise_x = np.load('/content/drive/My Drive/Audio_Quality_Analysis/data/noise_result_np_array_X1.npy', allow_pickle=True)\n","noise_y = np.full((len(noise_x)), 'real_noise')\n","#le = LabelEncoder()\n","yy1 = to_categorical(le.fit_transform(noise_y))\n","\n","noise_x = np.expand_dims(noise_x, axis=3)\n","\n","x_train1, x_test1, y_train1, y_test1 = train_test_split(noise_x, yy1, test_size=0.9, random_state = 42)\n","\n","predict = model.predict(x_test1)\n","predict=np.round(predict,decimals=5)\n","result = map(lambda v : np.argmax(v), predict)\n","prediction_result = np.array(list(result))\n","print(prediction_result)\n","\n","actual=np.round(y_test1,decimals=5)\n","actualresult = map(lambda v : np.argmax(v), actual)\n","actualresult_result = np.array(list(actualresult))\n","print(actualresult_result)\n","\n","classification_report = metrics.classification_report(actualresult_result, prediction_result)\n","print(\"Classification report: \\n\", classification_report)\n","confusion_matrix = metrics.confusion_matrix(actualresult_result, prediction_result)\n","print(\"Confusion matrix: \\n\",confusion_matrix)\n","\n","print(\"Accuracy Score: \", accuracy_score(actualresult_result, prediction_result))\n","print(\"F1 Score: \", f1_score(actualresult_result, prediction_result, average='weighted'))\n","print(\"Precision Score: \", precision_score(actualresult_result, prediction_result, average='weighted'))\n","print(\"Recall Score: \", recall_score(actualresult_result, prediction_result, average='weighted'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yj9BtniBs6i8","colab_type":"code","colab":{}},"source":["actualresult_result = np.full((len(y_test1)), 1)\n","print(actualresult_result)\n","print(len(actualresult_result))"],"execution_count":0,"outputs":[]}]}