{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier,GradientBoostingClassifier\n",
    "from IPython.display import display\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.impute._base import SimpleImputer as Imputer\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    " \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2         1       3                             Heikkinen, Miss. Laina   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4         0       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = pd.read_csv('train.csv')\n",
    "titanic_df = titanic_df.drop('PassengerId', axis=1)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      int64\n",
       "Pclass        int64\n",
       "Name         object\n",
       "Sex          object\n",
       "Age         float64\n",
       "SibSp         int64\n",
       "Parch         int64\n",
       "Ticket       object\n",
       "Fare        float64\n",
       "Cabin        object\n",
       "Embarked     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping Passenger ID as its not required feature\n",
    "\n",
    "titanic_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test.\n",
    "X = titanic_df.drop('Survived', axis=1)\n",
    "y = titanic_df['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['Age', 'Fare']\n",
    "categorical_features = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']\n",
    "name_feature = ['Name']\n",
    "cabin_feature = ['Cabin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='U')),\n",
    "    ('labelEncoder', LabelEncoder()),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CabinFeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        print('in the CabinFeatureTransformer init method: ')\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        x.Cabin.fillna('U', inplace=True)\n",
    "        x['Cabin'] = x['Cabin'].map(lambda c: c[0])\n",
    "        \n",
    "        cabin_dummies = pd.get_dummies(x['Cabin'], prefix='Cabin')    \n",
    "        self.cabin_columns=  cabin_dummies.columns\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        # replacing missing cabins with U (for Uknown)\n",
    "        x.Cabin.fillna('U', inplace=True)\n",
    "    \n",
    "        # mapping each Cabin value with the cabin letter\n",
    "        x['Cabin'] = x['Cabin'].map(lambda c: c[0])\n",
    "        \n",
    "        cabin_dummies = pd.get_dummies(x['Cabin'], prefix='Cabin') \n",
    "        cabin_dummies = cabin_dummies.reindex(columns = self.cabin_columns, fill_value=0)\n",
    "        \n",
    "        x = pd.concat([x, cabin_dummies], axis=1)\n",
    "\n",
    "        x.drop('Cabin', axis=1, inplace=True)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameFeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        print('in the NameFeatureTransformer Init method: ')\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        Title_Dictionary = {\n",
    "                \"Capt\": \"Officer\", \"Col\": \"Officer\", \"Major\": \"Officer\",\"Jonkheer\": \"Royalty\",\n",
    "                \"Don\": \"Royalty\",\"Sir\" : \"Royalty\",\"Dr\": \"Officer\",\"Rev\": \"Officer\",\"the Countess\":\"Royalty\",\n",
    "                \"Mme\": \"Mrs\", \"Mlle\": \"Miss\", \"Ms\": \"Mrs\", \"Mr\" : \"Mr\", \"Mrs\" : \"Mrs\", \"Miss\" : \"Miss\",\n",
    "                \"Master\" : \"Master\", \"Lady\" : \"Royalty\"}\n",
    "        \n",
    "        x['Title'] = x['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
    "        x['Title'] = x.Title.map(Title_Dictionary)\n",
    "        \n",
    "        x.drop('Name', axis=1, inplace=True)\n",
    "    \n",
    "        titles_dummies = pd.get_dummies(x['Title'], prefix='Title')\n",
    "        x = pd.concat([x, titles_dummies], axis=1)\n",
    "    \n",
    "        x.drop('Title', axis=1, inplace=True)\n",
    "        return x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the CabinFeatureTransformer init method: \n",
      "in the NameFeatureTransformer Init method: \n"
     ]
    }
   ],
   "source": [
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric_data_preprocessing', numeric_transformer, numeric_features),\n",
    "        ('categorical_data_preprocessing', categorical_transformer, categorical_features),\n",
    "        ('cabin_data_preprocessing', CabinFeatureTransformer(), cabin_feature),\n",
    "        ('name_data_preprocessing', NameFeatureTransformer(), name_feature)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline = Pipeline(steps=[('transformer', transformer),\n",
    "                      ('rf_estimator', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the CabinFeatureTransformer init method: \n",
      "in the NameFeatureTransformer Init method: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('transformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('numeric_data_preprocessing',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='median',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScal...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = final_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.776536312849162\n",
      "F1 Score:  0.7774989742133006\n",
      "Precision Score:  0.778662973569316\n",
      "Recall Score:  0.776536312849162\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score: \", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Precision Score: \", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall Score: \", recall_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('Titanic_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(final_pipeline, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.776536312849162\n",
      "F1 Score:  0.7774989742133006\n",
      "Precision Score:  0.778662973569316\n",
      "Recall Score:  0.776536312849162\n"
     ]
    }
   ],
   "source": [
    "rf_pickle = pickle.load(open('Titanic_pipeline.pkl','rb'))\n",
    "y_pred = rf_pickle.predict(X_test)\n",
    "\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score: \", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Precision Score: \", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall Score: \", recall_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
